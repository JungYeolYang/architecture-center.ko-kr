---
title: 분할
description: 데이터 저장소를 수평 파티션 또는 분할 집합으로 나눕니다.
keywords: 디자인 패턴
author: dragon119
ms.date: 06/23/2017
pnp.series.title: Cloud Design Patterns
pnp.pattern.categories:
- data-management
- performance-scalability
ms.openlocfilehash: bc2b6aeb6966d14327a21849adbbfe635eae59df
ms.sourcegitcommit: 94d50043db63416c4d00cebe927a0c88f78c3219
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 09/28/2018
ms.locfileid: "47428859"
---
# <a name="sharding-pattern"></a><span data-ttu-id="442fa-104">분할 패턴</span><span class="sxs-lookup"><span data-stu-id="442fa-104">Sharding pattern</span></span>

[!INCLUDE [header](../_includes/header.md)]

<span data-ttu-id="442fa-105">데이터 저장소를 수평 파티션 또는 분할 집합으로 나눕니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-105">Divide a data store into a set of horizontal partitions or shards.</span></span> <span data-ttu-id="442fa-106">이를 통해 대량의 데이터를 저장하고 액세스할 때 확장성을 개선할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-106">This can improve scalability when storing and accessing large volumes of data.</span></span>

## <a name="context-and-problem"></a><span data-ttu-id="442fa-107">컨텍스트 및 문제점</span><span class="sxs-lookup"><span data-stu-id="442fa-107">Context and problem</span></span>

<span data-ttu-id="442fa-108">단일 서버에 의해 호스트된 데이터 저장소는 다음과 같은 제한을 받을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-108">A data store hosted by a single server might be subject to the following limitations:</span></span>

- <span data-ttu-id="442fa-109">**저장소 공간**.</span><span class="sxs-lookup"><span data-stu-id="442fa-109">**Storage space**.</span></span> <span data-ttu-id="442fa-110">대규모 클라우드 애플리케이션을 위한 데이터 저장소에는 시간이 지남에 따라 크게 늘어날 수 있는 대규모 데이터가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-110">A data store for a large-scale cloud application is expected to contain a huge volume of data that could increase significantly over time.</span></span> <span data-ttu-id="442fa-111">서버는 일반적으로 한정된 디스크 저장소만 제공하지만, 데이터 볼륨이 늘어남에 따라 기존의 디스크를 용량이 더 큰 디스크로 교체하거나 컴퓨터에 디스크를 추가할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-111">A server typically provides only a finite amount of disk storage, but you can replace existing disks with larger ones, or add further disks to a machine as data volumes grow.</span></span> <span data-ttu-id="442fa-112">그러나, 시스템은 결국 정해진 서버의 저장소 용량을 쉽게 늘릴 수 없는 한계에 이르게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-112">However, the system will eventually reach a limit where it isn't possible to easily increase the storage capacity on a given server.</span></span>

- <span data-ttu-id="442fa-113">**컴퓨팅 리소스**.</span><span class="sxs-lookup"><span data-stu-id="442fa-113">**Computing resources**.</span></span> <span data-ttu-id="442fa-114">클라우드 애플리케이션은 많은 동시 사용자를 지원해야 하고 각 사용자는 데이터 저장소에서 정보를 검색하는 쿼리를 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-114">A cloud application is required to support a large number of concurrent users, each of which run queries that retrieve information from the data store.</span></span> <span data-ttu-id="442fa-115">데이터 저장소를 호스트하는 단일 서버는 데이터 저장 및 검색을 시도하는 애플리케이션이 시간 초과되면서 사용자에 대한 응답 시간이 길어지고 빈번한 실패를 야기함에 따라 이 부하를 지원하는 데 필요한 컴퓨팅 기능을 제공하지 못할 수 있습니다. 메모리를 추가하거나 프로세서를 업데이트하는 것이 가능할 수도 있지만, 더 이상 계산 리소스를 늘리는 것이 불가능하면 시스템은 한계에 도달하게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-115">A single server hosting the data store might not be able to provide the necessary computing power to support this load, resulting in extended response times for users and frequent failures as applications attempting to store and retrieve data time out. It might be possible to add memory or upgrade processors, but the system will reach a limit when it isn't possible to increase the compute resources any further.</span></span>

- <span data-ttu-id="442fa-116">**네트워크 대역폭**.</span><span class="sxs-lookup"><span data-stu-id="442fa-116">**Network bandwidth**.</span></span> <span data-ttu-id="442fa-117">궁극적으로 단일 서버에서 실행되는 데이터 저장소의 성능은 서버가 요청을 검색하고 응답을 전송할 수 있는 속도에 따라 달라집니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-117">Ultimately, the performance of a data store running on a single server is governed by the rate the server can receive requests and send replies.</span></span> <span data-ttu-id="442fa-118">네트워크 트래픽 볼륨이 서버 연결에 사용된 네트워크 용량을 초과하여 요청이 실패할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-118">It's possible that the volume of network traffic might exceed the capacity of the network used to connect to the server, resulting in failed requests.</span></span>

- <span data-ttu-id="442fa-119">**지리**.</span><span class="sxs-lookup"><span data-stu-id="442fa-119">**Geography**.</span></span> <span data-ttu-id="442fa-120">법률, 규정 준수 또는 성능상의 이유로 또는 데이터 액세스의 대기 시간을 줄이기 위해 특정 사용자가 생성한 데이터를 해당 사용자와 동일한 지역에 저장해야 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-120">It might be necessary to store data generated by specific users in the same region as those users for legal, compliance, or performance reasons, or to reduce latency of data access.</span></span> <span data-ttu-id="442fa-121">사용자가 여러 나라나 지역에 분산된 경우 단일 데이터 저장소에 애플리케이션의 전체 데이터를 저장하는 것이 불가능할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-121">If the users are dispersed across different countries or regions, it might not be possible to store the entire data for the application in a single data store.</span></span>

<span data-ttu-id="442fa-122">디스크 용량, 처리 능력, 메모리, 네트워크 연결을 추가하여 수직적으로 확장하면 이러한 한계의 영향을 늦출 수 있지만, 일시적 해결책에 불과할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-122">Scaling vertically by adding more disk capacity, processing power, memory, and network connections can postpone the effects of some of these limitations, but it's likely to only be a temporary solution.</span></span> <span data-ttu-id="442fa-123">많은 사용자와 대용량 데이터를 지원할 수 있는 상용 클라우드 애플리케이션은 거의 무한정으로 크기 조정이 가능해야 하므로 수직적 확장이 반드시 최선의 해결책은 아닙니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-123">A commercial cloud application capable of supporting large numbers of users and high volumes of data must be able to scale almost indefinitely, so vertical scaling isn't necessarily the best solution.</span></span>

## <a name="solution"></a><span data-ttu-id="442fa-124">해결 방법</span><span class="sxs-lookup"><span data-stu-id="442fa-124">Solution</span></span>

<span data-ttu-id="442fa-125">데이터 저장소를 수평 파티션 또는 분할된 데이터베이스로 나눕니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-125">Divide the data store into horizontal partitions or shards.</span></span> <span data-ttu-id="442fa-126">각 분할된 데이터베이스는 같은 스키마를 갖지만 고유의 자체 데이터 하위 집합을 보유합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-126">Each shard has the same schema, but holds its own distinct subset of the data.</span></span> <span data-ttu-id="442fa-127">분할된 데이터베이스는 다양한 유형의 많은 엔터티에 대한 데이터를 포함할 수 있는 데이터 저장소 그 자체이며, 저장소 노드 역할을 하는 서버에서 실행됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-127">A shard is a data store in its own right (it can contain the data for many entities of different types), running on a server acting as a storage node.</span></span>

<span data-ttu-id="442fa-128">이 패턴에는 다음과 같은 이점이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-128">This pattern has the following benefits:</span></span>

- <span data-ttu-id="442fa-129">추가 저장소 노드에서 실행되는 분할된 데이터베이스를 더 추가하여 시스템을 확장할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-129">You can scale the system out by adding further shards running on additional storage nodes.</span></span>

- <span data-ttu-id="442fa-130">시스템은 각 저장소 노드에 특별하고 값비싼 컴퓨터 대신 기성 하드웨어를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-130">A system can use off-the-shelf hardware rather than specialized and expensive computers for each storage node.</span></span>

- <span data-ttu-id="442fa-131">분할된 데이터베이스에 워크로드를 분산하여 경합을 줄이고 성능을 개선할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-131">You can reduce contention and improve performance by balancing the workload across shards.</span></span>

- <span data-ttu-id="442fa-132">클라우드에서 분할된 데이터베이스는 데이터를 액세스할 사용자와 물리적으로 가까이 배치할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-132">In the cloud, shards can be located physically close to the users that'll access the data.</span></span>

<span data-ttu-id="442fa-133">데이터 저장소를 분할된 데이터베이스로 나눌 때 분할된 각 데이터베이스에 배치할 데이터를 결정합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-133">When dividing a data store up into shards, decide which data should be placed in each shard.</span></span> <span data-ttu-id="442fa-134">일반적으로 분할된 데이터베이스는 하나 이상의 데이터 특성에 의해 결정되는 특정한 범위에 속하는 항목을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-134">A shard typically contains items that fall within a specified range determined by one or more attributes of the data.</span></span> <span data-ttu-id="442fa-135">이러한 특성이 분할 키(파티션 키라고도 함)를 형성합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-135">These attributes form the shard key (sometimes referred to as the partition key).</span></span> <span data-ttu-id="442fa-136">분할 키는 정적이어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-136">The shard key should be static.</span></span> <span data-ttu-id="442fa-137">변경될 수 있는 데이터를 기반으로 하면 안 됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-137">It shouldn't be based on data that might change.</span></span>

<span data-ttu-id="442fa-138">분할은 물리적으로 데이터를 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-138">Sharding physically organizes the data.</span></span> <span data-ttu-id="442fa-139">애플리케이션이 데이터를 저장하고 검색할 때 분할 논리는 애플리케이션을 적절한 분할된 데이터베이스로 전달합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-139">When an application stores and retrieves data, the sharding logic directs the application to the appropriate shard.</span></span> <span data-ttu-id="442fa-140">이 분할 논리는 애플리케이션에서 데이터 액세스 코드의 일부로 구현되거나, 분할을 투명하게 지원할 경우 데이터 저장소 시스템에 의해 구현될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-140">This sharding logic can be implemented as part of the data access code in the application, or it could be implemented by the data storage system if it transparently supports sharding.</span></span>

<span data-ttu-id="442fa-141">데이터의 물리적 위치를 분할 논리로 추상화하면 어떤 분할된 데이터베이스가 어떤 데이터를 포함하는지에 대한 높은 수준의 관리를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-141">Abstracting the physical location of the data in the sharding logic provides a high level of control over which shards contain which data.</span></span> <span data-ttu-id="442fa-142">또한 분할된 데이터베이스에 있는 데이터가 추후 재배포되어야 할 경우(예: 분할된 데이터베이스가 불균형 상태가 되는 경우) 애플리케이션의 비즈니스 논리를 재작업하지 않고 분할된 데이터베이스 간에 데이터를 마이그레이션할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-142">It also enables data to migrate between shards without reworking the business logic of an application if the data in the shards need to be redistributed later (for example, if the shards become unbalanced).</span></span> <span data-ttu-id="442fa-143">단점은 각 데이터 항목 검색 시 해당 위치 결정에 필요한 추가적인 데이터 액세스 오버헤드가 발생한다는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-143">The tradeoff is the additional data access overhead required in determining the location of each data item as it's retrieved.</span></span>

<span data-ttu-id="442fa-144">최적의 성능과 확장성을 위해 애플리케이션이 수행하는 쿼리 유형에 맞는 방식으로 데이터를 분할하는 것이 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-144">To ensure optimal performance and scalability, it's important to split the data in a way that's appropriate for the types of queries that the application performs.</span></span> <span data-ttu-id="442fa-145">대부분의 경우 분할 구성표는 모든 쿼리의 요구 사항과 정확히 일치할 가능성이 낮습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-145">In many cases, it's unlikely that the sharding scheme will exactly match the requirements of every query.</span></span> <span data-ttu-id="442fa-146">예를 들어 다중 테넌트 시스템에서 애플리케이션은 테넌트 ID로 테넌트 데이터를 검색해야 할 수 있지만, 테넌트 이름이나 위치 등 일부 다른 특성을 기반으로 이 데이터를 조회해야 할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-146">For example, in a multi-tenant system an application might need to retrieve tenant data using the tenant ID, but it might also need to look up this data based on some other attribute such as the tenant’s name or location.</span></span> <span data-ttu-id="442fa-147">이러한 상황을 처리하기 위해서는 가장 일반적으로 수행되는 쿼리를 지원하는 분할 키로 분할 전략을 구현합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-147">To handle these situations, implement a sharding strategy with a shard key that supports the most commonly performed queries.</span></span>

<span data-ttu-id="442fa-148">쿼리가 특성 값을 조합하여 정기적으로 데이터를 검색할 경우 특성을 함께 연결하여 복합 분할 키를 정의할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-148">If queries regularly retrieve data using a combination of attribute values, you can likely define a composite shard key by linking attributes together.</span></span> <span data-ttu-id="442fa-149">또는 분할 키로 찾을 수 없는 특성을 기반으로 하는 데이터를 빨리 조회하려면 [인덱스 테이블](index-table.md)과 같은 패턴을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-149">Alternatively, use a pattern such as [Index Table](index-table.md) to provide fast lookup to data based on attributes that aren't covered by the shard key.</span></span>

## <a name="sharding-strategies"></a><span data-ttu-id="442fa-150">분할 전략</span><span class="sxs-lookup"><span data-stu-id="442fa-150">Sharding strategies</span></span>

<span data-ttu-id="442fa-151">분할 키를 선택하고 분할된 데이터베이스에 데이터를 어떻게 분산시킬지 결정할 때 일반적으로 사용하는 세 가지 전략이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-151">Three strategies are commonly used when selecting the shard key and deciding how to distribute data across shards.</span></span> <span data-ttu-id="442fa-152">분할된 데이터베이스와 이를 호스트하는 서버가 일대일로 대응할 필요는 없습니다. 단일 서버가 여러 분할된 데이터베이스를 호스트할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-152">Note that there doesn't have to be a one-to-one correspondence between shards and the servers that host them&mdash;a single server can host multiple shards.</span></span> <span data-ttu-id="442fa-153">전략은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-153">The strategies are:</span></span>

<span data-ttu-id="442fa-154">**조회 전략**.</span><span class="sxs-lookup"><span data-stu-id="442fa-154">**The Lookup strategy**.</span></span> <span data-ttu-id="442fa-155">이 전략에서 분할 논리는 분할 키를 사용하여 데이터 요청을 해당 데이터가 포함된 분할된 데이터베이스로 라우트하는 맵을 구현합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-155">In this strategy the sharding logic implements a map that routes a request for data to the shard that contains that data using the shard key.</span></span> <span data-ttu-id="442fa-156">다중 테넌트 애플리케이션에서 테넌트의 모든 데이터는 테넌트 ID를 사용하여 분할된 데이터베이스에 함께 분할 키로 저장할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-156">In a multi-tenant application all the data for a tenant might be stored together in a shard using the tenant ID as the shard key.</span></span> <span data-ttu-id="442fa-157">여러 테넌트가 같은 분할된 데이터베이스를 공유할 수는 있지만, 단일 테넌트의 데이터를 여러 분할된 데이터베이스에 분배할 수는 없습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-157">Multiple tenants might share the same shard, but the data for a single tenant won't be spread across multiple shards.</span></span> <span data-ttu-id="442fa-158">다음 그림은 테넌트 ID를 기반으로 테넌트 데이터를 분할하는 것을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-158">The figure illustrates sharding tenant data based on tenant IDs.</span></span>

   ![그림 1 - 테넌트 ID를 기반으로 테넌트 데이터 분할](./_images/sharding-tenant.png)


   <span data-ttu-id="442fa-160">분할 키와 실제 저장소 간의 매핑은 각 분할 키가 물리적 파티션에 매핑되는 물리적 분할된 데이터베이스를 기반으로 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-160">The mapping between the shard key and the physical storage can be based on physical shards where each shard key maps to a physical partition.</span></span> <span data-ttu-id="442fa-161">또는 보다 유연한 분할된 데이터베이스 리밸러스 기술은 가상으로 분할하는 것으로, 분할 키는 같은 수의 가상 분할된 데이터베이스에 매핑되고 결국 더 적은 수의 물리적 파티션에 매핑됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-161">Alternatively, a more flexible technique for rebalancing shards is virtual partitioning, where shard keys map to the same number of virtual shards, which in turn map to fewer physical partitions.</span></span> <span data-ttu-id="442fa-162">이 접근 방식에서 애플리케이션은 가상 분할된 데이터베이스를 참조하는 분할 키를 사용하여 데이터를 찾고 시스템은 가상 분할된 데이터베이스를 물리적 파티션에 투명하게 매핑합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-162">In this approach, an application locates data using a shard key that refers to a virtual shard, and the system transparently maps virtual shards to physical partitions.</span></span> <span data-ttu-id="442fa-163">가상 분할된 데이터베이스와 물리적 파티션 간의 매핑은 다양한 분할 키 집합을 사용하기 위해 애플리케이션 코드를 수정하지 않고도 변경될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-163">The mapping between a virtual shard and a physical partition can change without requiring the application code be modified to use a different set of shard keys.</span></span>

<span data-ttu-id="442fa-164">**범위 전략**.</span><span class="sxs-lookup"><span data-stu-id="442fa-164">**The Range strategy**.</span></span> <span data-ttu-id="442fa-165">이 전략은 같은 분할된 데이터베이스의 관련된 항목을 함께 그룹화하고 분할 키에 따라 정렬합니다(분할 키는 순차적임).</span><span class="sxs-lookup"><span data-stu-id="442fa-165">This strategy groups related items together in the same shard, and orders them by shard key&mdash;the shard keys are sequential.</span></span> <span data-ttu-id="442fa-166">범위 쿼리(특정 범위에 속하는 분할 키에 대한 데이터 항목 집합을 반환하는 쿼리)를 사용하여 항목 집합을 자주 검색하는 애플리케이션에 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-166">It's useful for applications that frequently retrieve sets of items using range queries (queries that return a set of data items for a shard key that falls within a given range).</span></span> <span data-ttu-id="442fa-167">예를 들어 애플리케이션에서 특정 월에 있었던 모든 주문을 찾아야 할 경우 한 달 동안의 모든 주문이 같은 분할된 데이터베이스에 날짜 및 시간 순으로 저장되어 있다면 더 빨리 이 데이터를 검색할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-167">For example, if an application regularly needs to find all orders placed in a given month, this data can be retrieved more quickly if all orders for a month are stored in date and time order in the same shard.</span></span> <span data-ttu-id="442fa-168">각 주문이 다른 분할된 데이터베이스에 저장된 경우에는 여러 번의 지점 쿼리(단일 데이터 항목을 반환하는 쿼리)를 수행하여 주문을 개별적으로 가져와야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-168">If each order was stored in a different shard, they'd have to be fetched individually by performing a large number of point queries (queries that return a single data item).</span></span> <span data-ttu-id="442fa-169">다음 그림은 순차적 데이터 집합(범위)을 분할된 데이터베이스에 저장하는 것을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-169">The next figure illustrates storing sequential sets (ranges) of data in shard.</span></span>

   ![그림 2 - 순차적 데이터 집합(범위)을 분할된 데이터베이스에 저장](./_images/sharding-sequential-sets.png)

<span data-ttu-id="442fa-171">이 예에서, 분할 키는 주문 월을 가장 중요한 요소로 포함하고 그 다음으로 주문한 날짜와 시간을 포함하는 복합 키입니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-171">In this example, the shard key is a composite key containing the order month as the most significant element, followed by the order day and the time.</span></span> <span data-ttu-id="442fa-172">새 주문이 생성되고 분할된 데이터베이스에 추가되면 주문 데이터는 자연스럽게 저장됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-172">The data for orders is naturally sorted when new orders are created and added to a shard.</span></span> <span data-ttu-id="442fa-173">일부 데이터 저장소는 분할된 데이터베이스를 식별하는 분할 키 요소와 분할된 데이터베이스에서 항목을 고유하게 식별하는 행 키를 포함한, 두 부분으로 구성된 분할 키를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-173">Some data stores support two-part shard keys containing a partition key element that identifies the shard and a row key that uniquely identifies an item in the shard.</span></span> <span data-ttu-id="442fa-174">일반적으로 데이터는 분할된 데이터베이스에 행 키 순으로 저장됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-174">Data is usually held in row key order in the shard.</span></span> <span data-ttu-id="442fa-175">범위 쿼리에 적용되고 함께 그룹화해야 하는 항목은 파티션 키에 대해서는 동일한 값을 갖지만 행 키에 대해서는 고유한 값을 갖는 분할 키를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-175">Items that are subject to range queries and need to be grouped together can use a shard key that has the same value for the partition key but a unique value for the row key.</span></span>

<span data-ttu-id="442fa-176">**해시 전략**.</span><span class="sxs-lookup"><span data-stu-id="442fa-176">**The Hash strategy**.</span></span> <span data-ttu-id="442fa-177">이 전략의 목적은 핫스폿(너무 많은 부하를 받는 분할된 데이터베이스)을 줄이는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-177">The purpose of this strategy is to reduce the chance of hotspots (shards that receive a disproportionate amount of load).</span></span> <span data-ttu-id="442fa-178">각각의 분할된 데이터베이스의 크기와 각각의 분할된 데이터베이스가 받게 될 부하 사이에 균형 잡힌 방식으로 분할된 데이터베이스에 데이터를 분산합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-178">It distributes the data across the shards in a way that achieves a balance between the size of each shard and the average load that each shard will encounter.</span></span> <span data-ttu-id="442fa-179">분할 논리는 하나 이상의 데이터 특성에 대한 해시를 기반으로 항목을 저장할 분할된 데이터베이스를 계산합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-179">The sharding logic computes the shard to store an item in based on a hash of one or more attributes of the data.</span></span> <span data-ttu-id="442fa-180">선택된 해시 함수는 가능하면 몇 가지 임의 요소를 계산에 도입하여 분할된 데이터베이스 간에 균등하게 데이터를 분산해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-180">The chosen hashing function should distribute data evenly across the shards, possibly by introducing some random element into the computation.</span></span> <span data-ttu-id="442fa-181">다음 그림은 테넌트 ID의 해시를 기반으로 테넌트 데이터를 분할하는 것을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-181">The next figure illustrates sharding tenant data based on a hash of tenant IDs.</span></span>

   ![그림 3 - 테넌트 ID의 해시를 기반으로 테넌트 데이터 분할](./_images/sharding-data-hash.png)

<span data-ttu-id="442fa-183">다른 분할 전략보다 해시 전략의 장점을 이해하려면 새 테넌트를 순차적으로 등록하는 다중 테넌트 애플리케이션이 데이터 저장소에서 어떤 식으로 분할된 데이터베이스에 테넌트를 할당할 수 있는지 고려합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-183">To understand the advantage of the Hash strategy over other sharding strategies, consider how a multi-tenant application that enrolls new tenants sequentially might assign the tenants to shards in the data store.</span></span> <span data-ttu-id="442fa-184">범위 전략을 사용할 때, 테넌트 1 ~ n의 데이터는 모두 분할된 데이터베이스 A에, 테넌트 n+1 ~ m의 데이터는 모두 분할된 데이터베이스 B에, 이런 식으로 저장됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-184">When using the Range strategy, the data for tenants 1 to n will all be stored in shard A, the data for tenants n+1 to m will all be stored in shard B, and so on.</span></span> <span data-ttu-id="442fa-185">가장 최근에 등록된 테넌트가 가장 활동적인 경우 대부분의 데이터 작업은 소수의 분할된 데이터베이스에서 발생하고 이로 인해 핫스폿이 야기될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-185">If the most recently registered tenants are also the most active, most data activity will occur in a small number of shards, which could cause hotspots.</span></span> <span data-ttu-id="442fa-186">반대로, 해시 전략은 테넌트 ID의 해시를 기반으로 분할된 데이터베이스에 테넌트를 할당합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-186">In contrast, the Hash strategy allocates tenants to shards based on a hash of their tenant ID.</span></span> <span data-ttu-id="442fa-187">이는 순차적인 테넌트가 서로 다른 분할된 데이터베이스에 할당될 가능성이 높고, 결국 분할된 데이터베이스 간의 부하가 분산됨을 의미합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-187">This means that sequential tenants are most likely to be allocated to different shards, which will distribute the load across them.</span></span> <span data-ttu-id="442fa-188">위 그림은 테넌트 55와 56에 대하여 이 전략을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-188">The previous figure shows this for tenants 55 and 56.</span></span>

<span data-ttu-id="442fa-189">세 가지 분할 전략의 이점 및 고려 사항은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-189">The three sharding strategies have the following advantages and considerations:</span></span>

- <span data-ttu-id="442fa-190">**조회**.</span><span class="sxs-lookup"><span data-stu-id="442fa-190">**Lookup**.</span></span> <span data-ttu-id="442fa-191">분할된 데이터베이스의 구성 및 사용 방식을 잘 제어합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-191">This offers more control over the way that shards are configured and used.</span></span> <span data-ttu-id="442fa-192">가상 분할된 데이터베이스를 사용하면 새로운 물리적 파티션이 추가되어 워크로드를 균등하게 분배할 수 있기 때문에 데이터를 리밸러스할 때 영향이 줄어듭니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-192">Using virtual shards reduces the impact when rebalancing data because new physical partitions can be added to even out the workload.</span></span> <span data-ttu-id="442fa-193">분할된 데이터베이스를 구현하는 가상 분할된 데이터베이스와 물리적 파티션 간의 매핑은 데이터 저장 및 검색에 분할 키를 사용하는 애플리케이션 코드에 영향을 주지 않고 수정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-193">The mapping between a virtual shard and the physical partitions that implement the shard can be modified without affecting application code that uses a shard key to store and retrieve data.</span></span> <span data-ttu-id="442fa-194">분할된 데이터베이스 위치 조회로 추가 오버헤드가 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-194">Looking up shard locations can impose an additional overhead.</span></span>

- <span data-ttu-id="442fa-195">**범위**.</span><span class="sxs-lookup"><span data-stu-id="442fa-195">**Range**.</span></span> <span data-ttu-id="442fa-196">단일 분할된 데이터베이스로부터 여러 데이터 항목을 단일 작업으로 가져올 수 있는 경우가 많으므로 범위 쿼리와 잘 맞고 구현하기 쉽습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-196">This is easy to implement and works well with range queries because they can often fetch multiple data items from a single shard in a single operation.</span></span> <span data-ttu-id="442fa-197">이 전략은 데이터 관리가 쉽습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-197">This strategy offers easier data management.</span></span> <span data-ttu-id="442fa-198">예를 들어 같은 지역의 사용자가 같은 분할된 데이터베이스에 있을 경우 로컬 부하 및 요구 패턴에 따라 각 표준 시간대에 업데이트를 예약할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-198">For example, if users in the same region are in the same shard, updates can be scheduled in each time zone based on the local load and demand pattern.</span></span> <span data-ttu-id="442fa-199">그러나 이 전략은 분할된 데이터베이스 간에 최적의 균형을 제공하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-199">However, this strategy doesn't provide optimal balancing between shards.</span></span> <span data-ttu-id="442fa-200">분할된 데이터베이스의 리밸러싱은 어려우며 대부분의 작업이 인접 분할 키에 관한 것일 경우 불균등한 부하 문제를 해결할 수 없을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-200">Rebalancing shards is difficult and might not resolve the problem of uneven load if the majority of activity is for adjacent shard keys.</span></span>

- <span data-ttu-id="442fa-201">**해시**.</span><span class="sxs-lookup"><span data-stu-id="442fa-201">**Hash**.</span></span> <span data-ttu-id="442fa-202">이 전략은 데이터 및 부하를 보다 균등하게 분산할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-202">This strategy offers a better chance of more even data and load distribution.</span></span> <span data-ttu-id="442fa-203">해시 함수를 사용하여 직접 요청 라우팅을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-203">Request routing can be accomplished directly by using the hash function.</span></span> <span data-ttu-id="442fa-204">맵을 유지 관리할 필요가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-204">There's no need to maintain a map.</span></span> <span data-ttu-id="442fa-205">해시 계산으로 추가적인 오버헤드가 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-205">Note that computing the hash might impose an additional overhead.</span></span> <span data-ttu-id="442fa-206">또한 분할된 데이터베이스의 리밸러싱이 어렵습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-206">Also, rebalancing shards is difficult.</span></span>

<span data-ttu-id="442fa-207">가장 일반적인 분할 시스템은 위에서 설명한 접근 방식 중 하나를 구현하는 것이지만 애플리케이션의 비즈니스 요구 사항과 데이터 사용량 패턴도 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-207">Most common sharding systems implement one of the approaches described above, but you should also consider the business requirements of your applications and their patterns of data usage.</span></span> <span data-ttu-id="442fa-208">예를 들어 다중 테넌트 애플리케이션에서 다음을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-208">For example, in a multi-tenant application:</span></span>

- <span data-ttu-id="442fa-209">워크로드를 기반으로 데이터를 분할할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-209">You can shard data based on workload.</span></span> <span data-ttu-id="442fa-210">별도의 분할된 데이터베이스에서 고휘발성 테넌트에 대한 데이터를 분리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-210">You could segregate the data for highly volatile tenants in separate shards.</span></span> <span data-ttu-id="442fa-211">결과적으로 다른 테넌트에 대한 데이터 액세스 속도가 개선될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-211">The speed of data access for other tenants might be improved as a result.</span></span>

- <span data-ttu-id="442fa-212">테넌트 위치를 기반으로 데이터를 분할할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-212">You can shard data based on the location of tenants.</span></span> <span data-ttu-id="442fa-213">백업 및 유지 관리를 위해 특정 지역의 테넌트 데이터를 해당 지역에서 사용량이 적은 시간에 오프라인으로 가져올 수 있는 반면, 다른 지역의 테넌트 데이터는 온라인으로 유지되며 업무 시간에 액세스할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-213">You can take the data for tenants in a specific geographic region offline for backup and maintenance during off-peak hours in that region, while the data for tenants in other regions remains online and accessible during their business hours.</span></span>

- <span data-ttu-id="442fa-214">중요한 테넌트는 개인 소유의 부하가 낮은 고성능 분할된 데이터베이스에 할당될 수 있는 반면, 그렇지 않은 테넌트는 더 밀집되고 사용량이 많은 분할된 데이터베이스를 공유하게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-214">High-value tenants could be assigned their own private, high performing, lightly loaded shards, whereas lower-value tenants might be expected to share more densely-packed, busy shards.</span></span>

- <span data-ttu-id="442fa-215">고도의 데이터 격리 및 개인정보보호가 필요한 테넌트 데이터는 완전히 분리된 서버에 저장할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-215">The data for tenants that need a high degree of data isolation and privacy can be stored on a completely separate server.</span></span>

## <a name="scaling-and-data-movement-operations"></a><span data-ttu-id="442fa-216">크기 조정 및 데이터 이동 작업</span><span class="sxs-lookup"><span data-stu-id="442fa-216">Scaling and data movement operations</span></span>

<span data-ttu-id="442fa-217">각 분할 전략은 규모 축소, 규모 확장, 데이터 이동을 관리하고 상태를 유지 관리하기 위한 다양한 기능과 복잡도를 의미합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-217">Each of the sharding strategies implies different capabilities and levels of complexity for managing scale in, scale out, data movement, and maintaining state.</span></span>

<span data-ttu-id="442fa-218">조회 전략은 온라인 또는 오프라인으로 사용자 수준에서 수행될 수 있도록 크기 조정 및 데이터 이동 작업을 허용합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-218">The Lookup strategy permits scaling and data movement operations to be carried out at the user level, either online or offline.</span></span> <span data-ttu-id="442fa-219">이 기술을 사용하면 사용량이 많지 않을 때 일부 또는 모든 사용자 작업을 일시 중단하고, 데이터를 새로운 가상 파티션이나 물리적 분할된 데이터베이스로 이동하고, 매핑을 변경하고, 이 데이터를 보관하는 캐시를 무효화하거나 새로 고친 다음 사용자 활동을 다시 시작할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-219">The technique is to suspend some or all user activity (perhaps during off-peak periods), move the data to the new virtual partition or physical shard, change the mappings, invalidate or refresh any caches that hold this data, and then allow user activity to resume.</span></span> <span data-ttu-id="442fa-220">보통 이 작업 유형은 중앙에서 관리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-220">Often this type of operation can be centrally managed.</span></span> <span data-ttu-id="442fa-221">조회 전략은 캐시가 원활하고 복제하기 쉬운 상태여야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-221">The Lookup strategy requires state to be highly cacheable and replica friendly.</span></span>

<span data-ttu-id="442fa-222">범위 전략은 크기 조정 및 데이터 이동 작업 시 일부 제한이 있습니다. 분할된 데이터베이스에서 데이터가 분할 및 병합되기 때문에 일반적으로 일부 또는 모든 데이터 저장소가 오프라인일 때 수행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-222">The Range strategy imposes some limitations on scaling and data movement operations, which must typically be carried out when a part or all of the data store is offline because the data must be split and merged across the shards.</span></span> <span data-ttu-id="442fa-223">대부분의 작업이 인접 분할 키 또는 같은 범위 내에 있는 데이터 식별자에 관한 것일 경우 데이터를 이동하여 분할된 데이터베이스 리밸러스로 불균등한 부하 문제를 해결할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-223">Moving the data to rebalance shards might not resolve the problem of uneven load if the majority of activity is for adjacent shard keys or data identifiers that are within the same range.</span></span> <span data-ttu-id="442fa-224">범위 전략은 범위를 물리적 파티션에 매핑하기 위해 일부 상태를 유지 관리해야 할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-224">The Range strategy might also require some state to be maintained in order to map ranges to the physical partitions.</span></span>

<span data-ttu-id="442fa-225">파티션 키는 분할 키 또는 데이터 식별자의 해시이므로 해시 전략은 크기 조정 및 데이터 이동 작업을 더 복잡하게 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-225">The Hash strategy makes scaling and data movement operations more complex because the partition keys are hashes of the shard keys or data identifiers.</span></span> <span data-ttu-id="442fa-226">해시 함수 또는 정확한 매핑을 제공하도록 수정된 함수에서 각 분할된 데이터베이스의 새로운 위치를 결정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-226">The new location of each shard must be determined from the hash function, or the function modified to provide the correct mappings.</span></span> <span data-ttu-id="442fa-227">그러나 해시 전략은 상태 유지 관리가 필요하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-227">However, the Hash strategy doesn't require maintenance of state.</span></span>

## <a name="issues-and-considerations"></a><span data-ttu-id="442fa-228">문제 및 고려 사항</span><span class="sxs-lookup"><span data-stu-id="442fa-228">Issues and considerations</span></span>

<span data-ttu-id="442fa-229">이 패턴을 구현할 방법을 결정할 때 다음 사항을 고려하세요.</span><span class="sxs-lookup"><span data-stu-id="442fa-229">Consider the following points when deciding how to implement this pattern:</span></span>

- <span data-ttu-id="442fa-230">분할은 수직 분할, 기능 분할 등 기타 형태의 분할을 보완합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-230">Sharding is complementary to other forms of partitioning, such as vertical partitioning and functional partitioning.</span></span> <span data-ttu-id="442fa-231">예를 들어 단일 분할된 데이터베이스는 수직으로 분할된 엔터티를 포함할 수 있고, 기능 파티션은 다중 분할된 데이터베이스로 구현할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-231">For example, a single shard can contain entities that have been partitioned vertically, and a functional partition can be implemented as multiple shards.</span></span> <span data-ttu-id="442fa-232">분할에 대한 자세한 내용은 [데이터 분할 지침](https://msdn.microsoft.com/library/dn589795.aspx)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="442fa-232">For more information about partitioning, see the [Data Partitioning Guidance](https://msdn.microsoft.com/library/dn589795.aspx).</span></span>

- <span data-ttu-id="442fa-233">분할된 데이터베이스가 모두 비슷한 양의 I/O를 처리할 수 있도록 균형이 조정된 상태를 유지합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-233">Keep shards balanced so they all handle a similar volume of I/O.</span></span> <span data-ttu-id="442fa-234">데이터가 삽입되고 삭제되면 균등한 분산을 보장하고 핫스폿 가능성을 줄이기 위해 주기적으로 분할된 데이터베이스를 리밸러스해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-234">As data is inserted and deleted, it's necessary to periodically rebalance the shards to guarantee an even distribution and to reduce the chance of hotspots.</span></span> <span data-ttu-id="442fa-235">리밸러싱은 비용 부담이 큰 작업일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-235">Rebalancing can be an expensive operation.</span></span> <span data-ttu-id="442fa-236">리밸러싱의 필요성을 줄이려면 각 분할된 데이터베이스에 예상되는 변동량을 충분히 처리할 사용 가능한 공간을 포함하여 변동량 증가에 대비합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-236">To reduce the necessity of rebalancing, plan for growth by ensuring that each shard contains sufficient free space to handle the expected volume of changes.</span></span> <span data-ttu-id="442fa-237">또한 분할된 데이터베이스를 리밸러스해야 할 경우에 신속히 조정하는 데 사용할 수 있는 전략 및 스크립트를 개발해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-237">You should also develop strategies and scripts you can use to quickly rebalance shards if this becomes necessary.</span></span>

- <span data-ttu-id="442fa-238">분할 키에 대한 안정적인 데이터를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-238">Use stable data for the shard key.</span></span> <span data-ttu-id="442fa-239">분할 키가 변경되면 해당 데이터 항목은 분할된 데이터베이스 간에 이동해야 하고 이때 업데이트 작업에 의해 수행되는 작업량이 늘어날 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-239">If the shard key changes, the corresponding data item might have to move between shards, increasing the amount of work performed by update operations.</span></span> <span data-ttu-id="442fa-240">따라서 분할 키가 잠재적 휘발성 정보를 기반으로 하지 않도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-240">For this reason, avoid basing the shard key on potentially volatile information.</span></span> <span data-ttu-id="442fa-241">대신 고정적이거나 자연스럽게 키를 만드는 특성을 찾습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-241">Instead, look for attributes that are invariant or that naturally form a key.</span></span>

- <span data-ttu-id="442fa-242">분할 키가 고유한지 확인합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-242">Ensure that shard keys are unique.</span></span> <span data-ttu-id="442fa-243">예를 들어 자동 증가 필드는 분할 키로 사용하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-243">For example, avoid using autoincrementing fields as the shard key.</span></span> <span data-ttu-id="442fa-244">일부 시스템에서 자동 증가된 필드는 분할된 데이터베이스 간에 조정될 수 없으므로 다른 분할된 데이터베이스에 있는 항목이 같은 분할 키를 가지게 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-244">Is some systems, autoincremented fields can't be coordinated across shards, possibly resulting in items in different shards having the same shard key.</span></span>

    >  <span data-ttu-id="442fa-245">분할 키가 아닌 다른 필드의 자동 증가 값 또한 문제를 일으킬 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-245">Autoincremented values in other fields that are not shard keys can also cause problems.</span></span> <span data-ttu-id="442fa-246">예를 들어 자동 증가된 필드를 사용하여 고유한 ID를 생성할 경우 다른 분할된 데이터베이스에 있는 다른 두 항목에 같은 ID가 지정될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-246">For example, if you use autoincremented fields to generate unique IDs, then two different items located in different shards might be assigned the same ID.</span></span>

- <span data-ttu-id="442fa-247">데이터에 대해 가능한 모든 쿼리의 요구 사항과 일치하는 분할 키를 디자인하는 것은 불가능할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-247">It might not be possible to design a shard key that matches the requirements of every possible query against the data.</span></span> <span data-ttu-id="442fa-248">데이터를 분할하여 가장 빈번히 수행되는 쿼리를 지원하고, 필요한 경우 보조 인덱스 테이블을 만들어 분할 키에 속하지 않는 특성을 기반으로 하는 조건을 사용하여 데이터를 검색하는 쿼리를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-248">Shard the data to support the most frequently performed queries, and if necessary create secondary index tables to support queries that retrieve data using criteria based on attributes that aren't part of the shard key.</span></span> <span data-ttu-id="442fa-249">자세한 내용은 [인덱스 테이블 패턴](index-table.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="442fa-249">For more information, see the [Index Table pattern](index-table.md).</span></span>

- <span data-ttu-id="442fa-250">단일 분할된 데이터베이스만 액세스하는 쿼리가 여러 분할된 데이터베이스에서 데이터를 검색하는 쿼리보다 효율적이므로 애플리케이션이 다른 분할된 데이터베이스에 저장된 데이터를 조인하는 다수의 쿼리를 수행하도록 하는 분할 시스템은 구현하지 않도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-250">Queries that access only a single shard are more efficient than those that retrieve data from multiple shards, so avoid implementing a sharding system that results in applications performing large numbers of queries that join data held in different shards.</span></span> <span data-ttu-id="442fa-251">단일 분할된 데이터베이스는 여러 엔터티 유형의 데이터를 포함할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-251">Remember that a single shard can contain the data for multiple types of entities.</span></span> <span data-ttu-id="442fa-252">애플리케이션이 별도로 수행하는 읽기 횟수를 줄이려면 데이터를 비정규화하여 일반적으로 함께 쿼리되는 관련 엔터티(고객 및 주문 세부 사항 등)를 같은 분할된 데이터베이스에 보관하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-252">Consider denormalizing your data to keep related entities that are commonly queried together (such as the details of customers and the orders that they have placed) in the same shard to reduce the number of separate reads that an application performs.</span></span>

    >  <span data-ttu-id="442fa-253">하나의 분할된 데이터베이스에 있는 엔터티가 다른 분할된 데이터베이스에 저장된 엔터티를 참조할 경우 두 번째 엔터티에 대한 분할 키를 첫 번째 엔터티에 대한 스키마의 일부로 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-253">If an entity in one shard references an entity stored in another shard, include the shard key for the second entity as part of the schema for the first entity.</span></span> <span data-ttu-id="442fa-254">이렇게 하면 분할된 데이터베이스에서 관련 데이터를 참조하는 쿼리 성능을 개선할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-254">This can help to improve the performance of queries that reference related data across shards.</span></span>

- <span data-ttu-id="442fa-255">애플리케이션이 여러 분할된 데이터베이스에서 데이터를 검색하는 쿼리를 수행해야 할 경우 병렬 작업을 사용하여 이 데이터를 가져올 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-255">If an application must perform queries that retrieve data from multiple shards, it might be possible to fetch this data by using parallel tasks.</span></span> <span data-ttu-id="442fa-256">예를 들어 팬아웃 쿼리의 경우 여러 분할된 데이터베이스의 데이터를 병렬로 검색한 다음 단일 결과로 집계합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-256">Examples include fan-out queries, where data from multiple shards is retrieved in parallel and then aggregated into a single result.</span></span> <span data-ttu-id="442fa-257">그러나 이 접근 방식을 사용하면 불가피하게 솔루션의 데이터 액세스 논리가 좀 더 복잡해집니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-257">However, this approach inevitably adds some complexity to the data access logic of a solution.</span></span>

- <span data-ttu-id="442fa-258">대부분의 애플리케이션에서 다수의 소규모 분할된 데이터베이스를 만드는 것이 소수의 대규모 분할된 데이터베이스보다 더 효율적일 수 있는데, 이는 부하 분산이 더 용이하기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-258">For many applications, creating a larger number of small shards can be more efficient than having a small number of large shards because they can offer increased opportunities for load balancing.</span></span> <span data-ttu-id="442fa-259">또한 분할된 데이터베이스를 한 물리적 위치에서 다른 물리적 위치로 마이그레이션할 필요성이 예상될 경우에도 유용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-259">This can also be useful if you anticipate the need to migrate shards from one physical location to another.</span></span> <span data-ttu-id="442fa-260">작은 분할된 데이터베이스를 이동하는 것이 큰 분할된 데이터베이스 이동보다 빠릅니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-260">Moving a small shard is quicker than moving a large one.</span></span>

- <span data-ttu-id="442fa-261">각 분할 저장소 노드에 사용할 수 있는 리소스가 데이터 크기 및 처리량 관점에서 확장성 요구 사항을 충분히 처리할 수 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-261">Make sure the resources available to each shard storage node are sufficient to handle the scalability requirements in terms of data size and throughput.</span></span> <span data-ttu-id="442fa-262">자세한 내용은 [데이터 분할 지침](https://msdn.microsoft.com/library/dn589795.aspx)의 "확장성을 위한 파티션 디자인" 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="442fa-262">For more information, see the section “Designing Partitions for Scalability” in the [Data Partitioning Guidance](https://msdn.microsoft.com/library/dn589795.aspx).</span></span>

- <span data-ttu-id="442fa-263">모든 분할된 데이터베이스에 참조 데이터를 복제할 것을 고려합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-263">Consider replicating reference data to all shards.</span></span> <span data-ttu-id="442fa-264">분할된 데이터베이스에서 데이터를 검색하는 작업이 동일한 쿼리의 일부로 정적 또는 느리게 이동하는 데이터도 참조할 경우 이 데이터를 분할된 데이터베이스에 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-264">If an operation that retrieves data from a shard also references static or slow-moving data as part of the same query, add this data to the shard.</span></span> <span data-ttu-id="442fa-265">이렇게 하면 애플리케이션은 별도의 데이터 저장소를 추가로 왕복하지 않고 쿼리의 모든 데이터를 쉽게 가져올 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-265">The application can then fetch all of the data for the query easily, without having to make an additional round trip to a separate data store.</span></span>

    >  <span data-ttu-id="442fa-266">여러 분할된 데이터베이스에 보관된 참조 데이터가 변경되면 시스템은 모든 분할된 데이터베이스 간에 이 변경 내용을 동기화해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-266">If reference data held in multiple shards changes, the system must synchronize these changes across all shards.</span></span> <span data-ttu-id="442fa-267">이 동기화가 진행되는 동안 시스템에서 어느 정도의 불일치가 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-267">The system can experience a degree of inconsistency while this synchronization occurs.</span></span> <span data-ttu-id="442fa-268">동기화를 수행하려면 애플리케이션이 이를 처리할 수 있도록 디자인해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-268">If you do this, you should design your applications to be able to handle it.</span></span>

- <span data-ttu-id="442fa-269">분할된 데이터베이스 간에 참조 무결성 및 일관성을 유지하기 어려울 수 있으므로 여러 분할된 데이터베이스에 있는 데이터에 영향을 주는 작업을 최소화해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-269">It can be difficult to maintain referential integrity and consistency between shards, so you should minimize operations that affect data in multiple shards.</span></span> <span data-ttu-id="442fa-270">애플리케이션이 분할된 데이터베이스에서 데이터를 수정해야 하는 경우 완벽한 데이터 일관성이 실제로 필요한지 여부를 평가합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-270">If an application must modify data across shards, evaluate whether complete data consistency is actually required.</span></span> <span data-ttu-id="442fa-271">일반적으로 클라우드에서는 강력한 일관성 대신 최종 일관성을 구현합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-271">Instead, a common approach in the cloud is to implement eventual consistency.</span></span> <span data-ttu-id="442fa-272">각 파티션에 있는 데이터가 개별적으로 업데이트되고, 애플리케이션 논리를 사용하여 업데이트를 모두 성공적으로 완료할 수 있도록 하며, 최종적으로 일치하는 작업이 실행되는 동안 데이터 쿼리에서 발생할 수 있는 불일치를 처리해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-272">The data in each partition is updated separately, and the application logic must take responsibility for ensuring that the updates all complete successfully, as well as handling the inconsistencies that can arise from querying data while an eventually consistent operation is running.</span></span> <span data-ttu-id="442fa-273">최종 일관성을 구현하는 방법에 대한 자세한 내용은 [데이터 일관성 입문서](https://msdn.microsoft.com/library/dn589800.aspx)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="442fa-273">For more information about implementing eventual consistency, see the [Data Consistency Primer](https://msdn.microsoft.com/library/dn589800.aspx).</span></span>

- <span data-ttu-id="442fa-274">다수의 분할된 데이터베이스를 구성하고 관리하는 작업은 어려울 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-274">Configuring and managing a large number of shards can be a challenge.</span></span> <span data-ttu-id="442fa-275">모니터링, 백업, 일관성 확인, 로깅 또는 감사 등의 작업은 여러 지역에 있을 수 있는 여러 개의 분할된 데이터베이스 및 서버에서 수행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-275">Tasks such as monitoring, backing up, checking for consistency, and logging or auditing must be accomplished on multiple shards and servers, possibly held in multiple locations.</span></span> <span data-ttu-id="442fa-276">이러한 작업은 스크립트나 다른 자동화 솔루션으로 구현되기 쉽지만 추가적인 관리 요구 사항을 완전히 없애지는 못할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-276">These tasks are likely to be implemented using scripts or other automation solutions, but that might not completely eliminate the additional administrative requirements.</span></span>

- <span data-ttu-id="442fa-277">분할된 데이터베이스를 여기에 포함된 데이터가 이 데이터를 사용하는 애플리케이션 인스턴스에 가깝게 위치하도록 배치할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-277">Shards can be geolocated so that the data that they contain is close to the instances of an application that use it.</span></span> <span data-ttu-id="442fa-278">이 접근 방식은 성능을 크게 개선할 수 있지만, 다른 위치에서 여러 분할된 데이터베이스에 액세스해야 하는 작업도 추가로 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-278">This approach can considerably improve performance, but requires additional consideration for tasks that must access multiple shards in different locations.</span></span>

## <a name="when-to-use-this-pattern"></a><span data-ttu-id="442fa-279">이 패턴을 사용해야 하는 경우</span><span class="sxs-lookup"><span data-stu-id="442fa-279">When to use this pattern</span></span>

<span data-ttu-id="442fa-280">데이터 저장소를 단일 저장소 노드에서 사용 가능한 리소스 이상으로 크기를 조정할 필요가 있거나 데이터 저장소에서 경합을 줄여 성능을 개선해야 할 필요가 있을 경우 이 패턴을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-280">Use this pattern when a data store is likely to need to scale beyond the resources available to a single storage node, or to improve performance by reducing contention in a data store.</span></span>

>  <span data-ttu-id="442fa-281">분할의 주안점은 시스템의 성능 및 확장성을 개선하는 것이지만 부가적으로 데이터가 별도의 파티션으로 어떻게 분할되느냐에 따라 가용성을 개선할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-281">The primary focus of sharding is to improve the performance and scalability of a system, but as a by-product it can also improve availability due to how the data is divided into separate partitions.</span></span> <span data-ttu-id="442fa-282">한 파티션에서 오류가 발생했다고 해서 반드시 애플리케이션이 다른 파티션에 보관된 데이터에 액세스할 수 없는 것은 아니며, 운영자는 애플리케이션의 전체 데이터를 액세스 불가로 만들지 않고 하나 이상의 파티션을 유지 관리하거나 복구할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-282">A failure in one partition doesn't necessarily prevent an application from accessing data held in other partitions, and an operator can perform maintenance or recovery of one or more partitions without making the entire data for an application inaccessible.</span></span> <span data-ttu-id="442fa-283">자세한 내용은 [데이터 분할 지침](https://msdn.microsoft.com/library/dn589795.aspx)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="442fa-283">For more information, see the [Data Partitioning Guidance](https://msdn.microsoft.com/library/dn589795.aspx).</span></span>

## <a name="example"></a><span data-ttu-id="442fa-284">예</span><span class="sxs-lookup"><span data-stu-id="442fa-284">Example</span></span>

<span data-ttu-id="442fa-285">C#으로 작성된 다음 예제는 분할된 데이터베이스 역할을 하는 SQL Server 데이터베이스 집합을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-285">The following example in C# uses a set of SQL Server databases acting as shards.</span></span> <span data-ttu-id="442fa-286">각 데이터베이스에는 애플리케이션에서 사용된 데이터의 하위 집합이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-286">Each database holds a subset of the data used by an application.</span></span> <span data-ttu-id="442fa-287">애플리케이션은 자체 분할 논리(팬아웃 쿼리의 예)를 사용하여 분할된 데이터베이스에서 분산된 데이터를 검색합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-287">The application retrieves data that's distributed across the shards using its own sharding logic (this is an example of a fan-out query).</span></span> <span data-ttu-id="442fa-288">각 분할된 데이터베이스에 위치한 데이터의 세부 사항은 `GetShards`라는 메서드에 의해 반환됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-288">The details of the data that's located in each shard is returned by a method called `GetShards`.</span></span> <span data-ttu-id="442fa-289">이 메서드는 `ShardInformation` 개체의 열거 목록을 반환하는데, 여기서 `ShardInformation` 형식에는 각 분할된 데이터베이스의 식별자 및 애플리케이션이 분할된 데이터베이스 연결에 사용해야 하는 SQL Server 연결 문자열이 포함됩니다(연결 문자열은 코드 예제에 표시되지 않음).</span><span class="sxs-lookup"><span data-stu-id="442fa-289">This method returns an enumerable list of `ShardInformation` objects, where the `ShardInformation` type contains an identifier for each shard and the SQL Server connection string that an application should use to connect to the shard (the connection strings aren't shown in the code example).</span></span>

```csharp
private IEnumerable<ShardInformation> GetShards()
{
  // This retrieves the connection information from a shard store
  // (commonly a root database).
  return new[]
  {
    new ShardInformation
    {
      Id = 1,
      ConnectionString = ...
    },
    new ShardInformation
    {
      Id = 2,
      ConnectionString = ...
    }
  };
}
```

<span data-ttu-id="442fa-290">다음 코드는 애플리케이션에서 `ShardInformation` 개체 목록을 사용하여 각 분할된 데이터베이스에서 병렬로 데이터를 가져오는 쿼리를 수행하는 방법을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-290">The code below shows how the application uses the list of `ShardInformation` objects to perform a query that fetches data from each shard in parallel.</span></span> <span data-ttu-id="442fa-291">자세한 쿼리는 표시되어 있지 않지만, 이 예제에서 검색된 데이터에는 분할된 데이터베이스에 고객의 세부 정보가 포함된 경우 고객 이름 등의 정보를 보관할 수 있는 문자열이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-291">The details of the query aren't shown, but in this example the data that's retrieved contains a string that could hold information such as the name of a customer if the shards contain the details of customers.</span></span> <span data-ttu-id="442fa-292">결과는 애플리케이션에서 처리하기 위해 `ConcurrentBag` 컬렉션으로 집계됩니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-292">The results are aggregated into a `ConcurrentBag` collection for processing by the application.</span></span>

```csharp
// Retrieve the shards as a ShardInformation[] instance.
var shards = GetShards();

var results = new ConcurrentBag<string>();

// Execute the query against each shard in the shard list.
// This list would typically be retrieved from configuration
// or from a root/master shard store.
Parallel.ForEach(shards, shard =>
{
  // NOTE: Transient fault handling isn't included,
  // but should be incorporated when used in a real world application.
  using (var con = new SqlConnection(shard.ConnectionString))
  {
    con.Open();
    var cmd = new SqlCommand("SELECT ... FROM ...", con);

    Trace.TraceInformation("Executing command against shard: {0}", shard.Id);

    var reader = cmd.ExecuteReader();
    // Read the results in to a thread-safe data structure.
    while (reader.Read())
    {
      results.Add(reader.GetString(0));
    }
  }
});

Trace.TraceInformation("Fanout query complete - Record Count: {0}",
                        results.Count);
```

## <a name="related-patterns-and-guidance"></a><span data-ttu-id="442fa-293">관련 패턴 및 지침</span><span class="sxs-lookup"><span data-stu-id="442fa-293">Related patterns and guidance</span></span>

<span data-ttu-id="442fa-294">이 패턴을 구현할 때 다음 패턴 및 지침도 관련이 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-294">The following patterns and guidance might also be relevant when implementing this pattern:</span></span>
- <span data-ttu-id="442fa-295">[Data Consistency Primer](https://msdn.microsoft.com/library/dn589800.aspx)(데이터 일관성 입문서).</span><span class="sxs-lookup"><span data-stu-id="442fa-295">[Data Consistency Primer](https://msdn.microsoft.com/library/dn589800.aspx).</span></span> <span data-ttu-id="442fa-296">서로 다른 분할된 데이터베이스 간에 분산된 데이터의 일관성을 유지해야 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-296">It might be necessary to maintain consistency for data distributed across different shards.</span></span> <span data-ttu-id="442fa-297">분산된 데이터의 일관성 유지 관리와 관련된 문제를 요약하고 다양한 일관성 모델의 장점과 단점을 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-297">Summarizes the issues surrounding maintaining consistency over distributed data, and describes the benefits and tradeoffs of different consistency models.</span></span>
- <span data-ttu-id="442fa-298">[데이터 분할 지침](https://msdn.microsoft.com/library/dn589795.aspx).</span><span class="sxs-lookup"><span data-stu-id="442fa-298">[Data Partitioning Guidance](https://msdn.microsoft.com/library/dn589795.aspx).</span></span> <span data-ttu-id="442fa-299">데이터 저장소 분할에 다양한 문제가 추가로 제기될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-299">Sharding a data store can introduce a range of additional issues.</span></span> <span data-ttu-id="442fa-300">확장성을 개선하고, 경합을 줄이고, 성능을 최적화하기 위해 클라우드의 데이터 저장소 분할과 관련된 이러한 문제에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-300">Describes these issues in relation to partitioning data stores in the cloud to improve scalability, reduce contention, and optimize performance.</span></span>
- <span data-ttu-id="442fa-301">[인덱스 테이블 패턴](index-table.md).</span><span class="sxs-lookup"><span data-stu-id="442fa-301">[Index Table pattern](index-table.md).</span></span> <span data-ttu-id="442fa-302">분할 키 디자인만으로 쿼리를 완전히 지원할 수 없는 경우가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-302">Sometimes it isn't possible to completely support queries just through the design of the shard key.</span></span> <span data-ttu-id="442fa-303">애플리케이션에서 분할 키 이외의 키를 지정하여 대규모 데이터 저장소에서 데이터를 빠르게 검색할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-303">Enables an application to quickly retrieve data from a large data store by specifying a key other than the shard key.</span></span>
- <span data-ttu-id="442fa-304">[구체화된 뷰 패턴](materialized-view.md).</span><span class="sxs-lookup"><span data-stu-id="442fa-304">[Materialized View pattern](materialized-view.md).</span></span> <span data-ttu-id="442fa-305">일부 쿼리 작업의 성능을 유지 관리하려면 데이터를 집계하고 요약하는 구체화된 뷰를 만드는 것이 유용합니다. 이 요약 데이터가 분할된 데이터베이스 간에 분산된 정보를 기반으로 할 경우에 특히 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-305">To maintain the performance of some query operations, it's useful to create materialized views that aggregate and summarize data, especially if this summary data is based on information that's distributed across shards.</span></span> <span data-ttu-id="442fa-306">이러한 뷰를 생성하고 채우는 방법에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="442fa-306">Describes how to generate and populate these views.</span></span>
