---
title: R 기계 학습 모델의 실시간 채점
description: AKS(Azure Kubernetes Service)에서 실행되는 Machine Learning Server를 사용하여 R에서 실시간 예측 서비스를 구현합니다.
author: njray
ms.date: 12/12/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 00bea3cae0c3d2f0fea2babd7b0157382cf9890a
ms.sourcegitcommit: 1b50810208354577b00e89e5c031b774b02736e2
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 01/23/2019
ms.locfileid: "54487171"
---
# <a name="real-time-scoring-of-r-machine-learning-models"></a><span data-ttu-id="30efe-103">R 기계 학습 모델의 실시간 채점</span><span class="sxs-lookup"><span data-stu-id="30efe-103">Real-time scoring of R machine learning models</span></span>

<span data-ttu-id="30efe-104">이 참조 아키텍처는 AKS(Azure Kubernetes Service)에서 실행되는 Microsoft Machine Learning Server를 사용하여 R에서 실시간(동기) 예측 서비스를 구현하는 방법을 보여줍니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-104">This reference architecture shows how to implement a real-time (synchronous) prediction service in R using Microsoft Machine Learning Server running in Azure Kubernetes Service (AKS).</span></span> <span data-ttu-id="30efe-105">이 아키텍처는 실시간 서비스로 배포할 목적으로 R에서 빌드한 예측 모델에 일반적으로 사용할 수 있도록 제작되었습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-105">This architecture is intended to be generic and suited for any predictive model built in R that you want to deploy as a real-time service.</span></span> <span data-ttu-id="30efe-106">**[이 솔루션을 배포하세요][github]**.</span><span class="sxs-lookup"><span data-stu-id="30efe-106">**[Deploy this solution][github]**.</span></span>

## <a name="architecture"></a><span data-ttu-id="30efe-107">아키텍처</span><span class="sxs-lookup"><span data-stu-id="30efe-107">Architecture</span></span>

![Azure 기반 R 기계 학습 모델의 실시간 채점][0]

<span data-ttu-id="30efe-109">이 참조 아키텍처는 컨테이너 기반 접근 방식을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-109">This reference architecture takes a container-based approach.</span></span> <span data-ttu-id="30efe-110">R 및 새 데이터를 채점하는 데 필요한 다양한 아티팩트를 포함하는 Docker 이미지가 빌드됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-110">A Docker image is built containing R, as well as the various artifacts needed to score new data.</span></span> <span data-ttu-id="30efe-111">여기에는 모델 개체 자체와 채점 스크립트가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-111">These include the model object itself and a scoring script.</span></span> <span data-ttu-id="30efe-112">이 이미지는 Azure에 호스트되는 Docker 레지스트리로 푸시된 다음, Azure에서도 Kubernetes 클러스터에 배포됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-112">This image is pushed to a Docker registry hosted in Azure, and then deployed to a Kubernetes cluster, also in Azure.</span></span>

<span data-ttu-id="30efe-113">이 워크플로의 아키텍처는 다음 구성 요소를 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-113">The architecture of this workflow includes the following components.</span></span>

- <span data-ttu-id="30efe-114">**[Azure Container Registry][acr]** 는 이 워크플로의 이미지를 저장하는 데 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-114">**[Azure Container Registry][acr]** is used to store the images for this workflow.</span></span> <span data-ttu-id="30efe-115">Container Registry를 사용하여 만든 레지스트리는 [Docker 레지스트리 V2 API][docker] 및 클라이언트를 통해 관리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-115">Registries created with Container Registry can be managed via the standard [Docker Registry V2 API][docker] and client.</span></span>

- <span data-ttu-id="30efe-116">**[Azure Kubernetes Service][aks]** 는 배포 및 서비스를 호스트하는 데 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-116">**[Azure Kubernetes Service][aks]** is used to host the deployment and service.</span></span> <span data-ttu-id="30efe-117">AKS를 사용하여 만든 클러스터는 표준 [Kubernetes API][k-api] 및 클라이언트(kubectl)를 사용하여 관리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-117">Clusters created with AKS can be managed using the standard [Kubernetes API][k-api] and client (kubectl).</span></span>

- <span data-ttu-id="30efe-118">**[Microsoft Machine Learning Server][mmls]** 는 서비스용 REST API를 정의하는 데 사용되며 [모델 운영화][operationalization]를 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-118">**[Microsoft Machine Learning Server][mmls]** is used to define the REST API for the service and includes [Model Operationalization][operationalization].</span></span> <span data-ttu-id="30efe-119">이 서비스 지향 웹 서버 프로세스는 요청을 수신 대기하며, 결과를 생성하는 실제 R 코드를 실행하는 다른 백그라운드 프로세스에 전달됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-119">This service-oriented web server process listens for requests, which are then handed off to other background processes that run the actual R code to generate the results.</span></span> <span data-ttu-id="30efe-120">이 모든 프로세스는 이 구성의 단일 노드에서 실행되고, 컨테이너에 래핑됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-120">All these processes run on a single node in this configuration, which is wrapped in a container.</span></span> <span data-ttu-id="30efe-121">개발 또는 테스트 환경 외부에서 이 서비스를 사용하는 방법에 대한 자세한 내용은 Microsoft 담당자에게 문의하세요.</span><span class="sxs-lookup"><span data-stu-id="30efe-121">For details about using this service outside a dev or test environment, contact your Microsoft representative.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="30efe-122">성능 고려 사항</span><span class="sxs-lookup"><span data-stu-id="30efe-122">Performance considerations</span></span>

<span data-ttu-id="30efe-123">기계 학습 워크로드는 새 데이터를 학습하고 채점할 때 컴퓨팅 집약적인 경향이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-123">Machine learning workloads tend to be compute-intensive, both when training and when scoring new data.</span></span> <span data-ttu-id="30efe-124">경험에 비춰보면, 채점 프로세스를 코어당 하나만 실행하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-124">As a rule of thumb, try not to run more than one scoring process per core.</span></span> <span data-ttu-id="30efe-125">Machine Learning Server를 통해 각 컨테이너에서 실행되는 R 프로세스의 수를 정의할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-125">Machine Learning Server lets you define the number of R processes running in each container.</span></span> <span data-ttu-id="30efe-126">기본값은 프로세스 5개입니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-126">The default is five processes.</span></span> <span data-ttu-id="30efe-127">변수가 많지 않은 선형 회귀처럼 비교적 간단한 모델 또는 소형 의사 결정 트리를 만들 때에는 프로세스 수를 늘려도 됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-127">When creating a relatively simple model, such as a linear regression with a small number of variables, or a small decision tree, you can increase the number of processes.</span></span> <span data-ttu-id="30efe-128">클러스터 노드의 CPU 로드를 모니터링하여 컨테이너 수를 적절하게 제한할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-128">Monitor the CPU load on your cluster nodes to determine the appropriate limit on the number of containers.</span></span>

<span data-ttu-id="30efe-129">GPU 지원 클러스터는 일부 워크로드 유형, 특히 딥러닝 모델의 속도를 높일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-129">A GPU-enabled cluster can speed up some types of workloads, and deep learning models in particular.</span></span> <span data-ttu-id="30efe-130">모든 워크로드가 GPU를 활용할 수 있는 것은 아니고, 행렬 대수를 많이 사용하는 워크로드만 활용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-130">Not all workloads can take advantage of GPUs &mdash; only those that make heavy use of matrix algebra.</span></span> <span data-ttu-id="30efe-131">예를 들어 임의 포리스트 및 부스팅 모델을 비롯한 트리 기반 모델은 일반적으로 GPU에서 아무런 이점도 얻을 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-131">For example, tree-based models, including random forests and boosting models, generally derive no advantage from GPUs.</span></span>

<span data-ttu-id="30efe-132">임의 포리스트 같은 일부 모델 유형은 CPU에서 대규모 병렬 처리가 가능합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-132">Some model types such as random forests are massively parallelizable on CPUs.</span></span> <span data-ttu-id="30efe-133">이 경우 워크로드를 여러 코어에 분산하여 단일 요청 채점 속도를 높일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-133">In these cases, speed up the scoring of a single request by distributing the workload across multiple cores.</span></span> <span data-ttu-id="30efe-134">그러나 이렇게 하면 클러스터 크기가 고정되므로 여러 채점 요청을 처리하는 용량이 감소합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-134">However, doing so reduces your capacity to handle multiple scoring requests given a fixed cluster size.</span></span>

<span data-ttu-id="30efe-135">일반적으로 오픈 소스 R 모델은 모든 데이터를 메모리에 저장하므로 노드에서 동시에 실행하려는 프로세스를 처리하기에 충분한 메모리가 확보됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-135">In general, open-source R models store all their data in memory, so ensure that your nodes have enough memory to accommodate the processes you plan to run concurrently.</span></span> <span data-ttu-id="30efe-136">Machine Learning Server를 사용하여 모델을 적절하게 조정하려면 모든 데이터를 메모리로 읽어 들이지 않고 디스크에서 데이터를 처리할 수 있는 라이브러리를 사용하세요.</span><span class="sxs-lookup"><span data-stu-id="30efe-136">If you are using Machine Learning Server to fit your models, use the libraries that can process data on disk, rather than reading it all into memory.</span></span> <span data-ttu-id="30efe-137">이렇게 하면 메모리 요구 사항을 대폭 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-137">This can help reduce memory requirements significantly.</span></span> <span data-ttu-id="30efe-138">Machine Learning Server를 사용하든 오픈 소스 R을 사용하든, 채점 프로세스 때문에 메모리가 고갈되는 일이 없도록 노드를 모니터링해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-138">Regardless of whether you use Machine Learning Server or open-source R, monitor your nodes to ensure that your scoring processes are not memory-starved.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="30efe-139">보안 고려 사항</span><span class="sxs-lookup"><span data-stu-id="30efe-139">Security considerations</span></span>

### <a name="network-encryption"></a><span data-ttu-id="30efe-140">네트워크 암호화</span><span class="sxs-lookup"><span data-stu-id="30efe-140">Network encryption</span></span>

<span data-ttu-id="30efe-141">이 참조 아키텍처에서는 클러스터와의 통신에 HTTPS를 사용하며, [Let’s Encrypt][encrypt]의 준비 인증서가 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-141">In this reference architecture, HTTPS is enabled for communication with the cluster, and a staging certificate from [Let’s Encrypt][encrypt] is used.</span></span> <span data-ttu-id="30efe-142">프로덕션 환경에서는 적절한 서명 기관의 인증서로 바꾸면 됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-142">For production purposes, substitute your own certificate from an appropriate signing authority.</span></span>

### <a name="authentication-and-authorization"></a><span data-ttu-id="30efe-143">인증 및 권한 부여</span><span class="sxs-lookup"><span data-stu-id="30efe-143">Authentication and authorization</span></span>

<span data-ttu-id="30efe-144">Machine Learning Server [모델 운영화][operationalization]를 사용하려면 채점 요청을 인증해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-144">Machine Learning Server [Model Operationalization][operationalization] requires scoring requests to be authenticated.</span></span> <span data-ttu-id="30efe-145">이 배포에는 사용자 이름과 암호가 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-145">In this deployment, a username and password are used.</span></span> <span data-ttu-id="30efe-146">엔터프라이즈 설정에서 [Azure Active Directory][AAD]를 사용하여 인증을 지원할 수도 있고 [Azure API Management][API]를 사용하여 별도의 프런트 엔드를 만들 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-146">In an enterprise setting, you can enable authentication using [Azure Active Directory][AAD] or create a separate front end using [Azure API Management][API].</span></span>

<span data-ttu-id="30efe-147">컨테이너에서 모델 운영화가 Machine Learning Server와 함께 제대로 작동하려면 JWT(JSON Web Token) 인증서를 설치해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-147">For Model Operationalization to work correctly with Machine Learning Server on containers, you must install a JSON Web Token (JWT) certificate.</span></span> <span data-ttu-id="30efe-148">이 배포에서는 Microsoft가 제공하는 인증서를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-148">This deployment uses a certificate supplied by Microsoft.</span></span> <span data-ttu-id="30efe-149">프로덕션 설정에서는 사용자 고유의 인증서를 제공하면 됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-149">In a production setting, supply your own.</span></span>

<span data-ttu-id="30efe-150">Container Registry와 AKS 간 트래픽에 대해서는 [RBAC(역할 기반 액세스 제어)][rbac]를 사용하여 꼭 필요한 액세스 권한만 허용하도록 제한하는 방안을 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-150">For traffic between Container Registry and AKS, consider enabling [role-based access control][rbac] (RBAC) to limit access privileges to only those needed.</span></span>

### <a name="separate-storage"></a><span data-ttu-id="30efe-151">별도의 스토리지</span><span class="sxs-lookup"><span data-stu-id="30efe-151">Separate storage</span></span>

<span data-ttu-id="30efe-152">이 참조 아키텍처는 애플리케이션(R) 및 데이터(모델 개체 및 채점 스크립트)를 단일 이미지에 번들로 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-152">This reference architecture bundles the application (R) and the data (model object and scoring script) into a single image.</span></span> <span data-ttu-id="30efe-153">분리하는 것이 유리한 경우도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-153">In some cases, it may be beneficial to separate these.</span></span> <span data-ttu-id="30efe-154">모델 데이터와 코드를 Azure BLOB 또는 파일 [스토리지][storage]에 배치하고, 컨테이너 초기화 시 검색할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-154">You can place the model data and code into Azure blob or file [storage][storage], and retrieve them at container initialization.</span></span> <span data-ttu-id="30efe-155">이 경우 인증된 액세스만 허용하고 HTTPS를 요구하도록 스토리지 계정을 설정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-155">In this case, ensure that the storage account is set to allow authenticated access only and require HTTPS.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="30efe-156">모니터링 및 로깅 고려 사항</span><span class="sxs-lookup"><span data-stu-id="30efe-156">Monitoring and logging considerations</span></span>

<span data-ttu-id="30efe-157">[Kubernetes 대시보드][dashboard]를 사용하여 AKS 클러스터의 전반적인 상태를 모니터링할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-157">Use the [Kubernetes dashboard][dashboard] to monitor the overall status of your AKS cluster.</span></span> <span data-ttu-id="30efe-158">자세한 내용은 Azure Portal에서 클러스터의 개요 블레이드를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="30efe-158">See the cluster’s overview blade in Azure portal for more details.</span></span> <span data-ttu-id="30efe-159">[GitHub][github] 리소스 역시 R에서 대시보드를 불러오는 방법을 보여줍니다</span><span class="sxs-lookup"><span data-stu-id="30efe-159">The [GitHub][github] resources also show how to bring up the dashboard from R.</span></span>

<span data-ttu-id="30efe-160">대시보드가 클러스터의 전반적인 상태를 보여주지만, 개별 컨테이너의 상태를 추적하는 것도 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-160">Although the dashboard gives you a view of the overall health of your cluster, it’s also important to track the status of individual containers.</span></span> <span data-ttu-id="30efe-161">개별 컨테이너의 상태를 추적하려면 Azure Portal의 클러스터 개요 블레이드에서 [Azure Monitor Insights][monitor]를 설정하거나 [컨테이너용 Azure Monitor][monitor-containers](미리 보기)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="30efe-161">To do this, enable [Azure Monitor Insights][monitor] from the cluster overview blade in Azure portal, or see [Azure Monitor for containers][monitor-containers] (in preview).</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="30efe-162">비용 고려 사항</span><span class="sxs-lookup"><span data-stu-id="30efe-162">Cost considerations</span></span>

<span data-ttu-id="30efe-163">Machine Learning Server는 코어 단위로 라이선스가 제공되며, Machine Learning Server를 실행하는 클러스터의 모든 코어가 집계됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-163">Machine Learning Server is licensed on a per-core basis, and all the cores in the cluster that will run Machine Learning  Server count towards this.</span></span> <span data-ttu-id="30efe-164">Machine Learning Server 또는 Microsoft SQL Server 고객인 경우 Microsoft 담당자에게 자세한 가격 책정 정보를 문의하세요.</span><span class="sxs-lookup"><span data-stu-id="30efe-164">If you are an enterprise Machine Learning Server or Microsoft SQL Server customer, contact your Microsoft representative for pricing details.</span></span>

<span data-ttu-id="30efe-165">Machine Learning Server를 대체하는 오픈 소스 [Plumber][plumber]는 코드를 REST API로 변환하는 R 패키지입니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-165">An open-source alternative to Machine Learning Server is [Plumber][plumber], an R package that turns your code into a REST API.</span></span> <span data-ttu-id="30efe-166">Plumber는 Machine Learning Server보다 적은 기능을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-166">Plumber is less fully featured than Machine Learning Server.</span></span> <span data-ttu-id="30efe-167">예를 들어 요청 인증을 제공하는 기능이 기본적으로 포함되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-167">For example, by default it doesn't include any features that provide request authentication.</span></span> <span data-ttu-id="30efe-168">Plumber를 사용하는 인증 세부 정보를 처리할 수 있도록 [Azure API Management][API]를 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-168">If you use Plumber, it’s recommended that you enable [Azure API Management][API] to handle authentication details.</span></span>

<span data-ttu-id="30efe-169">라이선스 외에도 주요 비용 요인으로 Kubernetes 클러스터의 계산 리소스를 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-169">Besides licensing, the main cost consideration is the Kubernetes cluster's compute resources.</span></span> <span data-ttu-id="30efe-170">클러스터가 피크 시간대의 예상 요청 볼륨을 처리할 수 있도록 충분히 커야 하지만, 이 방법은 그 외의 시간에는 리소스가 유휴 상태로 남게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-170">The cluster must be large enough to handle the expected request volume at peak times, but this approach leaves resources idle at other times.</span></span> <span data-ttu-id="30efe-171">유휴 리소스의 영향을 최소화하려면 kubectl 도구를 사용하여 클러스터에 [수평 자동 크기 조정기][autoscaler]를 사용하도록 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-171">To limit the impact of idle resources, enable the [horizontal autoscaler][autoscaler] for the cluster using the kubectl tool.</span></span> <span data-ttu-id="30efe-172">또는 AKS [클러스터 자동 크기 조정기][cluster-autoscaler]를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-172">Or use the AKS [cluster autoscaler][cluster-autoscaler].</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="30efe-173">솔루션 배포</span><span class="sxs-lookup"><span data-stu-id="30efe-173">Deploy the solution</span></span>

<span data-ttu-id="30efe-174">이 참조 아키텍처 구현은 [GitHub][github]에서 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="30efe-174">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="30efe-175">GitHub에 설명된 단계에 따라 간단한 예측 모델을 서비스로 배포해 보세요.</span><span class="sxs-lookup"><span data-stu-id="30efe-175">Follow the steps described there to deploy a simple predictive model as a service.</span></span>

<!-- links -->
[AAD]: /azure/active-directory/fundamentals/active-directory-whatis
[API]: /azure/api-management/api-management-key-concepts
[ACR]: /azure/container-registry/container-registry-intro
[AKS]: /azure/aks/intro-kubernetes
[autoscaler]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[cluster-autoscaler]: /azure/aks/autoscaler
[monitor]: /azure/monitoring/monitoring-container-insights-overview
[dashboard]: /azure/aks/kubernetes-dashboard
[docker]: https://docs.docker.com/registry/spec/api/
[encrypt]: https://letsencrypt.org/
[gitHub]: https://github.com/Azure/RealtimeRDeployment
[K-API]: https://kubernetes.io/docs/reference/
[MMLS]: /machine-learning-server/what-is-machine-learning-server
[monitor-containers]: /azure/azure-monitor/insights/container-insights-overview
[operationalization]: /machine-learning-server/what-is-operationalization
[plumber]: https://www.rplumber.io
[RBAC]: /azure/role-based-access-control/overview
[storage]: /azure/storage/common/storage-introduction
[0]: ./_images/realtime-scoring-r.png
