---
title: 기존 온-프레미스 SSIS와 Azure Data Factory를 사용한 하이브리드 ETL
titleSuffix: Azure Example Scenarios
description: 기존 온-프레미스 SSIS(SQL Server Integration Services) 배포와 Azure Data Factory를 사용한 하이브리드 ETL
author: alhieng
ms.date: 09/20/2018
ms.custom: tsp-team
ms.openlocfilehash: a2ca3817ed172e6d2332a92f68970ea2a5ad8f6c
ms.sourcegitcommit: 1f4cdb08fe73b1956e164ad692f792f9f635b409
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 01/08/2019
ms.locfileid: "54110393"
---
# <a name="hybrid-etl-with-existing-on-premises-ssis-and-azure-data-factory"></a><span data-ttu-id="332b7-103">기존 온-프레미스 SSIS와 Azure Data Factory를 사용한 하이브리드 ETL</span><span class="sxs-lookup"><span data-stu-id="332b7-103">Hybrid ETL with existing on-premises SSIS and Azure Data Factory</span></span>

<span data-ttu-id="332b7-104">SQL Server 데이터베이스를 클라우드로 마이그레이션하는 조직은 엄청난 비용 절감, 성능 향상, 추가 유연성 및 확장성을 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-104">Organizations that migrate their SQL Server databases to the cloud can realize tremendous cost savings, performance gains, added flexibility, and greater scalability.</span></span> <span data-ttu-id="332b7-105">그러나 SSIS(SQL Server Integration Services)를 사용하여 빌드된 기존의 ETL(추출, 변환 및 로드) 프로세스를 다시 작업하는 것은 마이그레이션에 방해가 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-105">However, reworking existing extract, transform, and load (ETL) processes built with SQL Server Integration Services (SSIS) can be a migration roadblock.</span></span> <span data-ttu-id="332b7-106">또는 데이터 로드 프로세스에는 아직 Azure Data Factory v2에서 지원되지 않는 복잡한 논리 및/또는 특정 데이터 도구 구성 요소가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-106">In other cases, the data load process requires complex logic and/or specific data tool components that are not yet supported by Azure Data Factory v2.</span></span> <span data-ttu-id="332b7-107">자주 사용되는 SSIS 기능으로는 유사 항목 조회 및 유사 항목 그룹화 변환, CDC(변경 데이터 캡처), SCD(느린 변경 차원) 및 DQS(Data Quality Services)가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-107">Commonly used SSIS capabilities include Fuzzy Lookup and Fuzzy Grouping transformations, Change Data Capture (CDC), Slowly Changing Dimensions (SCD), and Data Quality Services (DQS).</span></span>

<span data-ttu-id="332b7-108">기존 SQL 데이터베이스를 간편하게 리프트 앤 시프트 방식으로 마이그레이션하는 가장 적합한 옵션은 하이브리드 ETL입니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-108">To facilitate a lift-and-shift migration of an existing SQL database, a hybrid ETL approach may be the most suitable option.</span></span> <span data-ttu-id="332b7-109">하이브리드 접근 방식은 Data Factory를 기본 오케스트레이션 엔진으로 사용하지만, 기존 SSIS 패키지를 계속 활용하여 데이터를 정리하고 온-프레미스 리소스를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-109">A hybrid approach uses Data Factory as the primary orchestration engine, but continues to leverage existing SSIS packages to clean data and work with on-premise resources.</span></span> <span data-ttu-id="332b7-110">이 방법은 Data Factory SQL Server IR(통합 런타임)을 사용하여 기존 데이터베이스를 클라우드로 리프트 앤 시프트할 수 있도록 지원하는 한편, 기존 코드 및 SSIS 패키지를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-110">This approach uses the Data Factory SQL Server Integrated Runtime (IR) to enable a lift-and-shift of existing databases into the cloud, while using existing code and SSIS packages.</span></span>

<span data-ttu-id="332b7-111">이 예제 시나리오는 데이터베이스를 클라우드로 이동하고, Data Factory를 기본 클라우드 기반 ETL 엔진으로 사용하고 기존 SSIS 패키지를 새 클라우드 데이터 워크플로에 통합하는 방안을 고려하는 조직과 관련이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-111">This example scenario is relevant to organizations that are moving databases to the cloud and are considering using Data Factory as their primary cloud-based ETL engine while incorporating existing SSIS packages into their new cloud data workflow.</span></span> <span data-ttu-id="332b7-112">여러 조직에서 특정 데이터 작업을 위한 SSIS ETL 패키지 개발에 많은 비용을 투자했습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-112">Many organizations have significant invested in developing SSIS ETL packages for specific data tasks.</span></span> <span data-ttu-id="332b7-113">이러한 패키지를 다시 작성하기가 어려울 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-113">Rewriting these packages can be daunting.</span></span> <span data-ttu-id="332b7-114">또한 많은 기존 코드 패키지가 로컬 리소스에 종속되어 있어서 클라우드로 마이그레이션할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-114">Also, many existing code packages have dependencies on local resources, preventing migration to the cloud.</span></span>

<span data-ttu-id="332b7-115">Data Factory를 사용하면 고객은 기존 ETL 패키지를 활용하는 한편 온-프레미스 ETL 개발에 대한 추가 투자를 제한할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-115">Data Factory lets customers take advantage of their existing ETL packages while limiting further investment in on-premises ETL development.</span></span> <span data-ttu-id="332b7-116">이 예제에서는 Azure Data Factory v2를 사용하는 새 클라우드 데이터 워크플로의 일부분으로 기존 SSIS 패키지를 활용하는 잠재적 사용 사례를 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-116">This example discusses potential use cases for leveraging existing SSIS packages as part of a new cloud data workflow using Azure Data Factory v2.</span></span>

## <a name="potential-use-cases"></a><span data-ttu-id="332b7-117">잠재적인 사용 사례</span><span class="sxs-lookup"><span data-stu-id="332b7-117">Potential use cases</span></span>

<span data-ttu-id="332b7-118">일반적으로 SSIS는 여러 SQL Server 데이터 전문가들이 데이터 변환 및 로드를 위해 선택하는 ETL 도구입니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-118">Traditionally, SSIS has been the ETL tool of choice for many SQL Server data professionals for data transformation and loading.</span></span> <span data-ttu-id="332b7-119">종종 개발 속도를 높이기 위해 특정 SSIS 기능 또는 타사 플러그 인 구성 요소를 사용하기도 합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-119">Sometimes, specific SSIS features or third-party plugging components have been used to accelerate the development effort.</span></span> <span data-ttu-id="332b7-120">이러한 패키지를 바꾸거나 다시 개발하는 방법은 올바른 선택이 아닙니다. 고객이 데이터베이스를 클라우드로 마이그레이션할 수 없기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-120">Replacement or redevelopment of these packages may not be an option, which prevents customers from migrating their databases to the cloud.</span></span> <span data-ttu-id="332b7-121">고객은 기존 데이터베이스를 클라우드로 마이그레이션하고 기존 SSIS 패키지를 활용하는 데 영향을 많이 미치지 않는 방법을 원합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-121">Customers are looking for low impact approaches to migrating their existing databases to the cloud and taking advantage of their existing SSIS packages.</span></span>

<span data-ttu-id="332b7-122">다음은 몇 가지 가능한 온-프레미스 사용 사례입니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-122">Several potential on-premises use cases are listed below:</span></span>

- <span data-ttu-id="332b7-123">네트워크 라우터 로그를 데이터베이스에 로드하여 분석합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-123">Loading network router logs to a database for analysis.</span></span>
- <span data-ttu-id="332b7-124">분석 보고용 인적 자원 고용 데이터를 준비합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-124">Preparing human resources employment data for analytical reporting.</span></span>
- <span data-ttu-id="332b7-125">제품 및 판매 데이터를 데이터 웨어하우스에 로드하여 판매량을 예측합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-125">Loading product and sales data into a data warehouse for sales forecasting.</span></span>
- <span data-ttu-id="332b7-126">재무 및 회계 관리용 운영 데이터 저장소 또는 데이터 웨어하우스 로드를 자동화합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-126">Automating loading of operational data stores or data warehouses for finance and accounting.</span></span>

## <a name="architecture"></a><span data-ttu-id="332b7-127">아키텍처</span><span class="sxs-lookup"><span data-stu-id="332b7-127">Architecture</span></span>

![Azure Data Factory를 사용하는 하이브리드 ETL 프로세스의 아키텍처 개요][architecture-diagram]

1. <span data-ttu-id="332b7-129">데이터는 Blob 스토리지에서 Data Factory로 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-129">Data is sourced from Blob storage into Data Factory.</span></span>
2. <span data-ttu-id="332b7-130">Data Factory 파이프라인은 통합 런타임을 통해 온-프레미스에 호스트된 SSIS 작업을 실행하는 저장 프로시저를 호출합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-130">The Data Factory pipeline invokes a stored procedure to execute an SSIS job hosted on-premises via the Integrated Runtime.</span></span>
3. <span data-ttu-id="332b7-131">데이터 정리 작업이 실행되어 다운스트림에 사용할 데이터가 준비됩니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-131">The data cleansing jobs are executed to prepare the data for downstream consumption.</span></span>
4. <span data-ttu-id="332b7-132">데이터 정리 작업이 완료되면 정리 데이터를 Azure에 로드하는 복사 작업이 실행됩니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-132">Once the data cleansing task completes successfully, a copy task is executed to load the clean data into Azure.</span></span>
5. <span data-ttu-id="332b7-133">그러면 정리 데이터가 SQL Data Warehouse의 테이블에 로드됩니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-133">The clean data is then loaded into tables in the SQL Data Warehouse.</span></span>

### <a name="components"></a><span data-ttu-id="332b7-134">구성 요소</span><span class="sxs-lookup"><span data-stu-id="332b7-134">Components</span></span>

- <span data-ttu-id="332b7-135">[Blob 스토리지][docs-blob-storage]는 파일을 저장하는 데 사용되며 Data Factory가 데이터를 검색하는 원본으로도 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-135">[Blob storage][docs-blob-storage] is used to store files and as a source for Data Factory to retrieve data.</span></span>
- <span data-ttu-id="332b7-136">[SQL Server Integration Services][docs-ssis]는 작업별 워크로드를 실행하는 데 사용되는 온-프레미스 ETL 패키지를 포함하고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-136">[SQL Server Integration Services][docs-ssis] contains the on-premises ETL packages used to execute task-specific workloads.</span></span>
- <span data-ttu-id="332b7-137">[Azure Data Factory][docs-data-factory]는 여러 원본에서 데이터를 가져와서 결합하고, 오케스트레이션하고, 데이터 웨어하우스에 데이터를 로드하는 클라우드 오케스트레이션 엔진입니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-137">[Azure Data Factory][docs-data-factory] is the cloud orchestration engine that takes data from multiple sources and combines, orchestrates, and loads the data into a data warehouse.</span></span>
- <span data-ttu-id="332b7-138">[SQL Data Warehouse][docs-sql-data-warehouse]는 표준 ANSI SQL 쿼리를 사용하여 쉽게 액세스할 수 있도록 데이터를 클라우드에 중앙 집중화합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-138">[SQL Data Warehouse][docs-sql-data-warehouse] centralizes data in the cloud for easy access using standard ANSI SQL queries.</span></span>

### <a name="alternatives"></a><span data-ttu-id="332b7-139">대안</span><span class="sxs-lookup"><span data-stu-id="332b7-139">Alternatives</span></span>

<span data-ttu-id="332b7-140">Data Factory는 Databricks Notebook, Python 스크립트, 가상 머신에서 실행되는 SSIS 인스턴스 등의 다른 기술을 사용하여 구현된 데이터 정리 프로시저를 호출할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-140">Data Factory could invoke data cleansing procedures implemented using other technologies, such as a Databricks notebook, Python script, or SSIS instance running in a virtual machine.</span></span> <span data-ttu-id="332b7-141">하이브리드 방식의 대안으로 [Azure-SSIS 통합 런타임을 위한 유료 또는 라이선스 방식의 사용자 지정 구성 요소를 설치](/azure/data-factory/how-to-develop-azure-ssis-ir-licensed-components)할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-141">[Installing paid or licensed custom components for the Azure-SSIS integration runtime](/azure/data-factory/how-to-develop-azure-ssis-ir-licensed-components) may be a viable alternative to the hybrid approach.</span></span>

## <a name="considerations"></a><span data-ttu-id="332b7-142">고려 사항</span><span class="sxs-lookup"><span data-stu-id="332b7-142">Considerations</span></span>

<span data-ttu-id="332b7-143">IR(통합 런타임)은 자체 호스팅 IR 또는 Azure 호스팅 IR의 두 가지 모델을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-143">The Integrated Runtime (IR) supports two models: self-hosted IR or Azure-hosted IR.</span></span> <span data-ttu-id="332b7-144">먼저 두 옵션 중 무엇을 사용할지 결정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-144">You first must decide between these two options.</span></span> <span data-ttu-id="332b7-145">자체 호스팅은 경제적이지만 유지 관리 및 관리 오버헤드가 증가합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-145">Self-hosting is more cost effective but has more overhead for maintenance and management.</span></span> <span data-ttu-id="332b7-146">자세한 내용은 [자체 호스팅 IR](/azure/data-factory/concepts-integration-runtime#self-hosted-integration-runtime)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="332b7-146">For more information, see [Self-hosted IR](/azure/data-factory/concepts-integration-runtime#self-hosted-integration-runtime).</span></span> <span data-ttu-id="332b7-147">어떤 IR을 사용할지 결정하는 데 도움이 필요한 경우 [사용할 IR 결정](/azure/data-factory/concepts-integration-runtime#determining-which-ir-to-use)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="332b7-147">If you need help determining which IR to use, see [Determining which IR to use](/azure/data-factory/concepts-integration-runtime#determining-which-ir-to-use).</span></span>

<span data-ttu-id="332b7-148">Azure 호스팅 방법의 경우 데이터 처리에 필요한 성능을 결정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-148">For the Azure-hosted approach, you should decide how much power is required to process your data.</span></span> <span data-ttu-id="332b7-149">Azure 호스팅 구성을 사용하면 구성 단계에서 VM 크기를 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-149">The Azure-hosted configuration allows you to select the VM size as part of the configuration steps.</span></span> <span data-ttu-id="332b7-150">VM 크기 선택에 대한 자세한 내용은 [VM 성능 고려 사항](/azure/cloud-services/cloud-services-sizes-specs#performance-considerations)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="332b7-150">To learn more about selecting VM sizes, see [VM performance considerations](/azure/cloud-services/cloud-services-sizes-specs#performance-considerations).</span></span>

<span data-ttu-id="332b7-151">Azure에서 액세스할 수 없는 데이터 원본 또는 파일처럼 온-프레미스에 종속된 기존 SSIS 패키지가 이미 있는 경우 의사 결정이 훨씬 간단합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-151">The decision is much easier when you already have existing SSIS packages that have on-premise dependencies such as data sources or files that are not accessible from Azure.</span></span> <span data-ttu-id="332b7-152">이 시나리오에서 선택 가능한 유일한 옵션은 자체 호스팅 IR입니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-152">In this scenario, your only option is the self-hosted IR.</span></span> <span data-ttu-id="332b7-153">이 방법은 기존 패키지를 다시 작성할 필요 없이 클라우드를 오케스트레이션 엔진으로 활용하는 최고의 유연성을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-153">This approach provides the most flexibility to leverage the cloud as the orchestration engine, without having to rewrite existing packages.</span></span>

<span data-ttu-id="332b7-154">궁극적인 의도는 처리된 데이터를 클라우드로 이동하여 추가로 구체화하거나 클라우드에 저장된 다른 데이터와 결합하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-154">Ultimately, the intent is to move the processed data into the cloud for further refinement or combining with other data stored in the cloud.</span></span> <span data-ttu-id="332b7-155">디자인 프로세스의 일부로 Data Factory 파이프라인에서 사용되는 작업의 수를 추적합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-155">As part of the design process, keep track of the number of activities used in the Data Factory pipelines.</span></span> <span data-ttu-id="332b7-156">자세한 내용은 [Azure Data Factory의 파이프라인 및 작업](/azure/data-factory/concepts-pipelines-activities)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="332b7-156">For more information, see [Pipelines and activities in Azure Data Factory](/azure/data-factory/concepts-pipelines-activities).</span></span>

## <a name="pricing"></a><span data-ttu-id="332b7-157">가격</span><span class="sxs-lookup"><span data-stu-id="332b7-157">Pricing</span></span>

<span data-ttu-id="332b7-158">Data Factory는 클라우드에서 데이터 이동을 오케스트레이션하는 비용 효율적인 방법입니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-158">Data Factory is a cost-effective way to orchestrate data movement in the cloud.</span></span> <span data-ttu-id="332b7-159">비용은 여러 가지 요소에 따라 달라집니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-159">The cost is based on the several factors.</span></span>

- <span data-ttu-id="332b7-160">파이프라인 실행 수</span><span class="sxs-lookup"><span data-stu-id="332b7-160">Number of pipeline executions</span></span>
- <span data-ttu-id="332b7-161">파이프라인 내에서 사용되는 엔터티/작업의 수</span><span class="sxs-lookup"><span data-stu-id="332b7-161">Number of entities/activities used within the pipeline</span></span>
- <span data-ttu-id="332b7-162">모니터링 작업의 수</span><span class="sxs-lookup"><span data-stu-id="332b7-162">Number of monitoring operations</span></span>
- <span data-ttu-id="332b7-163">통합 실행 횟수(Azure 호스팅 IR 또는 자체 호스팅 IR)</span><span class="sxs-lookup"><span data-stu-id="332b7-163">Number of Integration Runs (Azure-hosted IR or self-hosted IR)</span></span>

<span data-ttu-id="332b7-164">Data Factory는 사용량을 기준으로 요금이 청구됩니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-164">Data Factory uses consumption-based billing.</span></span> <span data-ttu-id="332b7-165">따라서 파이프라인을 실행하고 모니터링하는 동안에만 비용이 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-165">Therefore, cost is only incurred during pipeline executions and monitoring.</span></span> <span data-ttu-id="332b7-166">기본 파이프라인 실행 시 발생하는 비용은 50센트, 모니터링 시 발생하는 비용은 25센트에 불과합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-166">The execution of a basic pipeline would cost as little as 50 cents and the monitoring as little as 25 cents.</span></span> <span data-ttu-id="332b7-167">[Azure 비용 계산기](https://azure.microsoft.com/pricing/calculator/)를 사용하여 워크로드에 따른 정확한 비용을 계산할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-167">The [Azure cost calculator](https://azure.microsoft.com/pricing/calculator/) can be used to create a more accurate estimate based on your specific workload.</span></span>

<span data-ttu-id="332b7-168">하이브리드 ETL 워크로드를 실행하는 경우 SSIS 패키지를 호스트하는 데 사용되는 가상 머신의 비용을 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-168">When running a hybrid ETL workload, you must factor in the cost of the virtual machine used to host your SSIS packages.</span></span> <span data-ttu-id="332b7-169">이 비용은 D1v2(1코어, 3.5GB RAM, 50GB 디스크)부터 E64V3(64코어, 432GB RAM, 1600GB 디스크)에 이르는 VM 크기에 따라 결정됩니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-169">This cost is based on the size of the VM ranging from a D1v2 (1 core, 3.5 GB RAM, 50 GB Disk) to E64V3 (64 cores, 432 GB RAM, 1600 GB disk).</span></span> <span data-ttu-id="332b7-170">적절한 VM 크기를 선택하는 방법에 대한 자세한 지침은 [VM 성능 고려 사항](/azure/cloud-services/cloud-services-sizes-specs#performance-considerations)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="332b7-170">If you need further guidance on selection the appropriate VM size, see [VM performance considerations](/azure/cloud-services/cloud-services-sizes-specs#performance-considerations).</span></span>

## <a name="next-steps"></a><span data-ttu-id="332b7-171">다음 단계</span><span class="sxs-lookup"><span data-stu-id="332b7-171">Next Steps</span></span>

- <span data-ttu-id="332b7-172">[Azure Data Factory](https://azure.microsoft.com/services/data-factory/)에 대해 자세히 알아봅니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-172">Learn more about [Azure Data Factory](https://azure.microsoft.com/services/data-factory/).</span></span>
- <span data-ttu-id="332b7-173">[단계별 자습서](/azure/data-factory/#step-by-step-tutorials)를 수행하여 Azure Data Factory를 시작합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-173">Get started with Azure Data Factory by following the [Step-by-step tutorial](/azure/data-factory/#step-by-step-tutorials).</span></span>
- <span data-ttu-id="332b7-174">[Azure Data Factory에서 Azure-SSIS 통합 런타임을 프로비전](/azure/data-factory/tutorial-deploy-ssis-packages-azure)합니다.</span><span class="sxs-lookup"><span data-stu-id="332b7-174">[Provision the Azure-SSIS Integration Runtime in Azure Data Factory](/azure/data-factory/tutorial-deploy-ssis-packages-azure).</span></span>

<!-- links -->
[architecture-diagram]: ./media/architecture-diagram-hybrid-etl-with-adf.png
[small-pricing]: https://azure.com/e/
[medium-pricing]: https://azure.com/e/
[large-pricing]: https://azure.com/e/
[availability]: /azure/architecture/checklist/availability
[resource-groups]: /azure/azure-resource-manager/resource-group-overview
[resiliency]: /azure/architecture/resiliency/
[security]: /azure/security/
[scalability]: /azure/architecture/checklist/scalability
[docs-blob-storage]: /azure/storage/blobs/
[docs-data-factory]: /azure/data-factory/introduction
[docs-resource-groups]: /azure/azure-resource-manager/resource-group-overview
[docs-ssis]: /sql/integration-services/sql-server-integration-services
[docs-sql-data-warehouse]: /azure/sql-data-warehouse/sql-data-warehouse-overview-what-is
