---
title: 마이크로 서비스에서 로깅 및 모니터링
description: 마이크로 서비스에서 로깅 및 모니터링
author: MikeWasson
ms.date: 10/23/2018
ms.openlocfilehash: 9d385a141edb34b2b0f4badb7dfcaf53baac2666
ms.sourcegitcommit: 1b5411f07d74f0a0680b33c266227d24014ba4d1
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 11/26/2018
ms.locfileid: "52305913"
---
# <a name="designing-microservices-logging-and-monitoring"></a><span data-ttu-id="0d7c3-103">마이크로 서비스 디자인: 로깅 및 모니터링</span><span class="sxs-lookup"><span data-stu-id="0d7c3-103">Designing microservices: Logging and monitoring</span></span>

<span data-ttu-id="0d7c3-104">모든 복잡한 응용 프로그램의 특정 시점에서 일부는 잘못될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-104">In any complex application, at some point something will go wrong.</span></span> <span data-ttu-id="0d7c3-105">마이크로 서비스 응용 프로그램에서는 수십 또는 수백 개의 서비스에서 발생하는 것을 추적해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-105">In a microservices application, you need to track what's happening across dozens or even hundreds of services.</span></span> <span data-ttu-id="0d7c3-106">로깅 및 모니터링은 시스템에 대한 전체적인 뷰를 제공하는 데 매우 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-106">Logging and monitoring are critically important to give you a holistic view of the system.</span></span> 

![](./images/monitoring.png)

<span data-ttu-id="0d7c3-107">마이크로 서비스 아키텍처에서는 오류 또는 성능 병목 상태의 정확한 원인을 찾는 데 특히 어려울 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-107">In a microservices architecture, it can be especially challenging to pinpoint the exact cause of errors or performance bottlenecks.</span></span> <span data-ttu-id="0d7c3-108">단일 사용자 작업에는 여러 서비스가 포함될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-108">A single user operation might span multiple services.</span></span> <span data-ttu-id="0d7c3-109">서비스는 클러스터 내의 네트워크 I/O 제한에 도달할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-109">Services may hit network I/O limits inside the cluster.</span></span> <span data-ttu-id="0d7c3-110">서비스의 호출 체인은 시스템에서 역압을 생성하여 긴 대기 시간 또는 연속적인 오류를 발생시킬 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-110">A chain of calls across services may cause backpressure in the system, resulting in high latency or cascading failures.</span></span> <span data-ttu-id="0d7c3-111">또한 일반적으로 특정 컨테이너에서 실행할 노드를 알지 못합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-111">Moreover, you generally don't know which node a particular container will run in.</span></span> <span data-ttu-id="0d7c3-112">동일한 노드에 배치된 컨테이너는 제한된 CPU 또는 메모리에 대해 경쟁할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-112">Containers placed on the same node may be competing for limited CPU or memory.</span></span> 

<span data-ttu-id="0d7c3-113">상황을 이해하려면 응용 프로그램에서 원격 분석 데이터를 수집해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-113">To make sense of what's happening, you must collect telemetry from the application.</span></span>  <span data-ttu-id="0d7c3-114">원격 분석 데이터를 *로그*과 *메트릭*으로 나눌 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-114">Telemetry can be divided into *logs* and *metrics*.</span></span> <span data-ttu-id="0d7c3-115">[Azure Monitor](/azure/monitoring-and-diagnostics/monitoring-overview)는 Azure 플랫폼에서 로그와 메트릭을 모두 수집합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-115">[Azure Monitor](/azure/monitoring-and-diagnostics/monitoring-overview) collects both logs and metrics across the Azure platform.</span></span>

<span data-ttu-id="0d7c3-116">**로그**는 응용 프로그램이 실행되는 동안 발생하는 이벤트의 텍스트 기반 레코드입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-116">**Logs** are text-based records of events that occur while the application is running.</span></span> <span data-ttu-id="0d7c3-117">응용 프로그램 로그(추적문) 또는 웹 서버 로그 등이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-117">They include things like application logs (trace statements) or web server logs.</span></span> <span data-ttu-id="0d7c3-118">로그는 포렌식스 및 근본 원인 분석에 주로 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-118">Logs are primarily useful for forensics and root cause analysis.</span></span> 

<span data-ttu-id="0d7c3-119">**메트릭**은 분석될 수 있는 숫자 값입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-119">**Metrics** are numerical values that can be analyzed.</span></span> <span data-ttu-id="0d7c3-120">실시간으로(또는 실시간에 가까운) 시스템을 관찰하거나 시간에 따른 성능 추세를 분석하기 위해 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-120">You can use them to observe the system in real time (or close to real time), or to analyze performance trends over time.</span></span> <span data-ttu-id="0d7c3-121">메트릭을 다음과 같은 하위 범주로 분류할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-121">Metrics can be further subcategorized as follows:</span></span>

- <span data-ttu-id="0d7c3-122">CPU, 메모리, 네트워크, 디스크 및 파일 시스템 사용량을 비롯한 **노드 수준**의 메트릭.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-122">**Node-level** metrics, including CPU, memory, network, disk, and file system usage.</span></span> <span data-ttu-id="0d7c3-123">시스템 메트릭은 클러스터의 각 노드에 대한 리소스 할당을 이해하고 이상값의 문제를 해결할 수 있도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-123">System metrics help you to understand resource allocation for each node in the cluster, and troubleshoot outliers.</span></span>

- <span data-ttu-id="0d7c3-124">**컨테이너 메트릭**.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-124">**Container** metrics.</span></span> <span data-ttu-id="0d7c3-125">서비스가 컨테이너 내에서 실행되는 경우 VM 수준은 물론이고 컨테이너 수준에서도 메트릭을 수집해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-125">If services are run inside containers, you need to collect metrics at the container level, not just at the VM level.</span></span> <span data-ttu-id="0d7c3-126">AKS(Azure Kubernetes Service)에서 컨테이너 워크로드를 모니터링하도록 Azure Monitor를 설정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-126">You can set up Azure Monitor to monitor container workloads in Azure Kubernetes Service (AKS).</span></span> <span data-ttu-id="0d7c3-127">자세한 내용은 [컨테이너용 Azure Monitor 개요](/azure/monitoring/monitoring-container-insights-overview)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-127">For more information, see [Azure Monitor for containers overview](/azure/monitoring/monitoring-container-insights-overview).</span></span> <span data-ttu-id="0d7c3-128">다른 컨테이너 오케스트레이터에는 [Log Analytics의 컨테이너 모니터링 솔루션](/azure/log-analytics/log-analytics-containers)을 사용하세요.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-128">For other container orchestrators, use the [Container Monitoring solution in Log Analytics](/azure/log-analytics/log-analytics-containers).</span></span>

- <span data-ttu-id="0d7c3-129">**응용 프로그램** 메트릭.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-129">**Application** metrics.</span></span> <span data-ttu-id="0d7c3-130">서비스의 동작을 이해하는 데 관련된 모든 메트릭을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-130">This includes any metrics that are relevant to understanding the behavior of a service.</span></span> <span data-ttu-id="0d7c3-131">큐에 대기 중인 인바운드 HTTP 요청 수, 요청 대기 시간, 메시지 큐 길이 등을 예로 들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-131">Examples include the number of queued inbound HTTP requests, request latency, or message queue length.</span></span> <span data-ttu-id="0d7c3-132">응용 프로그램에서 분당 처리된 비즈니스 트랜잭션 수 같은 도메인 관련 사용자 지정 메트릭을 만들 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-132">Applications can also create custom metrics that are specific to the domain, such as the number of business transactions processed per minute.</span></span> <span data-ttu-id="0d7c3-133">[Application Insights](/azure/application-insights/app-insights-overview)를 사용하여 응용 프로그램 메트릭을 사용하도록 설정하세요.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-133">Use [Application Insights](/azure/application-insights/app-insights-overview) to enable application metrics.</span></span> 

- <span data-ttu-id="0d7c3-134">**종속 서비스** 메트릭.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-134">**Dependent service** metrics.</span></span> <span data-ttu-id="0d7c3-135">서비스에서 관리 PaaS 서비스 또는 SaaS 서비스 같은 외부 서비스 또는 엔드포인트를 호출할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-135">Services may call external services or endpoints, such as managed PaaS services or SaaS services.</span></span> <span data-ttu-id="0d7c3-136">타사 서비스는 모든 메트릭을 제공하거나 제공하지 않을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-136">Third-party services may or may not provide any metrics.</span></span> <span data-ttu-id="0d7c3-137">제공하지 않는 경우 사용자 고유의 응용 프로그램 메트릭을 사용하여 대기 시간 및 오류 비율에 대한 통계를 추적해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-137">If not, you'll have to rely on your own application metrics to track statistics for latency and error rate.</span></span>

## <a name="considerations"></a><span data-ttu-id="0d7c3-138">고려 사항</span><span class="sxs-lookup"><span data-stu-id="0d7c3-138">Considerations</span></span>

<span data-ttu-id="0d7c3-139">[모니터링 및 진단](../best-practices/monitoring.md) 문서는 응용 프로그램 모니터링에 대한 일반적인 모범 사례를 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-139">The article [Monitoring and diagnostics](../best-practices/monitoring.md) describes general best practices for monitoring an application.</span></span> <span data-ttu-id="0d7c3-140">마이크로 서비스 아키텍처의 컨텍스트에서 고려할 몇 가지 특정 사항은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-140">Here are some particular things to think about in the context of a microservices architecture.</span></span>

<span data-ttu-id="0d7c3-141">**구성 및 관리**</span><span class="sxs-lookup"><span data-stu-id="0d7c3-141">**Configuration and management**.</span></span> <span data-ttu-id="0d7c3-142">로깅 및 모니터링에 관리 서비스를 사용하거나 클러스터 내 컨테이너로 구성 요소 로깅 및 모니터링을 배포하겠습니까?</span><span class="sxs-lookup"><span data-stu-id="0d7c3-142">Will you use a managed service for logging and monitoring, or deploy logging and monitoring components as containers inside the cluster?</span></span> <span data-ttu-id="0d7c3-143">이러한 옵션에 대한 자세한 내용은 아래 [기술 옵션](#technology-options) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-143">For more discussion of these options, see the section [Technology Options](#technology-options) below.</span></span>

<span data-ttu-id="0d7c3-144">**수집 속도**</span><span class="sxs-lookup"><span data-stu-id="0d7c3-144">**Ingestion rate**.</span></span> <span data-ttu-id="0d7c3-145">시스템이 원격 분석 이벤트를 수집할 수 있는 처리량이란?</span><span class="sxs-lookup"><span data-stu-id="0d7c3-145">What is the throughput at which the system can ingest telemetry events?</span></span> <span data-ttu-id="0d7c3-146">해당 속도를 초과하는 경우 어떻게 되나요?</span><span class="sxs-lookup"><span data-stu-id="0d7c3-146">What happens if that rate is exceeded?</span></span> <span data-ttu-id="0d7c3-147">예를 들어 시스템은 클라이언트를 제한할 수 있습니다. 이 경우 원격 분석 데이터가 손실되거나 데이터를 저해상도 처리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-147">For example, the system may throttle clients, in which case telemetry data is lost, or it may downsample the data.</span></span> <span data-ttu-id="0d7c3-148">경우에 따라 수집하는 데이터의 양을 줄여 이 문제를 완화할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-148">Sometimes you can mitigate this problem by reducing the amount of data that you collect:</span></span>

  - <span data-ttu-id="0d7c3-149">평균 및 표준 편차 등의 통계를 계산하여 메트릭을 집계하고 모니터링 시스템에 해당 통계 데이터를 보냅니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-149">Aggregate metrics by calculating statistics, such as average and standard deviation, and send that statistical data to the monitoring system.</span></span>  

  - <span data-ttu-id="0d7c3-150">데이터를 저해상도 처리합니다. &mdash; 즉, 이벤트의 일부분만 처리합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-150">Downsample the data &mdash; that is, process only a percentage of the events.</span></span>

  - <span data-ttu-id="0d7c3-151">모니터링 서비스에 대한 네트워크 호출 수를 줄이기 위해 데이터를 일괄 처리합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-151">Batch the data to reduce the number of network calls to the monitoring service.</span></span>

<span data-ttu-id="0d7c3-152">**비용**</span><span class="sxs-lookup"><span data-stu-id="0d7c3-152">**Cost**.</span></span> <span data-ttu-id="0d7c3-153">원격 분석 데이터를 수집하고 저장하는 비용은 특히 대용량에서 높을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-153">The cost of ingesting and storing telemetry data may be high, especially at high volumes.</span></span> <span data-ttu-id="0d7c3-154">경우에 따라 응용 프로그램 실행 비용을 초과할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-154">In some cases it could even exceed the cost of running the application.</span></span> <span data-ttu-id="0d7c3-155">이 경우 위에서 설명한 것처럼 데이터를 집계, 저해상도 처리 또는 일괄 처리하여 원격 분석의 양을 줄여야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-155">In that case, you may need to reduce the volume of telemetry by aggregating, downsampling, or batching the data, as described above.</span></span> 
        
<span data-ttu-id="0d7c3-156">**데이터 충실도**</span><span class="sxs-lookup"><span data-stu-id="0d7c3-156">**Data fidelity**.</span></span> <span data-ttu-id="0d7c3-157">메트릭은 얼마나 정확하나요?</span><span class="sxs-lookup"><span data-stu-id="0d7c3-157">How accurate are the metrics?</span></span> <span data-ttu-id="0d7c3-158">평균은 특히 규모에서 이상값을 숨길 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-158">Averages can hide outliers, especially at scale.</span></span> <span data-ttu-id="0d7c3-159">또한 샘플링 비율이 너무 낮으면 데이터의 변동을 제거할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-159">Also, if the sampling rate is too low, it can smooth out fluctuations in the data.</span></span> <span data-ttu-id="0d7c3-160">실제로 요청 작업의 상당 부분에 더 많은 시간이 소요되는 경우 모든 요청에 동일한 종단 간 대기 시간이 있는 것처럼 나타날 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-160">It may appear that all requests have about the same end-to-end latency, when in fact a significant fraction of requests are taking much longer.</span></span> 

<span data-ttu-id="0d7c3-161">**대기 시간**</span><span class="sxs-lookup"><span data-stu-id="0d7c3-161">**Latency**.</span></span> <span data-ttu-id="0d7c3-162">실시간 모니터링 및 경고를 사용하려면 원격 분석 데이터를 신속하게 사용할 수 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-162">To enable real-time monitoring and alerts, telemetry data should be available quickly.</span></span> <span data-ttu-id="0d7c3-163">모니터링 대시보드에 표시되는 데이터는 얼마나 "실시간"인가요?</span><span class="sxs-lookup"><span data-stu-id="0d7c3-163">How "real-time" is the data that appears on the monitoring dashboard?</span></span> <span data-ttu-id="0d7c3-164">몇 초 늦나요?</span><span class="sxs-lookup"><span data-stu-id="0d7c3-164">A few seconds old?</span></span> <span data-ttu-id="0d7c3-165">1분 이상인가요?</span><span class="sxs-lookup"><span data-stu-id="0d7c3-165">More than a minute?</span></span>

<span data-ttu-id="0d7c3-166">**저장소**</span><span class="sxs-lookup"><span data-stu-id="0d7c3-166">**Storage.**</span></span> <span data-ttu-id="0d7c3-167">로그의 경우 클러스터의 임시 저장소에 로그 이벤트를 기록하고 더 영구적인 저장소로 로그 파일을 제공하도록 에이전트를 구성하는 것이 가장 효율적일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-167">For logs, it may be most efficient to write the log events to ephemeral storage in the cluster, and configure an agent to ship the log files to more persistent storage.</span></span>  <span data-ttu-id="0d7c3-168">데이터는 회고 분석에 사용할 수 있도록 결국 장기 저장소로 옮겨야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-168">Data should eventually be moved to long-term storage so that it's available for retrospective analysis.</span></span> <span data-ttu-id="0d7c3-169">해당 데이터를 저장하는 비용은 중요한 고려 사항이므로 마이크로 서비스 아키텍처에서 많은 양의 원격 분석 데이터를 생성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-169">A microservices architecture can generate a large volume of telemetry data, so the cost of storing that data is an important consideration.</span></span> <span data-ttu-id="0d7c3-170">또한 데이터를 쿼리하는 방법을 고려합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-170">Also consider how you will query the data.</span></span> 

<span data-ttu-id="0d7c3-171">**대시보드 및 시각화**</span><span class="sxs-lookup"><span data-stu-id="0d7c3-171">**Dashboard and visualization.**</span></span> <span data-ttu-id="0d7c3-172">클러스터 및 외부 서비스 내에서 모든 서비스에 대한 시스템의 전체적 뷰를 가져오나요?</span><span class="sxs-lookup"><span data-stu-id="0d7c3-172">Do you get a holistic view of the system, across all of the services, both within the cluster and external services?</span></span> <span data-ttu-id="0d7c3-173">둘 이상의 위치에 원격 분석 데이터 및 로그를 작성하는 경우 대시보드는 모두를 표시하고 상관 관계를 보여 줄 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="0d7c3-173">If you are writing telemetry data and logs to more than one location, can the dashboard show all of them and correlate?</span></span> <span data-ttu-id="0d7c3-174">모니터링 대시보드는 적어도 다음 정보를 표시해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-174">The monitoring dashboard should show at least the following information:</span></span>

- <span data-ttu-id="0d7c3-175">용량 및 증가에 대한 전체 리소스 할당</span><span class="sxs-lookup"><span data-stu-id="0d7c3-175">Overall resource allocation for capacity and growth.</span></span> <span data-ttu-id="0d7c3-176">여기에 컨테이너 수, 파일 시스템 메트릭, 네트워크 및 코어 할당이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-176">This includes the number of containers, file system metrics, network, and core allocation.</span></span>
- <span data-ttu-id="0d7c3-177">서비스 수준에서 상호 관련된 컨테이너 메트릭</span><span class="sxs-lookup"><span data-stu-id="0d7c3-177">Container metrics correlated at the service level.</span></span>
- <span data-ttu-id="0d7c3-178">컨테이너와 상호 관련된 시스템 메트릭</span><span class="sxs-lookup"><span data-stu-id="0d7c3-178">System metrics correlated with containers.</span></span>
- <span data-ttu-id="0d7c3-179">서비스 오류 및 이상값</span><span class="sxs-lookup"><span data-stu-id="0d7c3-179">Service errors and outliers.</span></span>
    

## <a name="distributed-tracing"></a><span data-ttu-id="0d7c3-180">분산된 추적</span><span class="sxs-lookup"><span data-stu-id="0d7c3-180">Distributed tracing</span></span>

<span data-ttu-id="0d7c3-181">언급한 바와 같이 마이크로 서비스에서 한 가지 문제는 서비스 전반에 걸쳐 이벤트 흐름을 파악하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-181">As mentioned, one challenge in microservices is understanding the flow of events across services.</span></span> <span data-ttu-id="0d7c3-182">단일 작업 또는 트랜잭션은 여러 서비스에 대한 호출을 포함할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-182">A single operation or transaction may involve calls to multiple services.</span></span> <span data-ttu-id="0d7c3-183">단계의 전체 시퀀스를 다시 구성하기 위해 각 서비스는 해당 작업에 대해 고유 식별자의 역할을 하는 *상관 관계 ID*를 전파해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-183">To reconstruct the entire sequence of steps, each service should propagate a *correlation ID* that acts as a unique identifier for that operation.</span></span> <span data-ttu-id="0d7c3-184">상관 관계 ID는 서비스 전반에 걸쳐 [분산된 추적](https://microservices.io/patterns/observability/distributed-tracing.html)을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-184">The correlation ID enables [distributed tracing](https://microservices.io/patterns/observability/distributed-tracing.html) across services.</span></span>

<span data-ttu-id="0d7c3-185">클라이언트 요청을 수신하는 첫 번째 서비스는 상관 관계 ID를 생성해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-185">The first service that receives a client request should generate the correlation ID.</span></span> <span data-ttu-id="0d7c3-186">서비스에서 다른 서비스에 대한 HTTP 호출을 수행하는 경우 요청 헤더에 상관 관계 ID를 배치합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-186">If the service makes an HTTP call to another service, it puts the correlation ID in a request header.</span></span> <span data-ttu-id="0d7c3-187">마찬가지로 서비스가 비동기 메시지를 보내는 경우 메시지에 상관 관계 ID를 배치합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-187">Similarly, if the service sends an asynchronous message, it puts the correlation ID into the message.</span></span> <span data-ttu-id="0d7c3-188">전체 시스템을 통해 흐르도록 다운스트림 서비스는 상관 관계 ID를 계속해서 전파합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-188">Downstream services continue to propagate the correlation ID, so that it flows through the entire system.</span></span> <span data-ttu-id="0d7c3-189">또한 응용 프로그램 메트릭 또는 로그 이벤트를 작성하는 모든 코드는 상관 관계 ID를 포함해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-189">In addition, all code that writes application metrics or log events should include the correlation ID.</span></span>

<span data-ttu-id="0d7c3-190">서비스 호출이 상호 관련된 경우 완전한 트랜잭션에 대한 종단 간 대기 시간, 초당 성공한 트랜잭션 수 및 실패한 트랜잭션의 백분율과 같은 운영 메트릭을 계산할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-190">When service calls are correlated, you can calculate operational metrics such as the end-to-end latency for a complete transaction, the number of successful transactions per second, and the percentage of failed transactions.</span></span> <span data-ttu-id="0d7c3-191">응용 프로그램 로그에 상관 관계 ID를 포함하여 근본 원인 분석을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-191">Including correlation IDs in application logs makes it possible to perform root cause analysis.</span></span> <span data-ttu-id="0d7c3-192">작업이 실패하면 동일한 작업의 일부분이었던 모든 서비스 호출에 대한 로그문을 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-192">If an operation fails, you can find the log statements for all of the service calls that were part of the same operation.</span></span> 

<span data-ttu-id="0d7c3-193">분산된 추적을 구현하는 경우 몇 가지 고려 사항은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-193">Here are some considerations when implementing distributed tracing:</span></span>

- <span data-ttu-id="0d7c3-194">현재 상관 관계 ID에 대한 표준 HTTP 헤더가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-194">There is currently no standard HTTP header for correlation IDs.</span></span> <span data-ttu-id="0d7c3-195">팀에서 사용자 지정 헤더 값을 표준화해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-195">Your team should standardize on a custom header value.</span></span> <span data-ttu-id="0d7c3-196">프레임워크 로깅/모니터링 또는 서비스 메시의 선택으로 선택을 결정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-196">The choice may be decided by your logging/monitoring framework or choice of service mesh.</span></span>

- <span data-ttu-id="0d7c3-197">비동기 메시지의 경우 메시징 인프라가 메시지에 메타데이터 추가를 지원하는 경우 메타데이터로 상관 관계 ID를 포함해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-197">For asynchronous messages, if your messaging infrastructure supports adding metadata to messages, you should include the correlation ID as metadata.</span></span> <span data-ttu-id="0d7c3-198">그렇지 않은 경우 메시지 스키마의 일부분으로 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-198">Otherwise, include it as part of the message schema.</span></span>

- <span data-ttu-id="0d7c3-199">단일 불투명 식별자 대신 호출자-호출 수신자 관계와 같은 다양한 정보를 포함하는 *상관 관계 컨텍스트*를 보낼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-199">Rather than a single opaque identifier, you might send a *correlation context* that includes richer information, such as caller-callee relationships.</span></span> 

- <span data-ttu-id="0d7c3-200">Azure Application Insights SDK는 자동으로 상관 관계 컨텍스트를 HTTP 헤더로 삽입하고 Application Insights 로그에 상관 관계 ID를 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-200">The Azure Application Insights SDK automatically injects correlation context into HTTP headers, and includes the correlation ID in Application Insights logs.</span></span> <span data-ttu-id="0d7c3-201">Application Insights에 기본 제공된 상관 관계 기능을 사용하려는 경우 일부 서비스는 사용되는 라이브러리에 따라 상관 관계 헤더를 여전히 명시적으로 전파해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-201">If you decide to use the correlation features built into Application Insights, some services may still need to explicitly propagate the correlation headers, depending on the libraries being used.</span></span> <span data-ttu-id="0d7c3-202">자세한 내용은 [Application Insights에서 원격 분석 상관 관계](/azure/application-insights/application-insights-correlation)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-202">For more information, see [Telemetry correlation in Application Insights](/azure/application-insights/application-insights-correlation).</span></span>
   
- <span data-ttu-id="0d7c3-203">서비스 메시로 Istio 또는 linkerd를 사용하는 경우 이러한 기술은 HTTP 호출이 서비스 메시 프록시를 통해 라우팅될 때 자동으로 상관 관계 헤더를 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-203">If you are using Istio or linkerd as a service mesh, these technologies automatically generate correlation headers when HTTP calls are routed through the service mesh proxies.</span></span> <span data-ttu-id="0d7c3-204">서비스는 관련 헤더를 전달해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-204">Services should forward the relevant headers.</span></span> 

    - <span data-ttu-id="0d7c3-205">Istio: [분산된 요청 추적](https://istio-releases.github.io/v0.1/docs/tasks/zipkin-tracing.html)</span><span class="sxs-lookup"><span data-stu-id="0d7c3-205">Istio: [Distributed Request Tracing](https://istio-releases.github.io/v0.1/docs/tasks/zipkin-tracing.html)</span></span>
    
    - <span data-ttu-id="0d7c3-206">linkerd: [컨텍스트 헤더](https://linkerd.io/config/1.3.0/linkerd/index.html#http-headers)</span><span class="sxs-lookup"><span data-stu-id="0d7c3-206">linkerd: [Context Headers](https://linkerd.io/config/1.3.0/linkerd/index.html#http-headers)</span></span>
    
- <span data-ttu-id="0d7c3-207">로그 집계 방법을 고려합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-207">Consider how you will aggregate logs.</span></span> <span data-ttu-id="0d7c3-208">로그에서 상관 관계 ID를 포함하는 방법을 팀 간에 표준화할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-208">You may want to standardize across teams on how to include correlation IDs in logs.</span></span> <span data-ttu-id="0d7c3-209">JSON과 같은 구조화되거나 반구조화된 형식을 사용하고 상관 관계 ID를 보유하도록 공통 필드를 정의합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-209">Use a structured or semi-structured format, such as JSON, and define a common field to hold the correlation ID.</span></span>

## <a name="technology-options"></a><span data-ttu-id="0d7c3-210">기술 옵션</span><span class="sxs-lookup"><span data-stu-id="0d7c3-210">Technology options</span></span>

<span data-ttu-id="0d7c3-211">**Application Insights**는 원격 분석 데이터를 수집 및 저장하고 데이터 분석 및 검색을 위한 도구를 제공하는 Azure의 관리 서비스입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-211">**Application Insights** is a managed service in Azure that ingests and stores telemetry data, and provides tools for analyzing and searching the data.</span></span> <span data-ttu-id="0d7c3-212">Application Insights를 사용하려면 응용 프로그램에서 계측 패키지를 설치합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-212">To use Application Insights, you install an instrumentation package in your application.</span></span> <span data-ttu-id="0d7c3-213">이 패키지는 앱을 모니터링하고 원격 분석 데이터를 Application Insights 서비스로 보냅니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-213">This package monitors the app and sends telemetry data to the Application Insights service.</span></span> <span data-ttu-id="0d7c3-214">호스트 환경에서 원격 분석 데이터를 가져올 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-214">It can also pull telemetry data from the host environment.</span></span> <span data-ttu-id="0d7c3-215">Application Insights는 기본 제공 상관 관계 및 종속성 추적을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-215">Application Insights provides built-in correlation and dependency tracking.</span></span> <span data-ttu-id="0d7c3-216">시스템 메트릭, 응용 프로그램 메트릭 및 Azure 서비스 메트릭을 모두 한 곳에서 추적할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-216">It lets you track system metrics, application metrics, and Azure service metrics, all in one place.</span></span>

<span data-ttu-id="0d7c3-217">Application Insights는 데이터 속도가 최대 한도를 초과하는 경우를 제한합니다. 자세한 내용은 [Application Insights 제한](/azure/azure-subscription-service-limits#application-insights-limits)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-217">Be aware that Application Insights throttles if the data rate exceeds a maximum limit; for details, see [Application Insights limits](/azure/azure-subscription-service-limits#application-insights-limits).</span></span> <span data-ttu-id="0d7c3-218">단일 작업에서 여러 원격 분석 이벤트를 생성할 수 있으므로 응용 프로그램에 큰 용량의 트래픽이 있는 경우 제한될 가능성이 높습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-218">A single operation may generate several telemetry events, so if the application experiences a high volume of traffic, it is likely to get throttled.</span></span> <span data-ttu-id="0d7c3-219">이 문제를 완화하기 위해 원격 분석 트래픽을 줄이도록 샘플링을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-219">To mitigate this problem, you can perform sampling to reduce the telemetry traffic.</span></span> <span data-ttu-id="0d7c3-220">이 경우 메트릭은 덜 정확하게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-220">The tradeoff is that your metrics will be less precise.</span></span> <span data-ttu-id="0d7c3-221">자세한 내용은 [Application Insights의 샘플링](/azure/application-insights/app-insights-sampling)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-221">For more information, see [Sampling in Application Insights](/azure/application-insights/app-insights-sampling).</span></span> <span data-ttu-id="0d7c3-222">메트릭을 사전 집계하여 &mdash; 즉, 평균 및 표준 편차 등의 통계 값을 계산하고 원시 원격 분석 대신 해당 값을 전송하여 데이터 볼륨을 줄일 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-222">You can also reduce the data volume by pre-aggregating metrics &mdash; that is, calculating statistical values such as average and standard deviation, and sending those values instead of the raw telemetry.</span></span> <span data-ttu-id="0d7c3-223">다음 블로그 게시물 :[규모에서 Azure 모니터링 및 Analytics](https://blogs.msdn.microsoft.com/azurecat/2017/05/11/azure-monitoring-and-analytics-at-scale/)는 규모에서 Application Insights를 사용하는 방법을 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-223">The following blog post describes an approach to using Application Insights at scale: [Azure Monitoring and Analytics at Scale](https://blogs.msdn.microsoft.com/azurecat/2017/05/11/azure-monitoring-and-analytics-at-scale/).</span></span>

<span data-ttu-id="0d7c3-224">또한 데이터 양에 따라 요금이 청구되므로 Application Insights에 대한 가격 책정 모델을 이해해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-224">In addition, make sure that you understand the pricing model for Application Insights, because you are charged based on data volume.</span></span> <span data-ttu-id="0d7c3-225">자세한 내용은 [Application Insights에서 가격 책정 및 데이터 볼륨 관리](/azure/application-insights/app-insights-pricing)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-225">For more information, see [Manage pricing and data volume in Application Insights](/azure/application-insights/app-insights-pricing).</span></span> <span data-ttu-id="0d7c3-226">응용 프로그램에서 많은 양의 원격 분석을 생성하고 데이터의 샘플링 또는 집계를 수행하지 않으려는 경우 Application Insights는 적절한 선택이 아닐 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-226">If your application generates a large volume of telemetry, and you don't wish to perform sampling or aggregation of the data, then Application Insights may not be the appropriate choice.</span></span> 

<span data-ttu-id="0d7c3-227">Application Insights가 요구 사항을 충족하지 않는 경우 인기 있는 오픈 소스 기술을 사용하는 몇 가지 제안 방식은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-227">If Application Insights doesn't meet your requirements, here are some suggested approaches that use popular open-source technologies.</span></span>

<span data-ttu-id="0d7c3-228">시스템 및 컨테이너 메트릭의 경우 클러스터에서 실행되는 **Prometheus** 또는 **InfluxDB**와 같은 시계열 데이터베이스에 메트릭을 내보내는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-228">For system and container metrics, consider exporting metrics to a time-series database such as **Prometheus** or **InfluxDB** running in the cluster.</span></span>

- <span data-ttu-id="0d7c3-229">InfluxDB는 푸시 기반 시스템입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-229">InfluxDB is a push-based system.</span></span> <span data-ttu-id="0d7c3-230">에이전트는 메트릭을 푸시해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-230">An agent needs to push the metrics.</span></span> <span data-ttu-id="0d7c3-231">kubelet에서 클러스터 전체 메트릭을 수집하고, 데이터를 집계하고, InfluxDB 또는 다른 시계열 저장소 솔루션에 푸시하는 서비스인 [Heapster][heapster]를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-231">You can use [Heapster][heapster], which is a service that collects cluster-wide metrics from kubelet, aggregates the data, and pushes it to InfluxDB or other time-series storage solution.</span></span> <span data-ttu-id="0d7c3-232">Azure Container Service는 Heapster를 클러스터 설치의 일부로 배포합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-232">Azure Container Service deploys Heapster as part of the cluster setup.</span></span> <span data-ttu-id="0d7c3-233">또 다른 옵션은 메트릭을 수집 및 보고하기 위한 에이전트인 [Telegraf](https://www.influxdata.com/time-series-platform/telegraf/)입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-233">Another option is [Telegraf](https://www.influxdata.com/time-series-platform/telegraf/), which is an agent for collecting and reporting metrics.</span></span> 

- <span data-ttu-id="0d7c3-234">Prometheus는 풀 기반 시스템입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-234">Prometheus is a pull-based system.</span></span> <span data-ttu-id="0d7c3-235">구성된 위치에서 메트릭을 주기적으로 스크랩합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-235">It periodically scrapes metrics from configured locations.</span></span> <span data-ttu-id="0d7c3-236">Prometheus는 cAdvisor 또는 kube-상태-메트릭에 의해 생성된 메트릭을 스크랩할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-236">Prometheus can scrape metrics generated by cAdvisor or kube-state-metrics.</span></span> <span data-ttu-id="0d7c3-237">[kube-상태-메트릭][kube-state-metrics]은 Kubernetes API 서버에서 메트릭을 수집하고 Prometheus(또는 Prometheus 클라이언트 엔드포인트와 호환되는 스크레이퍼)에 사용할 수 있도록 하는 서비스입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-237">[kube-state-metrics][kube-state-metrics] is a service that collects metrics from the Kubernetes API server and makes them available to Prometheus (or a scraper that is compatible with a Prometheus client endpoint).</span></span> <span data-ttu-id="0d7c3-238">Heapster는 메트릭을 집계하는 반면 Kubernetes는 메트릭을 생성하고 싱크에 전달하고, kube-상태-메트릭은 자체 메트릭을 생성하고 스크랩에 대한 엔드포인트를 통해 사용할 수 있도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-238">Whereas Heapster aggregates metrics that Kubernetes generates and forwards them to a sink, kube-state-metrics generates its own metrics and makes them available through an endpoint for scraping.</span></span> <span data-ttu-id="0d7c3-239">시스템 메트릭의 경우 시스템 메트릭에 대한 Prometheus 내보내기인 [노드 내보내기](https://github.com/prometheus/node_exporter)를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-239">For system metrics, use [Node exporter](https://github.com/prometheus/node_exporter), which is a Prometheus exporter for system metrics.</span></span> <span data-ttu-id="0d7c3-240">Prometheus는 부동 소수점 데이터를 지원하지만 문자열 데이터를 지원하지 않으므로 로그가 아닌 시스템 메트릭에 적합합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-240">Prometheus supports floating point data, but not string data, so it is appropriate for system metrics but not logs.</span></span>

- <span data-ttu-id="0d7c3-241">**Kibana** 또는 **Grafana**와 같은 대시보드 도구를 사용하여 데이터를 시각화 및 모니터링합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-241">Use a dashboard tool such as **Kibana** or **Grafana** to visualize and monitor the data.</span></span> <span data-ttu-id="0d7c3-242">대시보드 서비스는 클러스터의 컨테이너 내부에서 실행될 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-242">The dashboard service can also run inside a container in the cluster.</span></span>

<span data-ttu-id="0d7c3-243">응용 프로그램 로그의 경우 **Fluentd** 및 **Elasticsearch**를 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-243">For application logs, consider using **Fluentd** and **Elasticsearch**.</span></span> <span data-ttu-id="0d7c3-244">Fluentd는 오픈 소스 데이터 수집기이며 Elasticsearch는 검색 엔진 역할에 최적화된 문서 데이터베이스입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-244">Fluentd is an open source data collector, and Elasticsearch is a document database that is optimized to act as a search engine.</span></span> <span data-ttu-id="0d7c3-245">이 방법을 사용하여 각 서비스는 로그를 `stdout` 및 `stderr`에 보내고 Kubernetes는 로컬 파일 시스템에 이러한 스트림을 작성합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-245">Using this approach, each service sends logs to `stdout` and `stderr`, and Kubernetes writes these streams to the local file system.</span></span> <span data-ttu-id="0d7c3-246">Fluentd는 로그를 수집하고, 경우에 따라 Kubernetes의 추가 메타데이터로 강화하고, 로그를 Elasticsearch에 보냅니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-246">Fluentd collects the logs, optionally enriches them with additional metadata from Kubernetes, and sends the logs to Elasticsearch.</span></span> <span data-ttu-id="0d7c3-247">Kibana, Grafana 또는 유사한 도구를 사용하여 Elasticsearch에 대한 대시보드를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-247">Use Kibana, Grafana, or a similar tool to create a dashboard for Elasticsearch.</span></span> <span data-ttu-id="0d7c3-248">Fluentd는 하나의 Fluentd Pod가 각 노드에 할당되도록 클러스터에서 DaemonSet으로 실행됩니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-248">Fluentd runs as a daemonset in the cluster, which ensures that one Fluentd pod is assigned to each node.</span></span> <span data-ttu-id="0d7c3-249">kubelet 로그 및 컨테이너 로그를 수집하도록 Fluentd를 구성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-249">You can configure Fluentd to collect kubelet logs as well as container logs.</span></span> <span data-ttu-id="0d7c3-250">높은 볼륨에서 로컬 파일 시스템에 로그를 작성하면 특히 여러 서비스가 동일한 노드에서 실행되는 경우 성능 병목 상태가 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-250">At high volumes, writing logs to the local file system could become a performance bottleneck, especially when multiple services are running on the same node.</span></span> <span data-ttu-id="0d7c3-251">프로덕션 환경에서 디스크 대기 시간 및 파일 시스템 사용률을 모니터링합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-251">Monitor disk latency and file system utilization in production.</span></span>

<span data-ttu-id="0d7c3-252">로그에 대한 Elasticsearch로 Fluentd를 사용하는 장점 중 하나는 서비스에 추가 라이브러리 종속성이 필요하지 않다는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-252">One advantage of using Fluentd with Elasticsearch for logs is that services do not require any additional library dependencies.</span></span> <span data-ttu-id="0d7c3-253">각 서비스는 `stdout` 및 `stderr`에 바로 작성하고 Fluentd는 Elasticsearch로 로그 내보내기를 처리합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-253">Each service just writes to `stdout` and `stderr`, and Fluentd handles exporting the logs into Elasticsearch.</span></span> <span data-ttu-id="0d7c3-254">또한 서비스를 작성하는 팀은 로깅 인프라를 구성하는 방법을 이해할 필요가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-254">Also, the teams writing services don't need to understand how to configure the logging infrastructure.</span></span> <span data-ttu-id="0d7c3-255">한 가지 문제는 트래픽을 처리할 수 있도록 확장하도록 프로덕션 배포에 대한 Elasticsearch 클러스터를 구성하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-255">One challenge is to configure the Elasticsearch cluster for a production deployment, so that it scales to handle your traffic.</span></span> 

<span data-ttu-id="0d7c3-256">다른 옵션은 OMS(Operations Management Suite) Log Analytics에 로그를 보내는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-256">Another option is to send logs to Operations Management Suite (OMS) Log Analytics.</span></span> <span data-ttu-id="0d7c3-257">[Log Analytics][log-analytics] 서비스는 중앙 리포지토리로 로그 데이터를 수집하고, 응용 프로그램에서 사용하는 다른 Azure 서비스의 데이터를 통합할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-257">The [Log Analytics][log-analytics] service collects log data into a central repository, and can also consolidate data from other Azure services that your application uses.</span></span> <span data-ttu-id="0d7c3-258">자세한 내용은 [Microsoft OMS(Operations Management Suite)를 사용하여 Azure Container Service 클러스터 모니터링][k8s-to-oms]을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-258">For more information, see [Monitor an Azure Container Service cluster with Microsoft Operations Management Suite (OMS)][k8s-to-oms].</span></span>

## <a name="example-logging-with-correlation-ids"></a><span data-ttu-id="0d7c3-259">예제: 상관 관계 ID를 사용하여 로깅</span><span class="sxs-lookup"><span data-stu-id="0d7c3-259">Example: Logging with correlation IDs</span></span>

<span data-ttu-id="0d7c3-260">이 챕터에서 설명한 사항 중 일부를 보여 주기 위해 패키지 서비스에서 로깅을 구현하는 방법의 확장된 예제는 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-260">To illustrate some of the points discussed in this chapter, here is an extended example of how the Package service implements logging.</span></span> <span data-ttu-id="0d7c3-261">패키지 서비스는 TypeScript에서 작성되었으며 Node.js용 [Koa](https://koajs.com/) 웹 프레임워크를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-261">The Package service was written in TypeScript and uses the [Koa](https://koajs.com/) web framework for Node.js.</span></span> <span data-ttu-id="0d7c3-262">여러 개의 Node.js 로깅 라이브러리에서 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-262">There are several Node.js logging libraries to choose from.</span></span> <span data-ttu-id="0d7c3-263">테스트했을 때 성능 요구 사항을 충족했던 일반적인 로깅 라이브러리인 [Winston](https://github.com/winstonjs/winston)을 선택했습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-263">We picked [Winston](https://github.com/winstonjs/winston), a popular logging library that met our performance requirements when we tested it.</span></span>

<span data-ttu-id="0d7c3-264">구현 세부 정보를 캡슐화하기 위해 추상 `ILogger` 인터페이스를 정의했습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-264">To encapsulate the implementation details, we defined an abstract  `ILogger` interface:</span></span>

```ts
export interface ILogger {
    log(level: string, msg: string, meta?: any)
    debug(msg: string, meta?: any)
    info(msg: string, meta?: any)
    warn(msg: string, meta?: any)
    error(msg: string, meta?: any)
}
```

<span data-ttu-id="0d7c3-265">다음은 Winston 라이브러리를 래핑하는 `ILogger` 구현입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-265">Here is an `ILogger` implementation that wraps the Winston library.</span></span> <span data-ttu-id="0d7c3-266">생성자 매개 변수로 상관 관계 ID를 사용하고 모든 로그 메시지에 ID를 삽입합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-266">It takes the correlation ID as a constructor parameter, and injects the ID into every log message.</span></span> 

```ts
class WinstonLogger implements ILogger {
    constructor(private correlationId: string) {}
    log(level: string, msg: string, payload?: any) {
        var meta : any = {};
        if (payload) { meta.payload = payload };
        if (this.correlationId) { meta.correlationId = this.correlationId }
        winston.log(level, msg, meta)
    }
  
    info(msg: string, payload?: any) {
        this.log('info', msg, payload);
    }
    debug(msg: string, payload?: any) {
        this.log('debug', msg, payload);
    }
    warn(msg: string, payload?: any) {
        this.log('warn', msg, payload);
    }
    error(msg: string, payload?: any) {
        this.log('error', msg, payload);
    }
}
```

<span data-ttu-id="0d7c3-267">패키지 서비스는 HTTP 요청에서 상관 관계 ID를 추출해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-267">The Package service needs to extract the correlation ID from the HTTP request.</span></span> <span data-ttu-id="0d7c3-268">예를 들어 linkerd를 사용하는 경우 상관 관계 ID는 `l5d-ctx-trace` 헤더에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-268">For example, if you're using linkerd, the correlation ID is found in the `l5d-ctx-trace` header.</span></span> <span data-ttu-id="0d7c3-269">Koa에서 HTTP 요청은 파이프라인 처리 요청을 통해 전달되는 컨텍스트 개체에 저장됩니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-269">In Koa, the HTTP request is stored in a Context object that gets passed through the request processing pipeline.</span></span> <span data-ttu-id="0d7c3-270">컨텍스트에서 상관 관계 ID를 가져오고 로거를 초기화하도록 미들웨어 함수를 정의할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-270">We can define a middleware function to get the correlation ID from the Context and initialize the logger.</span></span> <span data-ttu-id="0d7c3-271">(Koa의 미들웨어 함수는 단순히 각 요청에 대해 실행되는 함수입니다.)</span><span class="sxs-lookup"><span data-stu-id="0d7c3-271">(A middleware function in Koa is simply a function that gets executed for each request.)</span></span>

```ts
export type CorrelationIdFn = (ctx: Context) => string;

export function logger(level: string, getCorrelationId: CorrelationIdFn) {
    winston.configure({ 
        level: level,
        transports: [new (winston.transports.Console)()]
        });
    return async function(ctx: any, next: any) {
        ctx.state.logger = new WinstonLogger(getCorrelationId(ctx));
        await next();
    }
}
```

<span data-ttu-id="0d7c3-272">이 미들웨어는 상관 관계 ID를 가져오도록 호출자 정의 함수, `getCorrelationId`를 호출합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-272">This middleware invokes a caller-defined function, `getCorrelationId`, to get the correlation ID.</span></span> <span data-ttu-id="0d7c3-273">그런 다음 로거의 인스턴스를 만들고 `ctx.state` 내에 스태시합니다. 이는 Koa에서 파이프라인을 통해 정보를 전달하는 데 사용되는 키-값 사전입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-273">Then it creates an instance of the logger and stashes it inside `ctx.state`, which is a key-value dictionary used in Koa to pass information through the pipeline.</span></span> 

<span data-ttu-id="0d7c3-274">로거 미들웨어는 시작할 때 파이프라인에 추가됩니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-274">The logger middleware is added to the pipeline on startup:</span></span>

```ts
app.use(logger(Settings.logLevel(), function (ctx) {
    return ctx.headers[Settings.correlationHeader()];  
}));
```

<span data-ttu-id="0d7c3-275">모든 항목이 구성되면 코드에 로깅문을 추가하기 쉽습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-275">Once everything is configured, it's easy to add logging statements to the code.</span></span> <span data-ttu-id="0d7c3-276">예를 들어 다음은 패키지를 조회하는 메서드입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-276">For example, here is the method that looks up a package.</span></span> <span data-ttu-id="0d7c3-277">`ILogger.info` 메서드에 대한 두 호출을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-277">It makes two calls to the `ILogger.info` method.</span></span>

```ts
async getById(ctx: any, next: any) {
  var logger : ILogger = ctx.state.logger;
  var packageId = ctx.params.packageId;
  logger.info('Entering getById, packageId = %s', packageId);

  await next();

  let pkg = await this.repository.findPackage(ctx.params.packageId)

  if (pkg == null) {
    logger.info(`getById: %s not found`, packageId);
    ctx.response.status= 404;
    return;
  }

  ctx.response.status = 200;
  ctx.response.body = this.mapPackageDbToApi(pkg);
}
```

<span data-ttu-id="0d7c3-278">미들웨어 함수에 의해 자동으로 수행되기 때문에 로깅문에서 상관 관계 ID를 포함할 필요가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-278">We don't need to include the correlation ID in the logging statements, because that's done automatically by the middleware function.</span></span> <span data-ttu-id="0d7c3-279">이는 로깅 코드를 간결하게 하고 개발자가 상관 관계 ID를 포함하는 것을 잊어버릴 가능성을 줄입니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-279">This makes the logging code cleaner, and reduces the chance that a developer will forget to include the correlation ID.</span></span> <span data-ttu-id="0d7c3-280">또한 모든 로깅문은 추상 `ILogger` 인터페이스를 사용하므로 나중에 로거 구현을 쉽게 교체할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="0d7c3-280">And because all of the logging statements use the abstract `ILogger` interface, it would be easy to replace the logger implementation later.</span></span>

> [!div class="nextstepaction"]
> [<span data-ttu-id="0d7c3-281">지속적인 통합 및 업데이트</span><span class="sxs-lookup"><span data-stu-id="0d7c3-281">Continuous integration and delivery</span></span>](./ci-cd.md)

<!-- links -->

[app-insights]: /azure/application-insights/app-insights-overview
[heapster]: https://github.com/kubernetes/heapster
[kube-state-metrics]: https://github.com/kubernetes/kube-state-metrics
[k8s-to-oms]: /azure/container-service/kubernetes/container-service-kubernetes-oms
[log-analytics]: /azure/log-analytics/
