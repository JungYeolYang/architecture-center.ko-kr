---
title: 마이크로 서비스의 수집 및 워크플로
description: 마이크로 서비스의 수집 및 워크플로
author: MikeWasson
ms.date: 10/23/2018
ms.openlocfilehash: 5b39087297a05e5a59644c5ae1cf1f0334c996d0
ms.sourcegitcommit: fdcacbfdc77370532a4dde776c5d9b82227dff2d
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/24/2018
ms.locfileid: "49962924"
---
# <a name="designing-microservices-ingestion-and-workflow"></a><span data-ttu-id="7ee9b-103">마이크로 서비스 디자인: 수집 및 워크플로</span><span class="sxs-lookup"><span data-stu-id="7ee9b-103">Designing microservices: Ingestion and workflow</span></span>

<span data-ttu-id="7ee9b-104">마이크로 서비스에는 단일 트랜잭션을 위한 워크플로가 여러 서비스에 걸쳐있는 있는 경우가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-104">Microservices often have a workflow that spans multiple services for a single transaction.</span></span> <span data-ttu-id="7ee9b-105">워크플로에는 신뢰성이 필요합니다. 트랜잭션을 손실하거나 부분적으로 완료된 상태로 남겨 둘 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-105">The workflow must be reliable; it can't lose transactions or leave them in a partially completed state.</span></span> <span data-ttu-id="7ee9b-106">들어오는 요청의 수집 속도를 제어하는 것도 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-106">It's also critical to control the ingestion rate of incoming requests.</span></span> <span data-ttu-id="7ee9b-107">서로 통신하는 소규모 서비스가 많은 경우 들어오는 요청이 폭증하면 서비스 간 통신이 압도될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-107">With many small services communicating with each other, a burst of incoming requests can overwhelm the interservice communication.</span></span> 

![](./images/ingestion-workflow.png)

## <a name="the-drone-delivery-workflow"></a><span data-ttu-id="7ee9b-108">드론 배달 워크플로</span><span class="sxs-lookup"><span data-stu-id="7ee9b-108">The drone delivery workflow</span></span>

<span data-ttu-id="7ee9b-109">드론 배달 애플리케이션에서 배달을 예약하려면 다음 작업을 수행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-109">In the Drone Delivery application, the following operations must be performed to schedule a delivery:</span></span>

1. <span data-ttu-id="7ee9b-110">고객의 계정 상태를 확인합니다(계정 서비스).</span><span class="sxs-lookup"><span data-stu-id="7ee9b-110">Check the status of the customer's account (Account service).</span></span>
2. <span data-ttu-id="7ee9b-111">새 패키지 엔터티를 만듭니다(패키지 서비스).</span><span class="sxs-lookup"><span data-stu-id="7ee9b-111">Create a new package entity (Package service).</span></span>
3. <span data-ttu-id="7ee9b-112">픽업 및 배달 위치에 따라 타사 전송이 필요한지 확인합니다(타사 전송 서비스).</span><span class="sxs-lookup"><span data-stu-id="7ee9b-112">Check whether any third-party transportation is required for this delivery, based on the pickup and delivery locations (Third-party Transportation service).</span></span>
4. <span data-ttu-id="7ee9b-113">픽업을 위해 드론을 예약합니다(드론 서비스).</span><span class="sxs-lookup"><span data-stu-id="7ee9b-113">Schedule a drone for pickup (Drone service).</span></span>
5. <span data-ttu-id="7ee9b-114">새 배달 엔터티를 만듭니다(배달 서비스).</span><span class="sxs-lookup"><span data-stu-id="7ee9b-114">Create a new delivery entity (Delivery service).</span></span>

<span data-ttu-id="7ee9b-115">이것이 전체 애플리케이션의 핵심이므로 종단 간 프로세스가 성능 기준에 맞아야 할뿐만 아니라 신뢰성이 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-115">This is the core of the entire application, so the end-to-end process must be performant as well as reliable.</span></span> <span data-ttu-id="7ee9b-116">몇 가지 특정 과제를 반드시 해결해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-116">Some particular challenges must be addressed:</span></span>

- <span data-ttu-id="7ee9b-117">**부하 평준화**.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-117">**Load leveling**.</span></span> <span data-ttu-id="7ee9b-118">클라이언트 요청이 너무 많으면 서비스 간 네트워크 트래픽으로 인해 시스템이 압도될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-118">Too many client requests can overwhelm the system with interservice network traffic.</span></span> <span data-ttu-id="7ee9b-119">이로 인해 저장소나 원격 서비스와 같은 백 엔드 종속성이 압도될 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-119">It can also overwhelm backend dependencies such as storage or remote services.</span></span> <span data-ttu-id="7ee9b-120">이러한 문제는 시스템에서 역 압력(backpressure)을 생성하여 호출하는 서비스를 제한하는 방식으로 대응할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-120">These may react by throttling the services calling them, creating backpressure in the system.</span></span> <span data-ttu-id="7ee9b-121">따라서 시스템에 들어오는 요청을 버퍼나 큐에 넣어 처리하는 방식으로 요청의 부하를 평준화하는 것이 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-121">Therefore, it's important to load level the requests coming into the system, by putting them into a buffer or queue for processing.</span></span> 

- <span data-ttu-id="7ee9b-122">**배달 보장**.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-122">**Guaranteed delivery**.</span></span> <span data-ttu-id="7ee9b-123">클라이언트 요청이 누락되는 것을 방지하기 위해 수집 구성 요소는 한 번 이상의 메시지 배달을 반드시 보장해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-123">To avoid dropping any client requests, the ingestion component must guarantee at-least-once delivery of messages.</span></span> 

- <span data-ttu-id="7ee9b-124">**오류 처리**.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-124">**Error handling**.</span></span> <span data-ttu-id="7ee9b-125">오류를 반환하는 서비스가 있거나 일시적인 오류가 발생하면 배달을 예약할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-125">If any of the services returns an error code or experiences a non-transient failure, the delivery cannot be scheduled.</span></span> <span data-ttu-id="7ee9b-126">오류 코드는 예상되는 오류 상태(예: 고객의 계정이 중지됨) 또는 예기치 않은 서버 오류(HTTP 5xx)를 표시할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-126">An error code might indicate an expected error condition (for example, the customer's account is suspended) or an unexpected server error (HTTP 5xx).</span></span> <span data-ttu-id="7ee9b-127">서비스를 사용할 수 없어서 네트워크 호출 시간이 초과될 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-127">A service might also be unavailable, causing the network call to time out.</span></span> 

<span data-ttu-id="7ee9b-128">우선 수식의 수집 측면 &mdash; 즉 시스템에서 들어오는 사용자 요청을 높은 처리량으로 처리하는 방법을 살펴 보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-128">First we'll look at the ingestion side of the equation &mdash; how the system can ingest incoming user requests at high throughput.</span></span> <span data-ttu-id="7ee9b-129">그런 다음 무인 드론 배달 애플리케이션으로 안정적인 워크플로를 구현하는 방법을 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-129">Then we'll consider how the drone delivery application can implement a reliable workflow.</span></span> <span data-ttu-id="7ee9b-130">수집 하위 시스템 디자인은 워크플로 백 엔드에 영향을 미칩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-130">It turns out that the design of the ingestion subsystem affects the workflow backend.</span></span> 

## <a name="ingestion"></a><span data-ttu-id="7ee9b-131">수집</span><span class="sxs-lookup"><span data-stu-id="7ee9b-131">Ingestion</span></span>

<span data-ttu-id="7ee9b-132">개발 팀은 비즈니스 요구 사항을 기반으로 수집에 대해 다음과 같은 비기능적인 요구 사항을 파악했습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-132">Based on business requirements, the development team identified the following non-functional requirements for ingestion:</span></span>

- <span data-ttu-id="7ee9b-133">지속적인 처리량: 초당 요청 10,000건</span><span class="sxs-lookup"><span data-stu-id="7ee9b-133">Sustained throughput of 10K requests/sec.</span></span>
- <span data-ttu-id="7ee9b-134">클라이언트 요청 손실이나 시간 초과 없이 초당 최대 50,000건의 스파이크 처리 가능</span><span class="sxs-lookup"><span data-stu-id="7ee9b-134">Able to handle spikes of up to 50K/sec without dropping client requests or timing out.</span></span>
- <span data-ttu-id="7ee9b-135">99번째 백분위수에서 500밀리초 미만의 대기 시간</span><span class="sxs-lookup"><span data-stu-id="7ee9b-135">Less than 500ms latency in the 99th percentile.</span></span>

<span data-ttu-id="7ee9b-136">트래픽에 종종 발생하는 스파이크를 처리하기 위한 요구 사항으로 인해 디자인에 어려움이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-136">The requirement to handle occasional spikes in traffic presents a design challenge.</span></span> <span data-ttu-id="7ee9b-137">이론상으로는 최대 예상 트래픽을 처리하도록 시스템을 확장할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-137">In theory, the system could be scaled out to handle the maximum expected traffic.</span></span> <span data-ttu-id="7ee9b-138">그러나 많은 자원을 프로비전하는 것은 매우 비효율적입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-138">However, provisioning that many resources would be very inefficient.</span></span> <span data-ttu-id="7ee9b-139">대부분의 경우, 애플리케이션에 그만큼의 용량이 필요하지 않아서 유휴 코어가 발생하기 때문에 가치는 창출하지 않고 비용만 소비하게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-139">Most of the time, the application will not need that much capacity, so there would be idle cores, costing money without adding value.</span></span>

<span data-ttu-id="7ee9b-140">더 좋은 방법은 들어오는 요청을 버퍼에 넣고 버퍼를 부하 평준화 도구로 작동시키는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-140">A better approach is to put the incoming requests into a buffer, and let the buffer act as a load leveler.</span></span> <span data-ttu-id="7ee9b-141">이렇게 디자인하면 수집 서비스는 짧은 기간 동안 최대 수집 속도를 처리할 수 있어야 하지만 백 엔드 서비스는 최대 지속 부하만 처리하면 됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-141">With this design, the Ingestion service must be able to handle the maximum ingestion rate over short periods, but the backend services only need to handle the maximum sustained load.</span></span> <span data-ttu-id="7ee9b-142">프런트 엔드에서 버퍼링을 하기 때문에 백엔드 서비스는 트래픽의 대규모 스파이크를 처리할 필요가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-142">By buffering at the front end, the backend services shouldn't need to handle large spikes in traffic.</span></span> <span data-ttu-id="7ee9b-143">드론 배달 애플리케이션에 필요한 규모에서 [Azure Event Hubs](/azure/event-hubs/)는 부하 평준화에 적합한 선택입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-143">At the scale required for the Drone Delivery application, [Azure Event Hubs](/azure/event-hubs/) is a good choice for load leveling.</span></span> <span data-ttu-id="7ee9b-144">Event Hubs는 낮은 대기 시간과 높은 처리량을 제공하며 수집 볼륨이 많은 경우에 비용 효율적인 솔루션입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-144">Event Hubs offers low latency and high throughput, and is a cost effective solution at high ingestion volumes.</span></span> 

<span data-ttu-id="7ee9b-145">테스트에서는 파티션이 32개이고 처리량 단위가 100인 표준 계층 이벤트 허브를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-145">For our testing, we used a Standard tier event hub with 32 partitions and 100 throughput units.</span></span> <span data-ttu-id="7ee9b-146">대기 시간 90밀리초, 초당 32,000개 정도의 이벤트 수집이 관찰되었습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-146">We observed about 32K events / second ingestion, with latency around 90ms.</span></span> <span data-ttu-id="7ee9b-147">현재 기본 제한 처리량 단위는 20이지만 Azure 고객이 지원 요청을 입력하여 처리량 단위를 추가로 요청할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-147">Currently the default limit is 20 throughput units, but Azure customers can request additional throughput units by filing a support request.</span></span> <span data-ttu-id="7ee9b-148">자세한 내용은 [Event Hubs 할당량](/azure/event-hubs/event-hubs-quotas)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-148">See [Event Hubs quotas](/azure/event-hubs/event-hubs-quotas) for more information.</span></span> <span data-ttu-id="7ee9b-149">모든 성능 메트릭과 마찬가지로 메시지 페이로드 크기와 같은 여러 요소가 성능에 영향을 줄 수 있으므로 이러한 수치를 벤치마크로 해석하지 않도록 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-149">As with all performance metrics, many factors can affect performance, such as message payload size, so don't interpret these numbers as a benchmark.</span></span> <span data-ttu-id="7ee9b-150">처리량이 더 필요한 경우 수집 서비스는 둘 이상의 이벤트 허브에서 분할될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-150">If more throughput is needed, the Ingestion service can shard across more than one event hub.</span></span> <span data-ttu-id="7ee9b-151">훨씬 더 높은 처리량 속도를 위해 [전용 Event Hubs](/azure/event-hubs/event-hubs-dedicated-overview)에 초당 2백만 개 이상의 이벤트를 수신할 수 있는 단일 테넌트 배포가 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-151">For even higher throughput rates, [Event Hubs Dedicated](/azure/event-hubs/event-hubs-dedicated-overview) offers single-tenant deployments that can ingress over 2 million events per second.</span></span>

<span data-ttu-id="7ee9b-152">Event Hubs에서 이렇게 높은 처리량을 구현하는 방법을 이해하는 것은 중요합니다. 클라이언트가 Event Hubs의 메시지를 소비하는 방법에 영향을 미치기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-152">It's important to understand how Event Hubs can achieve such high throughput, because that affects how a client should consume messages from Event Hubs.</span></span> <span data-ttu-id="7ee9b-153">Event Hubs는 *큐*를 구현하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-153">Event Hubs does not implement a *queue*.</span></span> <span data-ttu-id="7ee9b-154">대신 *이벤트 스트림*을 구현합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-154">Rather, it implements an *event stream*.</span></span> 

<span data-ttu-id="7ee9b-155">큐를 사용하면 개별 소비자가 큐에서 메시지를 제거할 수 있어서 다음 소비자가 해당 메시지를 볼 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-155">With a queue, an individual consumer can remove a message from the queue, and the next consumer won't see that message.</span></span> <span data-ttu-id="7ee9b-156">따라서 큐를 사용하면 [경쟁 소비자 패턴](../patterns/competing-consumers.md)을 사용하여 메시지를 병렬 처리하고 확장성을 높일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-156">Queues therefore allow you to use a [Competing Consumers pattern](../patterns/competing-consumers.md) to process messages in parallel and improve scalability.</span></span> <span data-ttu-id="7ee9b-157">복원력을 높이기 위해 소비자는 메시지를 잠근 상태로 유지하고 메시지 처리가 완료되면 잠금을 해제합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-157">For greater resiliency, the consumer holds a lock on the message and releases the lock when it's done processing the message.</span></span> <span data-ttu-id="7ee9b-158">소비자가 실패하면 &mdash;예를 들어, 실행 중인 노드가 충돌하면&mdash; 잠금 시간이 초과되고 메시지는 큐로 다시 돌아갑니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-158">If the consumer fails &mdash; for example, the node it's running on crashes &mdash; the lock times out and the message goes back onto the queue.</span></span> 

![](./images/queue-semantics.png)

<span data-ttu-id="7ee9b-159">반면에 Event Hubs는 스트리밍 의미 체계를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-159">Event Hubs, on the other hand, uses streaming semantics.</span></span> <span data-ttu-id="7ee9b-160">소비자는 자신의 속도에 맞게 독립적으로 스트림을 읽습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-160">Consumers read the stream independently at their own pace.</span></span> <span data-ttu-id="7ee9b-161">각 소비자는 스트림에서 현재 위치를 추적하는 일을 담당합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-161">Each consumer is responsible for keeping track of its current position in the stream.</span></span> <span data-ttu-id="7ee9b-162">소비자는 미리 정의된 간격으로 영구 저장소에 현재 위치를 기록해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-162">A consumer should write its current position to persistent storage at some predefined interval.</span></span> <span data-ttu-id="7ee9b-163">이렇게 하면 소비자에게 오류가 발생하는 경우(예: 소비자에게 충돌이나 호스트 장애가 발생하는 경우) 새 인스턴스가 마지막으로 기록된 위치에서 스트림 읽기를 다시 시작할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-163">That way, if the consumer experiences a fault (for example, the consumer crashes, or the host fails), then a new instance can resume reading the stream from the last recorded position.</span></span> <span data-ttu-id="7ee9b-164">이러한 프로세스를 *검사점 설정*이라고 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-164">This process is called *checkpointing*.</span></span> 

<span data-ttu-id="7ee9b-165">성능을 위해 소비자는 일반적으로 각 메시지 이후에 검사점을 설정하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-165">For performance reasons, a consumer generally doesn't checkpoint after each message.</span></span> <span data-ttu-id="7ee9b-166">대신 고정된 간격으로(예: *n*개 메시지를 처리한 후 또는 *n*초마다) 검사점을 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-166">Instead, it checkpoints at some fixed interval, for example after processing *n* messages, or every *n* seconds.</span></span> <span data-ttu-id="7ee9b-167">결과적으로 소비자에게 오류가 발생하면 마지막 검사점에서 새 인스턴스를 항상 픽업하기 때문에 일부 이벤트는 두 번 처리될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-167">As a consequence, if a consumer fails, some events may get processed twice, because a new instance always picks up from the last checkpoint.</span></span> <span data-ttu-id="7ee9b-168">여기에는 장단점이 있습니다. 검사점이 빈번하면 성능이 저하될 수 있지만 검사점이 드물면 오류가 발생한 후 더 많은 이벤트를 다시 재생합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-168">There is a tradeoff: Frequent checkpoints can hurt performance, but sparse checkpoints mean you will replay more events after a failure.</span></span>  

![](./images/stream-semantics.png)
 
<span data-ttu-id="7ee9b-169">Event Hubs는 경쟁 소비자에 맞게 설계되지 않았습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-169">Event Hubs is not designed for competing consumers.</span></span> <span data-ttu-id="7ee9b-170">여러 소비자가 하나의 스트림을 읽을 수 있지만 각 소비자는 스트림을 독립적으로 통과합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-170">Although multiple consumers can read a stream, each traverses the stream independently.</span></span> <span data-ttu-id="7ee9b-171">대신 Event Hubs는 분할된 소비자 패턴을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-171">Instead, Event Hubs uses a partitioned consumer pattern.</span></span> <span data-ttu-id="7ee9b-172">이벤트 허브에는 최대 32개의 파티션이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-172">An event hub has up to 32 partitions.</span></span> <span data-ttu-id="7ee9b-173">수평 확장은 각 파티션에 별도의 소비자를 할당하여 구현됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-173">Horizontal scale is achieved by assigning a separate consumer to each partition.</span></span>

<span data-ttu-id="7ee9b-174">이것은 드론 배달 워크플로에 어떤 의미일까요?</span><span class="sxs-lookup"><span data-stu-id="7ee9b-174">What does this mean for the drone delivery workflow?</span></span> <span data-ttu-id="7ee9b-175">Event Hubs를 최대한 활용하기 위해서 Delivery Scheduler는 다음 메시지로 이동하기 전에 각 메시지가 처리되기를 기다릴 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-175">To get the full benefit of Event Hubs, the Delivery Scheduler cannot wait for each message to be processed before moving onto the next.</span></span> <span data-ttu-id="7ee9b-176">만약 그렇게 되면 대부분의 시간을 네트워크 호출이 완료되기를 기다리는 데 소비하게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-176">If it does that, it will spend most of its time waiting for network calls to complete.</span></span> <span data-ttu-id="7ee9b-177">대신 백 엔드 서비스에 대한 비동기 호출을 사용하여 일괄 처리 메시지를 병렬로 처리해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-177">Instead, it needs to process batches of messages in parallel, using asynchronous calls to the backend services.</span></span> <span data-ttu-id="7ee9b-178">앞으로 살펴보겠지만 올바른 검사점 설정 전략을 선택하는 것도 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-178">As we'll see, choosing the right checkpointing strategy is also important.</span></span>  

## <a name="workflow"></a><span data-ttu-id="7ee9b-179">워크플로</span><span class="sxs-lookup"><span data-stu-id="7ee9b-179">Workflow</span></span>

<span data-ttu-id="7ee9b-180">메시지를 읽고 처리하는 이벤트 프로세서 호스트, Service Bus 큐 및 IoTHub React 라이브러리라는 세 가지 옵션을 살펴보았습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-180">We looked at three options for reading and processing the messages: Event Processor Host, Service Bus queues, and the IoTHub React library.</span></span> <span data-ttu-id="7ee9b-181">IoTHub React를 선택했지만 이유를 이해하기 위해서는 이벤트 프로세서 호스트부터 시작하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-181">We chose IoTHub React, but to understand why, it helps to start with Event Processor Host.</span></span> 

### <a name="event-processor-host"></a><span data-ttu-id="7ee9b-182">이벤트 프로세서 호스트</span><span class="sxs-lookup"><span data-stu-id="7ee9b-182">Event Processor Host</span></span>

<span data-ttu-id="7ee9b-183">이벤트 프로세서 호스트는 메시지 일괄 처리를 위해 설계되었습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-183">Event Processor Host is designed for message batching.</span></span> <span data-ttu-id="7ee9b-184">애플리케이션은 `IEventProcessor` 인터페이스를 구현하고 프로세서 호스트는 이벤트 허브의 각 파티션에 대해 하나의 이벤트 허브 프로세서를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-184">The application implements the `IEventProcessor` interface, and the Processor Host creates one event processor instance for each partition in the event hub.</span></span> <span data-ttu-id="7ee9b-185">그런 다름 이벤트 프로세서 호스트는 각 이벤트 프로세서의 `ProcessEventsAsync` 메서드를 일괄 처리 이벤트 메시지와 함께 호출합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-185">The Event Processor Host then calls each event processor's `ProcessEventsAsync` method with batches of event messages.</span></span> <span data-ttu-id="7ee9b-186">애플리케이션은 `ProcessEventsAsync` 메서드 내에서 검사점을 설정할 시기를 제어하고 이벤트 프로세서 호스트는 Azure 저장소에 검사점을 작성합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-186">The application controls when to checkpoint inside the `ProcessEventsAsync` method, and the Event Processor Host writes the checkpoints to Azure storage.</span></span> 

<span data-ttu-id="7ee9b-187">파티션 내에서 이벤트 프로세서 호스트는 다음 일괄 처리를 다시 호출하기 전에 반환할 `ProcessEventsAsync`를 기다립니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-187">Within a partition, Event Processor Host waits for `ProcessEventsAsync` to return before calling again with the next batch.</span></span> <span data-ttu-id="7ee9b-188">이 방법은 이벤트 처리 코드를 재진입할 필요가 없기 때문에 프로그래밍 모델을 간소화합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-188">This approach simplifies the programming model, because your event processing code doesn't need to be reentrant.</span></span> <span data-ttu-id="7ee9b-189">하지만 이벤트 프로세서가 한 번에 하나의 일괄 처리를 수행하기 때문에 프로세서 호스트가 메시지를 펌핑할 수 있는 속도를 제어합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-189">However, it also means that the event processor handles one batch at a time, and this gates the speed at which the Processor Host can pump messages.</span></span>

> [!NOTE] 
> <span data-ttu-id="7ee9b-190">프로세서 호스트는 스레드를 차단하는 의미로 *대기*하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-190">The Processor Host doesn't actually *wait* in the sense of blocking a thread.</span></span> <span data-ttu-id="7ee9b-191">`ProcessEventsAsync` 메서드가 비동기식이기 때문에 프로세서 호스트는 메서드가 완료되는 동안 다른 작업을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-191">The `ProcessEventsAsync` method is asynchronous, so the Processor Host can do other work while the method is completing.</span></span> <span data-ttu-id="7ee9b-192">하지만 메서드가 반환될 때 까지 해당 파티션에 대해 다른 일괄 처리 메시지를 전달하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-192">But it won't deliver another batch of messages for that partition until the method returns.</span></span> 

<span data-ttu-id="7ee9b-193">드론 애플리케이션에서 일괄 처리 메시지는 병렬로 처리될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-193">In the drone application, a batch of messages can be processed in parallel.</span></span> <span data-ttu-id="7ee9b-194">하지만 전체 일괄 처리가 완료되기까지 대기하면 병목 현상이 여전히 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-194">But waiting for the whole batch to complete can still cause a bottleneck.</span></span> <span data-ttu-id="7ee9b-195">처리 속도는 일괄 처리 내에서 가장 느린 메시지 만큼만 빠를 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-195">Processing can only be as fast as the slowest message within a batch.</span></span> <span data-ttu-id="7ee9b-196">응답 시간이 변하면 "꼬리가 길어질 수” 있으며 느린 응답으로 인해 전체 시스템이 느려질 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-196">Any variation in response times can create a "long tail," where a few slow responses drag down the entire system.</span></span> <span data-ttu-id="7ee9b-197">성능 테스트에 따르면 이러한 방법을 사용하여 목표 처리량을 달성하지 못한 것으로 나타났습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-197">Our performance tests showed that we did not achieve our target throughput using this approach.</span></span> <span data-ttu-id="7ee9b-198">그렇다고 이벤트 프로세서 호스트를 사용하지 말아야 한다는 것을 의미하지는 *않습니다*.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-198">This does *not* mean that you should avoid using Event Processor Host.</span></span> <span data-ttu-id="7ee9b-199">하지만 처리량을 높이려면 `ProcesssEventsAsync` 메서드 내에서 오래 실행되는 작업을 수행하지 마십시오.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-199">But for high throughput, avoid doing any long-running tasks inside the `ProcesssEventsAsync` method.</span></span> <span data-ttu-id="7ee9b-200">각각의 일괄 처리를 신속하게 처리하십시오.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-200">Process each batch quickly.</span></span>

### <a name="iothub-react"></a><span data-ttu-id="7ee9b-201">IotHub React</span><span class="sxs-lookup"><span data-stu-id="7ee9b-201">IotHub React</span></span> 

<span data-ttu-id="7ee9b-202">[IotHub React](https://github.com/Azure/toketi-iothubreact)는 Event Hub의 이벤트를 읽는 Akka Streams 라이브러리입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-202">[IotHub React](https://github.com/Azure/toketi-iothubreact) is an Akka Streams library for reading events from Event Hub.</span></span> <span data-ttu-id="7ee9b-203">Akka Streams는 [Reactive Streams](https://www.reactive-streams.org/) 사양을 구현하는 스트림 기반 프로그래밍 프레임워크입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-203">Akka Streams is a stream-based programming framework that implements the [Reactive Streams](https://www.reactive-streams.org/) specification.</span></span> <span data-ttu-id="7ee9b-204">모든 스트리밍 작업이 비동기적으로 수행되고 파이프라인은 정상적으로 역 압력(backpressure)을 처리는 효율적인 스트리밍 파이프라인을 구축하는 방법을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-204">It provides a way to build efficient streaming pipelines, where all streaming operations are performed asynchronously, and the pipeline gracefully handles backpressure.</span></span> <span data-ttu-id="7ee9b-205">역 압력(backpressure)은 이벤트 원본이 다운스트림 소비자가 수신할 수 있는 것보다 빠른 속도로 이벤트를 생성하는 경우 발생하며 &mdash; 드론 배달 시스템의 트래픽이 급증하는 상황과 정확히 일치합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-205">Backpressure occurs when an event source produces events at a faster rate than the downstream consumers can receive them &mdash; which is exactly the situation when the drone delivery system has a spike in traffic.</span></span> <span data-ttu-id="7ee9b-206">백 엔드 서비스가 느려지면 IoTHub React가 느려집니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-206">If backend services go slower, IoTHub React will slow down.</span></span> <span data-ttu-id="7ee9b-207">용량이 증가하면 IoTHub React는 파이프라인을 통해 더 많은 메시지를 푸시합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-207">If capacity is increased, IoTHub React will push more messages through the pipeline.</span></span>

<span data-ttu-id="7ee9b-208">Akka Streams는 Event Hubs의 스트리밍 이벤트의 매우 자연스러운 프로그래밍 모델이기도 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-208">Akka Streams is also a very natural programming model for streaming events from Event Hubs.</span></span> <span data-ttu-id="7ee9b-209">일괄 처리 이벤트를 반복하는 대신 각 이벤트에 적용할 작업 집합을 정의하여 Akka Streams에서 스트리밍을 처리하도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-209">Instead of looping through a batch of events, you define a set of operations that will be applied to each event, and let Akka Streams handle the streaming.</span></span> <span data-ttu-id="7ee9b-210">Akka Streams는 *소스*, *흐름* 및 *싱크* 측면에서 스트리밍 파이프라인을 정의합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-210">Akka Streams defines a streaming pipeline in terms of *Sources*, *Flows*, and *Sinks*.</span></span> <span data-ttu-id="7ee9b-211">원본은 출력 스트림을 생성하고, 흐름은 입력 스트림을 처리하고 출력 스트림을 생성하며, 싱크는 출력을 생성하지 않고 스트림을 소비합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-211">A source generates an output stream, a flow processes an input stream and produces an output stream, and a sink consumes a stream without producing any output.</span></span>

<span data-ttu-id="7ee9b-212">Akka Streams 파이프라인을 설정하는 Scheduler 서비스의 코드는 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-212">Here is the code in the Scheduler service that sets up the Akka Streams pipeline:</span></span>

```java
IoTHub iotHub = new IoTHub();
Source<MessageFromDevice, NotUsed> messages = iotHub.source(options);

messages.map(msg -> DeliveryRequestEventProcessor.parseDeliveryRequest(msg))
        .filter(ad -> ad.getDelivery() != null).via(deliveryProcessor()).to(iotHub.checkpointSink())
        .run(streamMaterializer);
```

<span data-ttu-id="7ee9b-213">이 코드는 Event Hubs를 원본으로 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-213">This code configures Event Hubs as a source.</span></span> <span data-ttu-id="7ee9b-214">`map` 문은 배달 요청을 나타내는 Java 클래스로 각 이벤트 메시지를 deserialize합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-214">The `map` statement deserializes each event message into a Java class that represents a delivery request.</span></span> <span data-ttu-id="7ee9b-215">`filter` 문은 스트림에서 `null` 개체를 제거하며, 이를 통해 메시지를 deserialize할 수 없는 경우에 대비합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-215">The `filter` statement removes any `null` objects from the stream; this guards against the case where a message can't be deserialized.</span></span> <span data-ttu-id="7ee9b-216">`via` 문은 각 배달 요청을 처리하는 흐름에 원본을 조언합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-216">The `via` statement joins the source to a flow that processes each delivery request.</span></span> <span data-ttu-id="7ee9b-217">`to` 메서드는 IoTHub React에 내장된 검사점 싱크에 흐름을 조인합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-217">The `to` method joins the flow to the checkpoint sink, which is built into IoTHub React.</span></span>

<span data-ttu-id="7ee9b-218">IoTHub React는 이벤트 호스트 프로세서와 다른 검사점 설정 전략을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-218">IoTHub React uses a different checkpointing strategy than Event Host Processor.</span></span> <span data-ttu-id="7ee9b-219">검사점은 파이프라인의 종료 단계인 검사점 싱크에 의해 작성됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-219">Checkpoints are written by the checkpoint sink, which is the terminating stage in the pipeline.</span></span> <span data-ttu-id="7ee9b-220">Akka Streams 디자인을 사용하면 싱크에서 검사점을 작성하는 동안 파이프라인에서 스트리밍을 계속 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-220">The design of Akka Streams allows the pipeline to continue streaming data while the sink is writing the checkpoint.</span></span> <span data-ttu-id="7ee9b-221">즉, 검사점이 설정될 때까지 업스트림 프로세싱 단계가 기다릴 필요가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-221">That means the upstream processing stages don't need to wait for checkpointing to happen.</span></span> <span data-ttu-id="7ee9b-222">시간이 초과된 후 또는 특정 수의 메시지가 처리된 후 검사점이 설정되도록 구성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-222">You can configure checkpointing to occur after a timeout or after a certain number of messages have been processed.</span></span>

<span data-ttu-id="7ee9b-223">`deliveryProcessor` 메서드는 Akka Streams 흐름을 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-223">The `deliveryProcessor` method creates the Akka Streams flow:</span></span>  

```java
private static Flow<AkkaDelivery, MessageFromDevice, NotUsed> deliveryProcessor() {
    return Flow.of(AkkaDelivery.class).map(delivery -> {
        CompletableFuture<DeliverySchedule> completableSchedule = DeliveryRequestEventProcessor
                .processDeliveryRequestAsync(delivery.getDelivery(), 
                        delivery.getMessageFromDevice().properties());
        
        completableSchedule.whenComplete((deliverySchedule,error) -> {
            if (error!=null){
                Log.info("failed delivery" + error.getStackTrace());
            }
            else{
                Log.info("Completed Delivery",deliverySchedule.toString());
            }
                                
        });
        completableSchedule = null;
        return delivery.getMessageFromDevice();
    });
}
```

<span data-ttu-id="7ee9b-224">이 흐름은 각 메시지를 처리하는 실제 작업을 수행하는 정적 `processDeliveryRequestAsync` 메서드를 호출합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-224">The flow calls a static `processDeliveryRequestAsync` method that does the actual work of processing each message.</span></span>

### <a name="scaling-with-iothub-react"></a><span data-ttu-id="7ee9b-225">IoTHub React로 크기 조정</span><span class="sxs-lookup"><span data-stu-id="7ee9b-225">Scaling with IoTHub React</span></span>

<span data-ttu-id="7ee9b-226">Scheduler 서비스는 각 컨테이너 인스턴스가 단일 파티션에서 읽을 수 있도록 설계되었습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-226">The Scheduler service is designed so that each container instance reads from a single partition.</span></span> <span data-ttu-id="7ee9b-227">예를 들어 Event Hubs에 32개의 파티션이 있는 경우 Scheduler 서비스는 32개의 복제본으로 배포됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-227">For example, if the Event Hub has 32 partitions, the Scheduler service is deployed with 32 replicas.</span></span> <span data-ttu-id="7ee9b-228">따라서 수평 확장의 측면에서 유연성이 큽니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-228">This allows for a lot of flexibility in terms of horizontal scaling.</span></span> 

<span data-ttu-id="7ee9b-229">클러스터의 크기에 따라 클러스터의 노드에 둘 이상의 Scheduler 서비스 Pod가 실행 중일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-229">Depending on the size of the cluster, a node in the cluster might have more than one Scheduler service pod running on it.</span></span> <span data-ttu-id="7ee9b-230">하지만 Scheduler 서비스에 리소스가 더 필요하면 더 많은 노드에 Pod를 배포하기 위해 클러스터를 확장할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-230">But if the Scheduler service needs more resources, the cluster can be scaled out, in order to distribute the pods across more nodes.</span></span> <span data-ttu-id="7ee9b-231">성능 테스트에 따르면 Scheduler 서비스는 메모리 및 스레드에 바운딩되므로 VM 크기와 노드당 Pod 수에 따라 성능이 크게 달라지는 것으로 나타납니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-231">Our performance tests showed that the Scheduler service is memory- and thread-bound, so performance depended greatly on the VM size and the number of pods per node.</span></span>

<span data-ttu-id="7ee9b-232">각 인스턴스는 읽을 수 있는 Event Hubs 파티션을 알아야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-232">Each instance needs to know which Event Hubs partition to read from.</span></span> <span data-ttu-id="7ee9b-233">파티션 번호를 구성하기 위해 Kubernetes의 [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) 리소스 유형이 활용되었습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-233">To configure the partition number, we took advantage of the [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) resource type in Kubernetes.</span></span> <span data-ttu-id="7ee9b-234">StatefulSet의 Pod에는 숫자 인덱스가 포함된 영구 식별자가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-234">Pods in a StatefulSet have a persistent identifier that includes a numeric index.</span></span> <span data-ttu-id="7ee9b-235">구체적으로 Pod 이름은 `<statefulset name>-<index>`이며 Kubernetes [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/)를 통해 컨테이너에서 이 값을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-235">Specifically, the pod name is `<statefulset name>-<index>`, and this value is available to the container through the Kubernetes [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span></span> <span data-ttu-id="7ee9b-236">런타임 시 Scheduler 서비스는 Pod 이름을 읽고 Pod 인덱스를 파티션 ID로 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-236">At run time, the Scheduler services reads the pod name and uses the pod index as the partition ID.</span></span>

<span data-ttu-id="7ee9b-237">Scheduler 서비스를 훨씬 더 확장해야 하는 경우 이벤트 허브 파티션 당 둘 이상의 Pod를 지정하여 여러 개의 Pod가 각 파티션을 읽도록 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-237">If you needed to scale out the Scheduler service even further, you could assign more than one pod per event hub partition, so that multiple pods are reading each partition.</span></span> <span data-ttu-id="7ee9b-238">단, 이런 경우 각 인스턴스는 할당된 파티션의 모든 이벤트를 읽습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-238">However, in that case, each instance would read all of the events in the assigned partition.</span></span> <span data-ttu-id="7ee9b-239">중복 처리를 방지하려면 각 인스턴스가 메시지의 일부를 건너뛸 수 있도록 해싱 알고리즘을 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-239">To avoid duplicate processing, you would need to use a hashing algorithm, so that each instance skips over a portion of the messages.</span></span> <span data-ttu-id="7ee9b-240">이렇게 하면 여러 판독기가 스트림을 소비할 수 있지만 모든 메시지는 하나의 인스턴스에서만 처리됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-240">That way, multiple readers can consume the stream, but every message is processed by only one instance.</span></span> 
 
![](./images/eventhub-hashing.png)

### <a name="service-bus-queues"></a><span data-ttu-id="7ee9b-241">Service Bus 큐</span><span class="sxs-lookup"><span data-stu-id="7ee9b-241">Service Bus queues</span></span>

<span data-ttu-id="7ee9b-242">세 번째로 고려한 옵션은 Event Hubs의 메시지를 Service Bus 큐에 복사한 다음 Scheduler 서비스에서 Service Bus의 메시지를 읽도록 하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-242">A third option that we considered was to copy messages from Event Hubs into a Service Bus queue, and then have the Scheduler service read the messages from Service Bus.</span></span> <span data-ttu-id="7ee9b-243">들어오는 요청을 Service Bus에 복사하기 위해서 Event Hubs에 쓰는 것이 생소할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-243">It might seem strange to writing the incoming requests into Event Hubs only to copy them in Service Bus.</span></span>  <span data-ttu-id="7ee9b-244">하지만 이것은 각 서비스의 다양한 장점을 활용하기 위한 아이디어입니다. Event Hubs를 사용하여 많이 사용되는 트래픽이 급증하면 흡수하고 Service Bus의 큐 의미 체계를 활용하여 경쟁 소비자 패턴으로 워크로드를 처리합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-244">However, the idea was to leverage the different strengths of each service: Use Event Hubs to absorb spikes of heavy traffic, while taking advantage of the queue semantics in Service Bus to process the workload with a competing consumers pattern.</span></span> <span data-ttu-id="7ee9b-245">지속적인 처리량에 대한 목표가 예상한 피크 부하보다 적기 때문에 Service Bus 큐를 처리하는 속도가 메시지 수집 속도만큼 빠를 필요가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-245">Remember that our target for sustained throughput is less than our expected peak load, so processing the Service Bus queue would not need to be as fast the message ingestion.</span></span>
 
<span data-ttu-id="7ee9b-246">이 접근 방식을 사용한 개념 증명 구현을 통해 초당 약 4000건의 작업이 수행되었습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-246">With this approach, our proof-of-concept implementation achieved about 4K operations per second.</span></span> <span data-ttu-id="7ee9b-247">이 테스트에서 실제 작업을 수행하지 않는 모의 백 엔드 서비스가 사용되고 서비스당 일정한 대기 시간만 추가되었습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-247">These tests used mock backend services that did not do any real work, but simply added a fixed amount of latency per service.</span></span> <span data-ttu-id="7ee9b-248">성능 수치는 Service Bus에 대한 이론적인 최대치보다 훨씬 적습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-248">Note that our performance numbers were much less than the theoretical maximum for Service Bus.</span></span> <span data-ttu-id="7ee9b-249">불일치에 대한 잠재적인 원인은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-249">Possible reasons for the discrepancy include:</span></span>

- <span data-ttu-id="7ee9b-250">연결 풀 제한, 병렬 처리 수준, 프리페치 수 및 일괄 처리 크기와 같은 다양한 클라이언트 매개 변수에 대해 최적의 값이 없습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-250">Not having optimal values for various client parameters, such as the connection pool limit, the degree of parallelization, the prefetch count, and the batch size.</span></span>

- <span data-ttu-id="7ee9b-251">네트워크 I/O 병목 현상.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-251">Network I/O bottlenecks.</span></span>

- <span data-ttu-id="7ee9b-252">한 번 이상의 메시지 배달을 보장하는 데 필요한 [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read) 대신 [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) 모드를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-252">Use of [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mode rather than [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), which was needed to ensure at-least-once delivery of messages.</span></span>

<span data-ttu-id="7ee9b-253">추가적인 성능 테스트를 통해 근본 원인을 찾고 이러한 문제를 해결할 수 있었습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-253">Further performance tests might have discovered the root cause and allowed us to resolve these issues.</span></span> <span data-ttu-id="7ee9b-254">하지만 IotHub React가 성능 목표를 충족했기 때문에 이 옵션을 선택했습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-254">However, IotHub React met our performance target, so we chose that option.</span></span> <span data-ttu-id="7ee9b-255">즉, Service Bus는 이 시나리오에 유용한 옵션입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-255">That said, Service Bus is a viable option for this scenario.</span></span>

## <a name="handling-failures"></a><span data-ttu-id="7ee9b-256">오류 처리</span><span class="sxs-lookup"><span data-stu-id="7ee9b-256">Handling failures</span></span> 

<span data-ttu-id="7ee9b-257">고려해야 할 일반적인 오류 클래스에는 세 가지가 입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-257">There are three general classes of failure to consider.</span></span>

1. <span data-ttu-id="7ee9b-258">다운스트림 서비스에는 영구적인 오류가 있을 수 있으며, 자체적으로 사라질 가능성이 없는 오류입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-258">A downstream service may have a non-transient failure, which is any failure that's unlikely to go away by itself.</span></span> <span data-ttu-id="7ee9b-259">영구 오류에는 메서드에 대한 잘못된 입력과 같은 일반적인 오류 조건이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-259">Non-transient failures include normal error conditions, such as invalid input to a method.</span></span> <span data-ttu-id="7ee9b-260">애플리케이션 코드의 처리되지 않은 예외나 프로세스 충돌도 포함될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-260">They also include unhandled exceptions in application code or a process crashing.</span></span> <span data-ttu-id="7ee9b-261">이런 유형의 오류가 발생하면 전체 비즈니스 트랜잭션이 실패로 표시되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-261">If this type of error occurs, the entire business transaction must be marked as a failure.</span></span> <span data-ttu-id="7ee9b-262">이미 성공한 동일한 트랜잭션의 다른 단계를 실행 취소해야 할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-262">It may be necessary to undo other steps in the same transaction that already succeeded.</span></span> <span data-ttu-id="7ee9b-263">(아래 보정 트랜잭션 참조)</span><span class="sxs-lookup"><span data-stu-id="7ee9b-263">(See Compensating Transactions, below.)</span></span>
 
2. <span data-ttu-id="7ee9b-264">다운 스트림 서비스에 네트워크 시간 초과와 같은 일시적인 오류가 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-264">A downstream service may experience a transient failure such as a network timeout.</span></span> <span data-ttu-id="7ee9b-265">이러한 오류는 호출을 다시 시도하여 종종 해결할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-265">These errors can often be resolved simply by retrying the call.</span></span> <span data-ttu-id="7ee9b-266">일정 횟수를 시도한 후에도 작업이 계속 실패하면 영구적인 오류로 간주됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-266">If the operation still fails after a certain number of attempts, it's considered a non-transient failure.</span></span> 

3. <span data-ttu-id="7ee9b-267">Scheduler 서비스 자체에서 오류가 발생할 수 있습니다(예: 노드 충돌로 인해).</span><span class="sxs-lookup"><span data-stu-id="7ee9b-267">The Scheduler service itself might fault (for example, because a node crashes).</span></span> <span data-ttu-id="7ee9b-268">이런 경우 Kubernetes는 새로운 서비스 인스턴스를 표시합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-268">In that case, Kubernetes will bring up a new instance of the service.</span></span> <span data-ttu-id="7ee9b-269">하지만 이미 진행 중인 트랜잭션이 있으면 다시 시작해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-269">However, any transactions that were already in progress must be resumed.</span></span> 

## <a name="compensating-transactions"></a><span data-ttu-id="7ee9b-270">보정 트랜잭션</span><span class="sxs-lookup"><span data-stu-id="7ee9b-270">Compensating transactions</span></span>

<span data-ttu-id="7ee9b-271">영구적인 오류가 발생하면 현재 트랜잭션은 하나 이상의 단계가 이미 완료된 *부분적으로 실패* 상태가 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-271">If a non-transient failure happens, the current transaction might be in a *partially failed* state, where one or more steps already completed successfully.</span></span> <span data-ttu-id="7ee9b-272">예를 들어 드론 서비스에서 드론을 이미 예약한 경우 드론을 취소해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-272">For example, if the Drone service already scheduled a drone, the drone must be canceled.</span></span> <span data-ttu-id="7ee9b-273">이 경우 애플리케이션은 [보정 트랜잭션](../patterns/compensating-transaction.md)을 사용하여 성공한 단계를 실행 취소해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-273">In that case, the application needs to undo the steps that succeeded, by using a [Compensating Transaction](../patterns/compensating-transaction.md).</span></span> <span data-ttu-id="7ee9b-274">경우에 따라 이 작업을 외부 시스템 또는 수동 프로세스로 수행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-274">In some cases, this must be done by an external system or even by a manual process.</span></span> 

<span data-ttu-id="7ee9b-275">보정 트랜잭션 논리가 복잡한 경우 이 프로세스를 담당하는 별도의 서비스를 만드는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-275">If the logic for compensating transactions is complex, consider creating a separate service that is responsible for this process.</span></span> <span data-ttu-id="7ee9b-276">드론 배달 애플리케이션에서 Scheduler 서비스는 실패한 작업을 전용 큐에 넣습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-276">In the Drone Delivery application, the Scheduler service puts failed operations onto a dedicated queue.</span></span> <span data-ttu-id="7ee9b-277">Supervisor라고 하는 별도의 마이크로 서비스는 이 큐를 읽고 보정이 필요한 서비스에 취소 API를 호출합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-277">A separate microservice, called the Supervisor, reads from this queue and calls a cancellation API on the services that need to compensate.</span></span> <span data-ttu-id="7ee9b-278">이것은 [Scheduler 에이전트 감독자 패턴][scheduler-agent-supervisor]의 변형입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-278">This is a variation of the [Scheduler Agent Supervisor pattern][scheduler-agent-supervisor].</span></span> <span data-ttu-id="7ee9b-279">감독자 서비스는 텍스트 또는 이메일로 사용자에게 알리는 등의 다른 작업을 수행하거나 작업 대시보드에 경고를 보낼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-279">The Supervisor service might take other actions as well, such as notify the user by text or email, or send an alert to an operations dashboard.</span></span> 

![](./images/supervisor.png)

## <a name="idempotent-vs-non-idempotent-operations"></a><span data-ttu-id="7ee9b-280">Idempotent 및 non-idempotent 작업</span><span class="sxs-lookup"><span data-stu-id="7ee9b-280">Idempotent vs non-idempotent operations</span></span>

<span data-ttu-id="7ee9b-281">요청이 손실되지 않으려면 Scheduler 서비스는 모든 메시지가 한 번 이상 처리되도록 보장해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-281">To avoid losing any requests, the Scheduler service must guarantee that all messages are processed at least once.</span></span> <span data-ttu-id="7ee9b-282">Event Hubs는 클라이언트가 검사점을 제대로 설정하면 한 번 이상 배달을 보장합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-282">Event Hubs can guarantee at-least-once delivery if the client checkpoints correctly.</span></span>

<span data-ttu-id="7ee9b-283">Scheduler 서비스가 충돌하면 하나 이상의 클라이언트 요청을 처리하는 중일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-283">If the Scheduler service crashes, it may be in the middle of processing one or more client requests.</span></span> <span data-ttu-id="7ee9b-284">이러한 메시지는 다른 Scheduler 인스턴스가 픽업하여 다시 처리합니다</span><span class="sxs-lookup"><span data-stu-id="7ee9b-284">Those messages will be picked up by another instance of the Scheduler and reprocessed.</span></span> <span data-ttu-id="7ee9b-285">요청이 두 번 처리되면 어떻게 되나요?</span><span class="sxs-lookup"><span data-stu-id="7ee9b-285">What happens if a request is processed twice?</span></span> <span data-ttu-id="7ee9b-286">작업을 중복하지 않는 것이 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-286">It's important to avoid duplicating any work.</span></span> <span data-ttu-id="7ee9b-287">즉, 동일한 패키지를 위해 시스템에서 드론을 두 개 보내지 않도록 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-287">After all, we don't want the system to send two drones for the same package.</span></span>

<span data-ttu-id="7ee9b-288">한 가지 방법은 모든 연산을 idempotent가 되도록 디자인하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-288">One approach is to design all operations to be idempotent.</span></span> <span data-ttu-id="7ee9b-289">연산을 처음 호출한 후에 추가로 부작용을 생성하지 않고 여러 번 호출 할 수 있으면 그 연산은 idempotent입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-289">An operation is idempotent if it can be called multiple times without producing additional side-effects after the first call.</span></span> <span data-ttu-id="7ee9b-290">다시 말해 클라이언트가 연산을 한 번, 두 번 또는 여러 번 호출할 수 있고 결과는 동일합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-290">In other words, a client can invoke the operation once, twice, or many times, and the result will be the same.</span></span> <span data-ttu-id="7ee9b-291">기본적으로 서비스는 중복 호출을 무시해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-291">Essentially, the service should ignore duplicate calls.</span></span> <span data-ttu-id="7ee9b-292">부작용이 idempotent가 되는 메서드의 경우 서비스는 중복 호출을 감지할 수 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-292">For a method with side effects to be idempotent, the service must be able to detect duplicate calls.</span></span> <span data-ttu-id="7ee9b-293">예를 들어 서비스에서 새 ID를 생성하는 대신 호출자가 ID를 할당하도록 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-293">For example, you can have the caller assign the ID, rather than having the service generate a new ID.</span></span> <span data-ttu-id="7ee9b-294">그런 다음 서비스에서 중복 ID를 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-294">The service can then check for duplicate IDs.</span></span>

> [!NOTE]
> <span data-ttu-id="7ee9b-295">HTTP 사양에 따라 GET, PUT 및 DELETE 메서드는 idempotent가 되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-295">The HTTP specification states that GET, PUT, and DELETE methods must be idempotent.</span></span> <span data-ttu-id="7ee9b-296">POST 메서드는 idempotent가 되는 것이 보장되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-296">POST methods are not guaranteed to be idempotent.</span></span> <span data-ttu-id="7ee9b-297">POST 메서드가 새 리소스를 만드는 경우 일반적으로 이 연산이 idempotent라는 보장은 없습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-297">If a POST method creates a new resource, there is generally no guarantee that this operation is idempotent.</span></span> 

<span data-ttu-id="7ee9b-298">idempotent 메서드 작성이 항상 쉬운 것은 아닙니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-298">It's not always straightforward to write idempotent method.</span></span> <span data-ttu-id="7ee9b-299">Scheduler에 대한 또 다른 옵션은 지속형 저장소의 모든 트랜잭션 진행률을 추적하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-299">Another option is for the Scheduler to track the progress of every transaction in a durable store.</span></span> <span data-ttu-id="7ee9b-300">메시지를 처리할 때마다 지속형 저장소에서 상태를 조회합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-300">Whenever it processes a message, it would look up the state in the durable store.</span></span> <span data-ttu-id="7ee9b-301">각 단계마다 저장소에 결과를 작성합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-301">After each step, it would write the result to the store.</span></span> <span data-ttu-id="7ee9b-302">이 접근 방식은 성능에 영향이 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-302">There may be performance implications to this approach.</span></span>

## <a name="example-idempotent-operations"></a><span data-ttu-id="7ee9b-303">예: Idempotent 연산</span><span class="sxs-lookup"><span data-stu-id="7ee9b-303">Example: Idempotent operations</span></span>

<span data-ttu-id="7ee9b-304">HTTP 사양에는 PUT 메서드가 idempotent여야 한다고 명시되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-304">The HTTP specification states that PUT methods must be idempotent.</span></span> <span data-ttu-id="7ee9b-305">idempotent는 사양에 다음과 같이 정의되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-305">The specification defines idempotent this way:</span></span>

>  <span data-ttu-id="7ee9b-306">해당 메서드로 여러 개의 동일한 요청이 서버에 미치는 영향이 단일 요청에 대한 효과와 동일한 경우 요청 메서드는 "idempotent"로 간주됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-306">A request method is considered "idempotent" if the intended effect on the server of multiple identical requests with that method is the   same as the effect for a single such request.</span></span> <span data-ttu-id="7ee9b-307">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span><span class="sxs-lookup"><span data-stu-id="7ee9b-307">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span></span>

<span data-ttu-id="7ee9b-308">새 엔터티를 만들 때 PUT과 POST 의미 체계 사이의 차이를 이해하는 것이 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-308">It's important to understand the difference between PUT and POST semantics when creating a new entity.</span></span> <span data-ttu-id="7ee9b-309">두 가지 경우 모두 클라이언트가 요청 본문에 엔터티 표시를 보냅니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-309">In both cases, the client sends a representation of an entity in the request body.</span></span> <span data-ttu-id="7ee9b-310">하지만 URI의 의미는 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-310">But the meaning of the URI is different.</span></span>

- <span data-ttu-id="7ee9b-311">POST 메서드의 경우 URI는 컬렉션과 같은 새 엔터티의 부모 리소스를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-311">For a POST method, the URI represents a parent resource of the new entity, such as a collection.</span></span> <span data-ttu-id="7ee9b-312">예를 들어 새 배달을 만들려면 URI는 `/api/deliveries`일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-312">For example, to create a new delivery, the URI might be `/api/deliveries`.</span></span> <span data-ttu-id="7ee9b-313">서버는 엔터티를 만들어서 새 URI(예: `/api/deliveries/39660`)를 할당합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-313">The server creates the entity and assigns it a new URI, such as `/api/deliveries/39660`.</span></span> <span data-ttu-id="7ee9b-314">이 URI는 응답의 Location 헤더에 반환됩니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-314">This URI is returned in the Location header of the response.</span></span> <span data-ttu-id="7ee9b-315">클라이언트가 요청을 보낼 때마다 서버는 새 URI로 새 엔터티를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-315">Each time the client sends a request, the server will create a new entity with a new URI.</span></span>

- <span data-ttu-id="7ee9b-316">PUT 메서드의 경우, URI는 엔터티를 식별합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-316">For a PUT method, the URI identifies the entity.</span></span> <span data-ttu-id="7ee9b-317">해당 URI가 있는 엔터티가 이미 존재하면 서버는 기존 엔터티를 요청의 버전으로 바꿉니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-317">If there already exists an entity with that URI, the server replaces the existing entity with the version in the request.</span></span> <span data-ttu-id="7ee9b-318">해당 URI가 있는 엔터티가 없으면 서버가 엔터티를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-318">If no entity exists with that URI, the server creates one.</span></span> <span data-ttu-id="7ee9b-319">예를 들어, 클라이언트가 PUT 요청을 `api/deliveries/39660`에 보낸다고 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-319">For example, suppose the client sends a PUT request to `api/deliveries/39660`.</span></span> <span data-ttu-id="7ee9b-320">해당 URI가 있는 배달이 없다고 가정하고 서버가 새 배달을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-320">Assuming there is no delivery with that URI, the server creates a new one.</span></span> <span data-ttu-id="7ee9b-321">이제 클라이언트가 동일한 요청을 다시 보내면 서버는 기존 엔터티를 바꿉니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-321">Now if the client sends the same request again, the server will replace the existing entity.</span></span>

<span data-ttu-id="7ee9b-322">다음은 배달 서비스의 PUT 메서드 구현입니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-322">Here is the Delivery service's implementation of the PUT method.</span></span> 

```csharp
[HttpPut("{id}")]
[ProducesResponseType(typeof(Delivery), 201)]
[ProducesResponseType(typeof(void), 204)]
public async Task<IActionResult> Put([FromBody]Delivery delivery, string id)
{
    logger.LogInformation("In Put action with delivery {Id}: {@DeliveryInfo}", id, delivery.ToLogInfo());
    try
    {
        var internalDelivery = delivery.ToInternal();

        // Create the new delivery entity.
        await deliveryRepository.CreateAsync(internalDelivery);

        // Create a delivery status event.
        var deliveryStatusEvent = new DeliveryStatusEvent { DeliveryId = delivery.Id, Stage = DeliveryEventType.Created };
        await deliveryStatusEventRepository.AddAsync(deliveryStatusEvent);

        // Return HTTP 201 (Created)
        return CreatedAtRoute("GetDelivery", new { id= delivery.Id }, delivery);
    }
    catch (DuplicateResourceException)
    {
        // This method is mainly used to create deliveries. If the delivery already exists then update it.
        logger.LogInformation("Updating resource with delivery id: {DeliveryId}", id);

        var internalDelivery = delivery.ToInternal();
        await deliveryRepository.UpdateAsync(id, internalDelivery);

        // Return HTTP 204 (No Content)
        return NoContent();
    }
}
```

<span data-ttu-id="7ee9b-323">대부분의 요청은 새 엔터티를 생성할 것으로 예상되기 때문에 메서드는 리포지토리 개체에서 낙관적으로 `CreateAsync`를 호출한 다음 리소스를 대신 업데이트하여 중복된 리소스 예외가 있으면 처리합니다.</span><span class="sxs-lookup"><span data-stu-id="7ee9b-323">It's expected that most requests will create a new entity, so the method optimistically calls `CreateAsync` on the repository object, and then handles any duplicate-resource exceptions by updating the resource instead.</span></span> 

> [!div class="nextstepaction"]
> [<span data-ttu-id="7ee9b-324">API 게이트웨이</span><span class="sxs-lookup"><span data-stu-id="7ee9b-324">API gateways</span></span>](./gateway.md)

<!-- links -->

[scheduler-agent-supervisor]: ../patterns/scheduler-agent-supervisor.md