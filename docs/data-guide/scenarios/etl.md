---
title: ETL(추출, 변환 및 로드)
description: ''
author: zoinerTejada
ms:date: 02/12/2018
ms.openlocfilehash: a980c1f8aef99fc263083e5e496b1340204f7dac
ms.sourcegitcommit: c441fd165e6bebbbbbc19854ec6f3676be9c3b25
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/31/2018
---
# <a name="extract-transform-and-load-etl"></a><span data-ttu-id="2eb1a-102">ETL(추출, 변환 및 로드)</span><span class="sxs-lookup"><span data-stu-id="2eb1a-102">Extract, transform, and load (ETL)</span></span>

<span data-ttu-id="2eb1a-103">조직이 일반적으로 직면하는 문제는 여러 원본의 데이터를 여러 형식으로 수집한 후 하나 이상의 데이터 저장소로 이동하는 방법에 대한 것입니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-103">A common problem that organizations face is how to gathering data from multiple sources, in multiple formats, and move it to one or more data stores.</span></span> <span data-ttu-id="2eb1a-104">대상은 원본과 동일한 유형의 데이터 저장소가 아닐 수 있으며, 종종 형식이 다르거나, 데이터를 최종 대상으로 로드하기 전에 셰이핑 또는 정리해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-104">The destination may not be the same type of data store as the source, and often the format is different, or the data needs to be shaped or cleaned before loading it into its final destination.</span></span>

<span data-ttu-id="2eb1a-105">이러한 문제를 해결하기 위해 수년에 걸쳐 다양한 도구, 서비스 및 프로세스 개발되었습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-105">Various tools, services, and processes have been developed over the years to help address these challenges.</span></span> <span data-ttu-id="2eb1a-106">사용되는 프로세스에 관계없이, 일반적으로 작업을 조정하고 데이터 파이프라인 내에서 일정 수준의 데이터 변환을 적용할 필요가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-106">No matter the process used, there is a common need to coordinate the work and apply some level of data transformation within the data pipeline.</span></span> <span data-ttu-id="2eb1a-107">다음 섹션에서는 이러한 작업을 수행하는 데 사용되는 일반적인 방법을 강조해서 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-107">The following sections highlight the common methods used to perform these tasks.</span></span>

## <a name="extract-transform-and-load-etl"></a><span data-ttu-id="2eb1a-108">ETL(추출, 변환 및 로드)</span><span class="sxs-lookup"><span data-stu-id="2eb1a-108">Extract, transform, and load (ETL)</span></span>

<span data-ttu-id="2eb1a-109">ETL(추출, 변환 및 로드)은 다양한 원본에서 데이터를 수집하고, 비즈니스 규칙에 따라 데이터를 변환하고, 대상 데이터 저장소로 로드하는 데 사용되는 데이터 파이프라인입니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-109">Extract, transform, and load (ETL) is a data pipeline used to collect data from various sources, transform the data according to business rules, and load it into a destination data store.</span></span> <span data-ttu-id="2eb1a-110">ETL의 변환 작업은 특수한 엔진에서 진행되며, 종종 변환 중인 데이터가 준비 테이블에서 임시로 보유되었다가 결과적으로 대상에 로드됩니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-110">The transformation work in ETL takes place in a specialized engine, and often involves using staging tables to temporarily hold data as it is being transformed and ultimately loaded to its destination.</span></span>

<span data-ttu-id="2eb1a-111">일반적으로 발생하는 데이터 변환에는 필터링, 정렬, 집계, 데이터 조인, 데이터 정리, 중복 제거 및 데이터 유효성 검사 등의 다양한 작업이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-111">The data transformation that takes place usually involves various operations, such as filtering, sorting, aggregating, joining data, cleaning data, deduplicating, and validating data.</span></span>

![ETL(추출, 변환, 로드) 프로세스](./images/etl.png)

<span data-ttu-id="2eb1a-113">종종 시간 절약을 위해 3가지 ETL 단계가 동시에 실행됩니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-113">Often, the three ETL phases are run in parallel to save time.</span></span> <span data-ttu-id="2eb1a-114">예를 들어, 데이터의 전체 추출이 완료될 때까지 기다리지 않고, 데이터가 추출되는 동안 이미 수신된 데이터가 변환되면서 로드 준비가 진행되고, 준비된 데이터에 대해 로드 프로세스가 시작될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-114">For example, while data is being extracted, a transformation process could be working on data already received and prepare it for loading, and a loading process can begin working on the prepared data, rather than waiting for the entire extraction process to complete.</span></span>

<span data-ttu-id="2eb1a-115">관련 Azure 서비스:</span><span class="sxs-lookup"><span data-stu-id="2eb1a-115">Relevant Azure service:</span></span>
- [<span data-ttu-id="2eb1a-116">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="2eb1a-116">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)

<span data-ttu-id="2eb1a-117">기타 도구:</span><span class="sxs-lookup"><span data-stu-id="2eb1a-117">Other tools:</span></span>
- [<span data-ttu-id="2eb1a-118">SSIS(SQL Server Integration Services)</span><span class="sxs-lookup"><span data-stu-id="2eb1a-118">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="extract-load-and-transform-elt"></a><span data-ttu-id="2eb1a-119">ELT(추출, 로드, 변환)</span><span class="sxs-lookup"><span data-stu-id="2eb1a-119">Extract, load, and transform (ELT)</span></span>

<span data-ttu-id="2eb1a-120">ELT(추출, 로드, 변환)는 변환이 수행되는 위치만 ETL과 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-120">Extract, load, and transform (ELT) differs from ETL solely in where the transformation takes place.</span></span> <span data-ttu-id="2eb1a-121">ELT 파이프라인에서는 대상 데이터 저장소에서 변환이 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-121">In the ELT pipeline, the transformation occurs in the target data store.</span></span> <span data-ttu-id="2eb1a-122">별도 변환 엔진을 사용하는 대신, 대상 데이터 저장소의 처리 기능을 사용하여 데이터를 변환합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-122">Instead of using a separate transformation engine, the processing capabilities of the target data store are used to transform data.</span></span> <span data-ttu-id="2eb1a-123">따라서 파이프라인에서 변환 엔진이 제거되므로 아키텍처가 단순해집니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-123">This simplifies the architecture by removing the transformation engine from the pipeline.</span></span> <span data-ttu-id="2eb1a-124">이 방식의 또 다른 이점은 대상 데이터 저장소의 크기를 조정하면 ELT 파이프라인 성능도 조정된다는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-124">Another benefit to this approach is that scaling the target data store also scales the ELT pipeline performance.</span></span> <span data-ttu-id="2eb1a-125">그러나 ELT는 대상 시스템이 데이터를 효율적으로 변환할 수 있을 만큼 강력할 때만 효과적입니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-125">However, ELT only works well when the target system is powerful enough to transform the data efficiently.</span></span>

![ELT(추출, 로드, 변환) 프로세스](./images/elt.png)

<span data-ttu-id="2eb1a-127">ELT의 일반적인 사용 사례는 빅 데이터 영역에 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-127">Typical use cases for ELT fall within the big data realm.</span></span> <span data-ttu-id="2eb1a-128">예를 들어, 먼저 모든 원본 데이터를 HDFS(Hadoop 분산 파일 시스템) 또는 Azure Data Lake Store 같은 확장 가능한 저장소의 플랫 파일로 추출할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-128">For example, you might start by extracting all of the source data to flat files in scalable storage such as Hadoop distributed file system (HDFS) or Azure Data Lake Store.</span></span> <span data-ttu-id="2eb1a-129">그런 후 Spark, Hive 또는 PolyBase와 같은 기술을 사용하여 원본 데이터를 쿼리하기만 하면 됩니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-129">Technologies such as Spark, Hive, or PolyBase can then be used to query the source data.</span></span> <span data-ttu-id="2eb1a-130">ELT의 중요한 점은 변형을 수행하는 데 사용된 동일한 데이터 저장소에서 궁극적으로 데이터가 사용된다는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-130">The key point with ELT is that the data store used to perform the transformation is the same data store where the data is ultimately consumed.</span></span> <span data-ttu-id="2eb1a-131">이 데이터 저장소는 자체 전용 저장소에 데이터를 로드하지 않고, 확장 가능한 저장소에서 직접 데이터를 읽습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-131">This data store reads directly from the scalable storage, instead of loading the data into its own proprietary storage.</span></span> <span data-ttu-id="2eb1a-132">이 방법은 큰 데이터 집합을 사용할 경우 시간이 많이 소요될 수 있는 ETL의 데이터 복사 단계를 건너뜁니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-132">This approach skips the data copy step present in ETL, which can be a time consuming operation for large data sets.</span></span>

<span data-ttu-id="2eb1a-133">실제로, 대상 데이터 저장소는 실제로 Hadoop 클러스터(Hive 또는 Spark 사용) 또는 SQL Data Warehouse를 사용하는 [데이터 웨어하우스](./data-warehousing.md)입니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-133">In practice, the target data store is a [data warehouse](./data-warehousing.md) using either a Hadoop cluster (using Hive or Spark) or a SQL Data Warehouse.</span></span> <span data-ttu-id="2eb1a-134">일반적으로 스키마는 쿼리 타임에 플랫 파일 데이터에 중첩되고 테이블로 저장되므로 데이터 저장소의 다른 테이블처럼 데이터를 쿼리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-134">In general, a schema is overlaid on the flat file data at query time and stored as a table, enabling the data to be queried like any other table in the data store.</span></span> <span data-ttu-id="2eb1a-135">데이터가 데이터 저장소 자체에서 관리하는 저장소에 있지 않고 확장 가능한 외부 저장소에 있으므로 이러한 테이블을 외부 테이블이라고 합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-135">These are referred to as external tables because the data does not reside in storage managed by the data store itself, but on some external scalable storage.</span></span> 

<span data-ttu-id="2eb1a-136">데이터 저장소는 데이터의 스키마만 관리하고 읽기 시 스키마를 적용합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-136">The data store only manages the schema of the data and applies the schema on read.</span></span> <span data-ttu-id="2eb1a-137">예를 들어, Hive를 사용하는 Hadoop 클러스터는 데이터 원본이 결과적으로 HDFS의 파일 집합에 대한 경로가 되는 Hive 테이블을 기술합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-137">For example, a Hadoop cluster using Hive would describe a Hive table where the data source is effectively a path to a set of files in HDFS.</span></span> <span data-ttu-id="2eb1a-138">SQL Data Warehouse에서 PolyBase는 동일한 결과를 얻을 수 있습니다. 즉, 외부 데이터베이스 자체에 외부적으로 저장되는 데이터 테이블이 만들어집니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-138">In SQL Data Warehouse, PolyBase can achieve the same result &mdash; creating a table against data stored externally to the database itself.</span></span> <span data-ttu-id="2eb1a-139">원본 데이터가 로드되면 데이터 저장소의 기능을 사용하여 외부 테이블에 있는 데이터를 처리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-139">Once the source data is loaded, the data present in the external tables can be processed using the capabilities of the data store.</span></span> <span data-ttu-id="2eb1a-140">따라서 빅 데이터 시나리오에서는 데이터 저장소가 데이터를 좀 더 작은 청크로 분할하고 여러 컴퓨터에서 병렬로 청크 처리를 분산하는 MPP(Massively Parallel Processing) 기능을 갖추어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-140">In big data scenarios, this means the data store must be capable of massively parallel processing (MPP), which breaks the data into smaller chunks and distributes processing of the chunks across multiple machines in parallel.</span></span>

<span data-ttu-id="2eb1a-141">ELT 파이프라인의 최종 단계는 일반적으로 지원해야 하는 쿼리 형식에 좀 더 효율적인 최종 형식으로 원본 데이터를 변환하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-141">The final phase of the ELT pipeline is typically to transform the source data into a final format that is more efficient for the types of queries that need to be supported.</span></span> <span data-ttu-id="2eb1a-142">예를 들어 데이터는 분할될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-142">For example, the data may be partitioned.</span></span> <span data-ttu-id="2eb1a-143">또한 ELT는 행 기반 데이터를 칼럼 방식으로 저장하고 최적화된 인덱스를 제공하는 Parquet과 같은 최적화된 저장소 형식을 사용할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-143">Also, ELT might use optimized storage formats like Parquet, which stores row-oriented data in a columnar fashion and providess optimized indexing.</span></span> 

<span data-ttu-id="2eb1a-144">관련 Azure 서비스:</span><span class="sxs-lookup"><span data-stu-id="2eb1a-144">Relevant Azure service:</span></span>

- [<span data-ttu-id="2eb1a-145">Azure SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="2eb1a-145">Azure SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is)
- [<span data-ttu-id="2eb1a-146">HDInsight(Hive 포함)</span><span class="sxs-lookup"><span data-stu-id="2eb1a-146">HDInsight with Hive</span></span>](/azure/hdinsight/hadoop/hdinsight-use-hive)
- [<span data-ttu-id="2eb1a-147">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="2eb1a-147">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)
- [<span data-ttu-id="2eb1a-148">HDInsight의 Oozie</span><span class="sxs-lookup"><span data-stu-id="2eb1a-148">Oozie on HDInsight</span></span>](/azure/hdinsight/hdinsight-use-oozie-linux-mac)

<span data-ttu-id="2eb1a-149">기타 도구:</span><span class="sxs-lookup"><span data-stu-id="2eb1a-149">Other tools:</span></span>

- [<span data-ttu-id="2eb1a-150">SSIS(SQL Server Integration Services)</span><span class="sxs-lookup"><span data-stu-id="2eb1a-150">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="data-flow-and-control-flow"></a><span data-ttu-id="2eb1a-151">데이터 흐름 및 제어 흐름</span><span class="sxs-lookup"><span data-stu-id="2eb1a-151">Data flow and control flow</span></span>

<span data-ttu-id="2eb1a-152">데이터 파이프라인의 컨텍스트에서 제어 흐름은 태스크 집합이 순서대로 처리되도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-152">In the context of data pipelines, the control flow ensures orderly processing of a set of tasks.</span></span> <span data-ttu-id="2eb1a-153">이러한 태스크의 올바른 처리 순서를 적용하기 위해 선행 제약 조건이 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-153">To enforce the correct processing order of these tasks, precedence constraints are used.</span></span> <span data-ttu-id="2eb1a-154">아래 그림에 나와 있는 것처럼, 이러한 제약 조건을 워크플로 다이어그램의 연결선으로 생각할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-154">You can think of these constraints as connectors in a workflow diagram, as shown in the image below.</span></span> <span data-ttu-id="2eb1a-155">각 태스크에는 성공, 실패 또는 완료와 같은 결과가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-155">Each task has an outcome, such as success, failure, or completion.</span></span> <span data-ttu-id="2eb1a-156">선행 작업이 이러한 결과 중 하나로 완료되어야만 후속 태스크의 처리가 시작됩니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-156">Any subsequent task does not initiate processing until its predecessor has completed with one of these outcomes.</span></span>

<span data-ttu-id="2eb1a-157">제어 흐름은 데이터 흐름을 하나의 태스크로 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-157">Control flows execute data flows as a task.</span></span> <span data-ttu-id="2eb1a-158">데이터 흐름 태스크에서 데이터는 원본에서 추출되고, 변형되고, 데이터 저장소에 로드됩니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-158">In a data flow task, data is extracted from a source, transformed, or loaded into a data store.</span></span> <span data-ttu-id="2eb1a-159">하나의 데이터 흐름 태스크의 출력이 다음 데이터 흐름 태스크의 입력이 되고 데이터 흐름이 병렬로 실행될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-159">The output of one data flow task can be the input to the next data flow task, and data flowss can run in parallel.</span></span> <span data-ttu-id="2eb1a-160">제어 흐름과 달리, 데이터 흐름의 태스크 간에는 제약 조건을 추가할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-160">Unlike control flows, you cannot add constraints between tasks in a data flow.</span></span> <span data-ttu-id="2eb1a-161">그러나 각 태스크에서 처리되는 데이터를 관찰하기 위해 데이터 뷰어를 추가할 수는 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-161">You can, however, add a data viewer to observe the data as it is processed by each task.</span></span>

![제어 흐름 내에서 태스크로 실행되는 데이터 흐름](./images/control-flow-data-flow.png)

<span data-ttu-id="2eb1a-163">위의 다이어그램에는 제어 흐름 내의 여러 태스크가 나와 있습니다. 이중 하나가 데이터 흐름 태스크입니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-163">In the diagram above, there are several tasks within the control flow, one of which is a data flow task.</span></span> <span data-ttu-id="2eb1a-164">태스크 중 하나가 컨테이너 내에 중첩되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-164">One of the tasks is nested within a container.</span></span> <span data-ttu-id="2eb1a-165">컨테이너는 태스크에 구조를 제공하는 데 사용될 수 있으며 작업 단위를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-165">Containers can be used to provide structure to tasks, providing a unit of work.</span></span> <span data-ttu-id="2eb1a-166">이러한 예제 중 하나는 폴더 또는 데이터베이스 문의 파일처럼 컬렉션 내에서 요소를 반복하는 경우입니다.</span><span class="sxs-lookup"><span data-stu-id="2eb1a-166">One such example is for repeating elements within a collection, such as files in a folder or database statements.</span></span>

<span data-ttu-id="2eb1a-167">관련 Azure 서비스:</span><span class="sxs-lookup"><span data-stu-id="2eb1a-167">Relevant Azure service:</span></span>
- [<span data-ttu-id="2eb1a-168">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="2eb1a-168">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)

<span data-ttu-id="2eb1a-169">기타 도구:</span><span class="sxs-lookup"><span data-stu-id="2eb1a-169">Other tools:</span></span>
- [<span data-ttu-id="2eb1a-170">SSIS(SQL Server Integration Services)</span><span class="sxs-lookup"><span data-stu-id="2eb1a-170">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="technology-choices"></a><span data-ttu-id="2eb1a-171">기술 선택</span><span class="sxs-lookup"><span data-stu-id="2eb1a-171">Technology choices</span></span>

- [<span data-ttu-id="2eb1a-172">OLTP(온라인 트랜잭션 처리) 데이터 저장소</span><span class="sxs-lookup"><span data-stu-id="2eb1a-172">Online Transaction Processing (OLTP) data stores</span></span>](../technology-choices/oltp-data-stores.md)
- [<span data-ttu-id="2eb1a-173">OLAP(온라인 분석 처리) 데이터 저장소</span><span class="sxs-lookup"><span data-stu-id="2eb1a-173">Online Analytical Processing (OLAP) data stores</span></span>](../technology-choices/olap-data-stores.md)
- [<span data-ttu-id="2eb1a-174">데이터 웨어하우스</span><span class="sxs-lookup"><span data-stu-id="2eb1a-174">Data warehouses</span></span>](../technology-choices/data-warehouses.md)
- [<span data-ttu-id="2eb1a-175">파이프라인 오케스트레이션</span><span class="sxs-lookup"><span data-stu-id="2eb1a-175">Pipeline orchestration</span></span>](../technology-choices/pipeline-orchestration-data-movement.md)
