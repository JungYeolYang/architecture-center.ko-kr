---
title: 빅 데이터 아키텍처
description: ''
author: zoinerTejada
ms:date: 02/12/2018
ms.openlocfilehash: 2a1336faea81470b082d4eef8e2cc53a082c63c7
ms.sourcegitcommit: 51f49026ec46af0860de55f6c082490e46792794
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 04/03/2018
ms.locfileid: "30298858"
---
# <a name="big-data-architectures"></a><span data-ttu-id="c542b-102">빅 데이터 아키텍처</span><span class="sxs-lookup"><span data-stu-id="c542b-102">Big data architectures</span></span>

<span data-ttu-id="c542b-103">빅 데이터 아키텍처는 기존의 데이터베이스 시스템에 비해 너무 크거나 복잡한 데이터의 수집, 처리 및 분석을 수행하도록 디자인되었습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-103">A big data architecture is designed to handle the ingestion, processing, and analysis of data that is too large or complex for traditional database systems.</span></span> <span data-ttu-id="c542b-104">조직이 빅 데이터 영역으로 전환하게 되는 시점은 사용자의 역량과 사용하는 도구에 따라 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-104">The threshold at which organizations enter into the big data realm differs, depending on the capabilities of the users and their tools.</span></span> <span data-ttu-id="c542b-105">수백 기가바이트의 데이터일 수도 있고, 수백 테라바이트의 데이터일 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-105">For some, it can mean hundreds of gigabytes of data, while for others it means hundreds of terabytes.</span></span> <span data-ttu-id="c542b-106">빅 데이터 집합으로 작업하기 위한 도구가 발전하면서 빅 데이터의 의미도 달라지고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-106">As tools for working with big data sets advance, so does the meaning of big data.</span></span> <span data-ttu-id="c542b-107">이 용어는 엄격히 데이터 크기만을 고려하지 않고, 고급 분석을 통해 데이터 집합에서 추출할 수 있는 가치와 점점 더 밀접한 관련을 갖습니다. 데이터 크기만 고려한다면 빅 데이터는 훨씬 더 큰 데이터일 것입니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-107">More and more, this term relates to the value you can extract from your data sets through advanced analytics, rather than strictly the size of the data, although in these cases they tend to be quite large.</span></span>

<span data-ttu-id="c542b-108">수 년에 걸쳐 데이터 환경이 변경되어 왔습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-108">Over the years, the data landscape has changed.</span></span> <span data-ttu-id="c542b-109">데이터로 수행할 수 있는 작업이나 수행하려는 작업이 변경되었습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-109">What you can do, or are expected to do, with data has changed.</span></span> <span data-ttu-id="c542b-110">데이터가 수집되는 방법이 점점 더 다양해지면서, 저장 비용은 크게 감소되었습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-110">The cost of storage has fallen dramatically, while the means by which data is collected keeps growing.</span></span> <span data-ttu-id="c542b-111">빠른 속도로 도착하며 지속적으로 수집 및 관찰해야 하는 데이터가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-111">Some data arrives at a rapid pace, constantly demanding to be collected and observed.</span></span> <span data-ttu-id="c542b-112">느리게 도착하지만 대량의 청크로 구성된 수십 년 간의 기록 데이터도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-112">Other data arrives more slowly, but in very large chunks, often in the form of decades of historical data.</span></span> <span data-ttu-id="c542b-113">고급 분석 문제나 기계 학습이 필요한 경우에 직면할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-113">You might be facing an advanced analytics problem, or one that requires machine learning.</span></span> <span data-ttu-id="c542b-114">이러한 점이 바로 빅 데이터 아키텍처가 해결하려고 하는 문제점입니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-114">These are challenges that big data architectures seek to solve.</span></span>

<span data-ttu-id="c542b-115">빅 데이터 솔루션에는 일반적으로 다음 중 하나 이상의 워크로드 유형이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-115">Big data solutions typically involve one or more of the following types of workload:</span></span>

* <span data-ttu-id="c542b-116">미사용 빅 데이터 원본의 일괄 처리</span><span class="sxs-lookup"><span data-stu-id="c542b-116">Batch processing of big data sources at rest.</span></span>
* <span data-ttu-id="c542b-117">사용 중인 빅 데이터의 실시간 처리</span><span class="sxs-lookup"><span data-stu-id="c542b-117">Real-time processing of big data in motion.</span></span>
* <span data-ttu-id="c542b-118">빅 데이터의 대화형 탐색</span><span class="sxs-lookup"><span data-stu-id="c542b-118">Interactive exploration of big data.</span></span>
* <span data-ttu-id="c542b-119">예측 분석 및 기계 학습</span><span class="sxs-lookup"><span data-stu-id="c542b-119">Predictive analytics and machine learning.</span></span>

<span data-ttu-id="c542b-120">다음 작업이 필요할 때 빅 데이터 아키텍처를 고려합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-120">Consider big data architectures when you need to:</span></span>

* <span data-ttu-id="c542b-121">기존 데이터베이스에 비해 너무 큰 볼륨의 데이터 저장 및 처리</span><span class="sxs-lookup"><span data-stu-id="c542b-121">Store and process data in volumes too large for a traditional database.</span></span>
* <span data-ttu-id="c542b-122">분석 및 보고를 위해 구조화되지 않은 데이터 변환</span><span class="sxs-lookup"><span data-stu-id="c542b-122">Transform unstructured data for analysis and reporting.</span></span>
* <span data-ttu-id="c542b-123">제한되지 않은 데이터 스트림을 실시간으로 또는 짧은 대기 시간으로 수집, 처리 및 분석</span><span class="sxs-lookup"><span data-stu-id="c542b-123">Capture, process, and analyze unbounded streams of data in real time, or with low latency.</span></span>

## <a name="components-of-a-big-data-architecture"></a><span data-ttu-id="c542b-124">빅 데이터 아키텍처의 구성 요소</span><span class="sxs-lookup"><span data-stu-id="c542b-124">Components of a big data architecture</span></span>

<span data-ttu-id="c542b-125">다음 다이어그램에서는 빅 데이터 아키텍처에 맞는 논리적 구성 요소를 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-125">The following diagram shows the logical components that fit into a big data architecture.</span></span> <span data-ttu-id="c542b-126">개별 솔루션이 이 다이어그램에 있는 모든 항목을 포함하지는 않을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-126">Individual solutions may not contain every item in this diagram.</span></span>

![전체 데이터 파이프라인 다이어그램](./images/big-data-pipeline.png) 

<span data-ttu-id="c542b-128">대부분의 빅 데이터 아키텍처에는 다음 구성 요소의 일부 또는 전체가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-128">Most big data architectures include some or all of the following components:</span></span>

* <span data-ttu-id="c542b-129">**데이터 원본**.</span><span class="sxs-lookup"><span data-stu-id="c542b-129">**Data sources**.</span></span> <span data-ttu-id="c542b-130">모든 빅 데이터 솔루션은 하나 이상의 데이터 원본으로 시작합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-130">All big data solutions start with one or more data sources.</span></span> <span data-ttu-id="c542b-131">이러한 예로 다음이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-131">Examples include:</span></span>

    * <span data-ttu-id="c542b-132">응용 프로그램 데이터 저장소(예: 관계형 데이터베이스)</span><span class="sxs-lookup"><span data-stu-id="c542b-132">Application data stores, such as relational databases.</span></span>
    * <span data-ttu-id="c542b-133">응용 프로그램에서 생성하는 정적 파일(예: 웹 서버 로그 파일)</span><span class="sxs-lookup"><span data-stu-id="c542b-133">Static files produced by applications, such as web server log files.</span></span>
    * <span data-ttu-id="c542b-134">실시간 데이터 원본(예: IoT 장치)</span><span class="sxs-lookup"><span data-stu-id="c542b-134">Real-time data sources, such as IoT devices.</span></span>

* <span data-ttu-id="c542b-135">**데이터 저장소**.</span><span class="sxs-lookup"><span data-stu-id="c542b-135">**Data storage**.</span></span> <span data-ttu-id="c542b-136">일괄 처리 작업을 위한 데이터는 대개 대용량 파일을 다양한 형식으로 저장할 수 있는 분산 파일 저장소에 저장됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-136">Data for batch processing operations is typically stored in a distributed file store that can hold high volumes of large files in various formats.</span></span> <span data-ttu-id="c542b-137">이런 종류의 저장소를 *Data Lake*라고도 합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-137">This kind of store is often called a *data lake*.</span></span> <span data-ttu-id="c542b-138">이 저장소를 구현하기 위한 옵션으로는 Azure Data Lake Store 또는 Azure Storage의 BLOB 컨테이너가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-138">Options for implementing this storage include Azure Data Lake Store or blob containers in Azure Storage.</span></span>

* <span data-ttu-id="c542b-139">**일괄 처리**.</span><span class="sxs-lookup"><span data-stu-id="c542b-139">**Batch processing**.</span></span> <span data-ttu-id="c542b-140">데이터 집합이 너무 큰 경우 빅 데이터 솔루션은 필터링, 집계 및 그 밖의 분석을 위한 데이터를 준비하기 위해 장기간 실행되는 일괄 처리 작업을 사용하여 데이터 파일을 처리해야 하는 경우가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-140">Because the data sets are so large, often a big data solution must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="c542b-141">일반적으로 이러한 작업은 원본 파일 읽기 및 처리와 새 파일에 출력 작성으로 이루어집니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-141">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span> <span data-ttu-id="c542b-142">옵션에는 Azure Data Lake Analytics에서 U-SQL 작업 실행, HDInsight Hadoop 클러스터에서 Hive, Pig 또는 사용자 지정 Map/Reduce 작업 사용, HDInsight Spark 클러스터에서 Java, Scala 또는 Python 프로그램 사용 등이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-142">Options include running U-SQL jobs in Azure Data Lake Analytics, using Hive, Pig, or custom Map/Reduce jobs in an HDInsight Hadoop cluster, or using Java, Scala, or Python programs in an HDInsight Spark cluster.</span></span>

* <span data-ttu-id="c542b-143">**실시간 메시지 수집**.</span><span class="sxs-lookup"><span data-stu-id="c542b-143">**Real-time message ingestion**.</span></span> <span data-ttu-id="c542b-144">솔루션에 실시간 원본이 포함되는 경우 스트림 처리를 위해 실시간 메시지를 캡처하고 저장하는 방법이 아키텍처에 포함되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-144">If the solution includes real-time sources, the architecture must include a way to capture and store real-time messages for stream processing.</span></span> <span data-ttu-id="c542b-145">이는 들어오는 메시지가 처리를 위해 폴더에 저장되는 간단한 데이터 저장소일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-145">This might be a simple data store, where incoming messages are dropped into a folder for processing.</span></span> <span data-ttu-id="c542b-146">그러나 많은 솔루션에는 메시지에 대한 버퍼로 작동하고 스케일 아웃 처리, 안정적인 전달 및 기타 메시지 큐 의미 체계를 지원하는 메시지 수집 저장소가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-146">However, many solutions need a message ingestion store to act as a buffer for messages, and to support scale-out processing, reliable delivery, and other message queuing semantics.</span></span> <span data-ttu-id="c542b-147">스트리밍 아키텍처의 이 부분을 스트림 버퍼링이라고도 합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-147">This portion of a streaming architecture is often referred to as stream buffering.</span></span> <span data-ttu-id="c542b-148">옵션에는 Azure Event Hubs, Azure IoT Hub 및 Kafka가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-148">Options include Azure Event Hubs, Azure IoT Hub, and Kafka.</span></span>

* <span data-ttu-id="c542b-149">**스트림 처리**.</span><span class="sxs-lookup"><span data-stu-id="c542b-149">**Stream processing**.</span></span> <span data-ttu-id="c542b-150">실시간 메시지를 캡처한 후 솔루션은 필터링, 집계 및 그 밖의 분석을 위한 데이터 준비를 통해 해당 메시지를 처리해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-150">After capturing real-time messages, the solution must process them by filtering, aggregating, and otherwise preparing the data for analysis.</span></span> <span data-ttu-id="c542b-151">그런 다음, 처리된 스트림 데이터는 출력 싱크에 기록됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-151">The processed stream data is then written to an output sink.</span></span> <span data-ttu-id="c542b-152">Azure Stream Analytics는 제한되지 않은(Unbounded) 스트림에서 작동하는 영구적으로 실행되는 SQL 쿼리를 기반으로 관리되는 스트림 처리 서비스를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-152">Azure Stream Analytics provides a managed stream processing service based on perpetually running SQL queries that operate on unbounded streams.</span></span> <span data-ttu-id="c542b-153">또한 HDInsight 클러스터에서 Storm 및 Spark Streaming과 같은 오픈 소스 Apache 스트리밍 기술을 사용할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-153">You can also use open source Apache streaming technologies like Storm and Spark Streaming in an HDInsight cluster.</span></span>

* <span data-ttu-id="c542b-154">**분석 데이터 저장소**.</span><span class="sxs-lookup"><span data-stu-id="c542b-154">**Analytical data store**.</span></span> <span data-ttu-id="c542b-155">대다수의 빅 데이터 솔루션은 분석할 데이터를 준비한 다음, 분석 도구를 사용하여 쿼리할 수 있는 구조화된 형식으로 처리된 데이터를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-155">Many big data solutions prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span> <span data-ttu-id="c542b-156">이러한 쿼리를 처리하는 데 사용되는 분석 데이터 저장소로는 대부분의 기존 BI(비즈니스 인텔리전스) 솔루션에서 볼 수 있는 Kimball 스타일의 관계형 데이터 웨어하우스가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-156">The analytical data store used to serve these queries can be a Kimball-style relational data warehouse, as seen in most traditional business intelligence (BI) solutions.</span></span> <span data-ttu-id="c542b-157">또는 HBase와 같이 대기 시간이 짧은 NoSQL 기술이나, 분산 데이터 저장소의 데이터 파일에 대한 메타데이터 추상화를 제공하는 대화형 Hive 데이터베이스를 통해 데이터를 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-157">Alternatively, the data could be presented through a low-latency NoSQL technology such as HBase, or an interactive Hive database that provides a metadata abstraction over data files in the distributed data store.</span></span> <span data-ttu-id="c542b-158">Azure SQL Data Warehouse는 클라우드 기반의 대규모 데이터 웨어하우징을 위한 관리형 서비스를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-158">Azure SQL Data Warehouse provides a managed service for large-scale, cloud-based data warehousing.</span></span> <span data-ttu-id="c542b-159">HDInsight는 대화형 Hive, HBase 및 Spark SQL을 지원하며 이들을 사용하여 분석용 데이터를 처리할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-159">HDInsight supports Interactive Hive, HBase, and Spark SQL, which can also be used to serve data for analysis.</span></span>

* <span data-ttu-id="c542b-160">**분석 및 보고**.</span><span class="sxs-lookup"><span data-stu-id="c542b-160">**Analysis and reporting**.</span></span> <span data-ttu-id="c542b-161">대부분의 빅 데이터 솔루션의 목표는 분석 및 보고를 통해 데이터에 대한 정보를 제공하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-161">The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span> <span data-ttu-id="c542b-162">사용자의 데이터 분석을 지원하도록 아키텍처에는 Azure Analysis Services의 다차원 OLAP 큐브 또는 테이블 형식 데이터 모델과 같은 데이터 모델링 계층이 포함될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-162">To empower users to analyze the data, the architecture may include a data modeling layer, such as a multidimensional OLAP cube or tabular data model in Azure Analysis Services.</span></span> <span data-ttu-id="c542b-163">또한 Microsoft Power BI 또는 Microsoft Excel의 모델링 기술 및 시각화 기술을 사용하여 셀프 서비스 BI를 지원할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-163">It might also support self-service BI, using the modeling and visualization technologies in Microsoft Power BI or Microsoft Excel.</span></span> <span data-ttu-id="c542b-164">분석 및 보고는 데이터 과학자 또는 데이터 분석가에 의한 대화형 데이터 탐색의 형태를 취할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-164">Analysis and reporting can also take the form of interactive data exploration by data scientists or data analysts.</span></span> <span data-ttu-id="c542b-165">이러한 시나리오의 경우 많은 Azure 서비스가 Jupyter와 같은 분석용 노트북을 지원하므로 사용자가 Python 또는 R을 사용하여 기존 기술을 활용할 수 있습니다. 대규모 데이터 탐색의 경우 Microsoft R Server를 독립적으로 또는 Spark와 함께 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-165">For these scenarios, many Azure services support analytical notebooks, such as Jupyter, enabling these users to leverage their existing skills with Python or R. For large-scale data exploration, you can use Microsoft R Server, either standalone or with Spark.</span></span>

* <span data-ttu-id="c542b-166">**오케스트레이션**.</span><span class="sxs-lookup"><span data-stu-id="c542b-166">**Orchestration**.</span></span> <span data-ttu-id="c542b-167">대부분의 빅 데이터 솔루션은 원본 데이터를 변환하고, 여러 원본과 싱크 간에 데이터를 이동하고, 처리된 데이터를 분석 데이터 저장소로 로드하거나, 또는 결과를 보고서나 대시보드로 직접 전달하는 '반복되는 데이터 처리 작업'을 워크플로 내에 캡슐화한 형태로 구성됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-167">Most big data solutions consist of repeated data processing operations, encapsulated in workflows, that transform source data, move data between multiple sources and sinks, load the processed data into an analytical data store, or push the results straight to a report or dashboard.</span></span> <span data-ttu-id="c542b-168">이러한 워크플로를 자동화하기 위해 Azure Data Factory 또는 Apache Oozie 및 Sqoop과 같은 오케스트레이션 기술을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-168">To automate these workflows, you can use an orchestration technology such Azure Data Factory or Apache Oozie and Sqoop.</span></span>

## <a name="lambda-architecture"></a><span data-ttu-id="c542b-169">람다 아키텍처</span><span class="sxs-lookup"><span data-stu-id="c542b-169">Lambda architecture</span></span>

<span data-ttu-id="c542b-170">매우 큰 데이터 집합을 사용할 경우 클라이언트가 필요로 하는 쿼리 종류를 실행하는 데 시간이 오래 걸릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-170">When working with very large data sets, it can take a long time to run the sort of queries that clients need.</span></span> <span data-ttu-id="c542b-171">이러한 쿼리는 실시간으로 수행할 수 없으며, [MapReduce](https://en.wikipedia.org/wiki/MapReduce)와 같이 전체 데이터 집합에 대해 병렬로 작동하는 알고리즘이 필요할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-171">These queries can't be performed in real time, and often require algorithms such as [MapReduce](https://en.wikipedia.org/wiki/MapReduce) that operate in parallel across the entire data set.</span></span> <span data-ttu-id="c542b-172">그런 후 결과는 원시 데이터와 별도로 저장되고 쿼리에 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-172">The results are then stored separately from the raw data and used for querying.</span></span>

<span data-ttu-id="c542b-173">이 방식의 한 가지 단점은 대기 시간이 발생한다는 것입니다. 즉, 처리에 몇 시간이 걸릴 경우 쿼리는 몇 시간 늦은 결과를 반환할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-173">One drawback to this approach is that it introduces latency &mdash; if processing takes a few hours, a query may return results that are several hours old.</span></span> <span data-ttu-id="c542b-174">일부 결과를 실시간으로 가져온 후(정확도가 다소 손실될 수 있음) 이러한 결과를 일괄 처리 분석의 결과와 조합하면 이상적일 것입니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-174">Ideally, you would like to get some results in real time (perhaps with some loss of accuracy), and combine these results with the results from the batch analytics.</span></span>

<span data-ttu-id="c542b-175">Nathan Marz가 최초로 제안한 **람다 아키텍처**는 데이터 흐름에 대해 두 개의 경로를 만들어 이 문제를 해결합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-175">The **lambda architecture**, first proposed by Nathan Marz, addresses this problem by creating two paths for data flow.</span></span> <span data-ttu-id="c542b-176">시스템으로 들어오는 모든 데이터는 다음 두 경로를 거칩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-176">All data coming into the system goes through these two paths:</span></span>

* <span data-ttu-id="c542b-177">**일괄 처리 계층**(실행 부하 미달 경로)은 들어오는 모든 데이터를 원시 형식으로 저장하고 해당 데이터에 대해 일괄 처리를 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-177">A **batch layer** (cold path) stores all of the incoming data in its raw form and performs batch processing on the data.</span></span> <span data-ttu-id="c542b-178">이러한 처리의 결과는 **일괄 처리 보기**로 저장됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-178">The result of this processing is stored as a **batch view**.</span></span>

* <span data-ttu-id="c542b-179">**빠른 레이어**(실행 부하 과다 경로)는 데이터를 실시간으로 분석합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-179">A **speed layer** (hot path) analyzes data in real time.</span></span> <span data-ttu-id="c542b-180">이 계층은 정확도는 떨어지지만 짧은 대기 시간을 제공하도록 디자인되었습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-180">This layer is designed for low latency, at the expense of accuracy.</span></span>

<span data-ttu-id="c542b-181">일괄 처리 계층은 효율적인 쿼리를 위해 일괄 처리 보기를 인덱싱하는 **서비스 계층**으로 이동됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-181">The batch layer feeds into a **serving layer** that indexes the batch view for efficient querying.</span></span> <span data-ttu-id="c542b-182">빠른 계층은 가장 최근 데이터를 기준으로 하는 증분 업데이트로 서비스 계층을 업데이트합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-182">The speed layer updates the serving layer with incremental updates based on the most recent data.</span></span>

![람다 아키텍처 다이어그램](./images/lambda.png)

<span data-ttu-id="c542b-184">실행 부하 과다 경로로 이동하는 데이터는 빠른 계층의 대기 시간 요구 사항으로 제약되므로 가능한 한 빠르게 처리될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-184">Data that flows into the hot path is constrained by latency requirements imposed by the speed layer, so that it can be processed as quickly as possible.</span></span> <span data-ttu-id="c542b-185">대개, 가능한 한 빠르게 데이터를 준비하기 위해 정확도는 어느 정도 손상되게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-185">Often, this requires a tradeoff of some level of accuracy in favor of data that is ready as quickly as possible.</span></span> <span data-ttu-id="c542b-186">예를 들어, 많은 수의 온도 센서가 원격 분석 데이터를 보내는 IoT 시나리오를 고려해 보세요.</span><span class="sxs-lookup"><span data-stu-id="c542b-186">For example, consider an IoT scenario where a large number of temperature sensors are sending telemetry data.</span></span> <span data-ttu-id="c542b-187">들어오는 데이터의 슬라이딩 기간을 처리하기 위해 빠른 계층을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-187">The speed layer may be used to process a sliding time window of the incoming data.</span></span> 

<span data-ttu-id="c542b-188">반면에 실행 부하 미달 경로로 흐르는 데이터에는 동일한 짧은 대기 시간 요구 사항이 적용되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-188">Data flowing into the cold path, on the other hand, is not subject to the same low latency requirements.</span></span> <span data-ttu-id="c542b-189">따라서 큰 데이터 집합에서 시간이 많이 소요되는 높은 정확도의 계산이 수행될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-189">This allows for high accuracy computation across large data sets, which can be very time intensive.</span></span> 

<span data-ttu-id="c542b-190">결과적으로, 실행 부하 과다 경로 및 실행 부하 미달 경로가 분석 클라이언트 응용 프로그램에서 수렴됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-190">Eventually, the hot and cold paths converge at the analytics client application.</span></span> <span data-ttu-id="c542b-191">클라이언트는 덜 정확할 수 있는 데이터를 실시간으로 표시해야 할 경우 실행 부하 과다 경로에서 해당 결과를 얻게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-191">If the client needs to display timely, yet potentially less accurate data in real time, it will acquire its result from the hot path.</span></span> <span data-ttu-id="c542b-192">그렇지 않은 경우, 실행 부하 미달 경로에서 결과를 선택하여 시기 적절성은 떨어지지만 좀 더 정확한 데이터를 표시합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-192">Otherwise, it will select results from the cold path to display less timely but more accurate data.</span></span> <span data-ttu-id="c542b-193">즉, 실행 부하 과다 경로는 비교적 짧은 기간 동안 데이터를 보유하며, 그 이후에는 실행 부하 미달 경로의 보다 정확한 데이터로 업데이트될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-193">In other words, the hot path has data for a relatively small window of time, after which the results can be updated with more accurate data from the cold path.</span></span>

<span data-ttu-id="c542b-194">일괄 처리 계층에 저장된 원시 데이터는 변경할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-194">The raw data stored at the batch layer is immutable.</span></span> <span data-ttu-id="c542b-195">들어오는 데이터는 항상 기존 데이터에 추가되며, 이전 데이터를 덮어쓰지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-195">Incoming data is always appended to the existing data, and the previous data is never overwritten.</span></span> <span data-ttu-id="c542b-196">특정 데이터 값의 변경 내용은 새 타임스탬프 이벤트 레코드로 저장됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-196">Any changes to the value of a particular datum are stored as a new timestamped event record.</span></span> <span data-ttu-id="c542b-197">따라서 데이터가 수집되는 모든 시점에서 재계산을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-197">This allows for recomputation at any point in time across the history of the data collected.</span></span> <span data-ttu-id="c542b-198">원래의 원시 데이터에서 일괄 처리 보기를 다시 계산하는 기능은 매우 중요합니다. 시스템 변화에 따라 새로운 보기를 만들 수 있기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-198">The ability to recompute the batch view from the original raw data is important, because it allows for new views to be created as the system evolves.</span></span> 

## <a name="kappa-architecture"></a><span data-ttu-id="c542b-199">카파 아키텍처</span><span class="sxs-lookup"><span data-stu-id="c542b-199">Kappa architecture</span></span>

<span data-ttu-id="c542b-200">람다 아키텍처의 단점은 복잡하다는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-200">A drawback to the lambda architecture is its complexity.</span></span> <span data-ttu-id="c542b-201">처리 논리는 다른 프레임워크를 사용하는 실행 부하 과다 경로와 실행 부하 미달 경로의 두 위치에서 나타납니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-201">Processing logic appears in two different places &mdash; the cold and hot paths &mdash; using different frameworks.</span></span> <span data-ttu-id="c542b-202">이로 인해 중복된 계산 논리와 두 경로의 아키텍처 관리에 따른 복잡성이 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-202">This leads to duplicate computation logic and the complexity of managing the architecture for both paths.</span></span>

<span data-ttu-id="c542b-203">**카파 아키텍처**는 람다 아키텍처의 대안으로 Jay Kreps가 제안했습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-203">The **kappa architecture** was proposed by Jay Kreps as an alternative to the lambda architecture.</span></span> <span data-ttu-id="c542b-204">람다 아키텍처와 기본 목표는 같지만, 모든 데이터가 스트림 처리 시스템을 사용하여 단일 경로를 따라 흐른다는 중요한 차이점이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-204">It has the same basic goals as the lambda architecture, but with an important distinction: All data flows through a single path, using a stream processing system.</span></span> 

![카파 아키텍처 다이어그램](./images/kappa.png)

<span data-ttu-id="c542b-206">이벤트 데이터가 변경 불가능하며, 일부가 아닌 전체가 수집된다는 측면은 람다 아키텍처의 일괄 처리 계층과 약간 유사합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-206">There are some similarities to the lambda architecture's batch layer, in that the event data is immutable and all of it is collected, instead of a subset.</span></span> <span data-ttu-id="c542b-207">데이터는 이벤트 스트림 형태로 내결함성이 있는 분산 통합 로그로 수집됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-207">The data is ingested as a stream of events into a distributed and fault tolerant unified log.</span></span> <span data-ttu-id="c542b-208">이러한 이벤트는 순서대로 정렬되며, 이벤트의 현재 상태는 추가되는 새 이벤트에 의해서만 변경됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-208">These events are ordered, and the current state of an event is changed only by a new event being appended.</span></span> <span data-ttu-id="c542b-209">람다 아키텍처의 빠른 계층과 비슷하게, 모든 이벤트 처리가 입력 스트림에서 수행되고 실시간 보기로 유지됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-209">Similar to a lambda architecture's speed layer, all event processing is performed on the input stream and persisted as a real-time view.</span></span> 

<span data-ttu-id="c542b-210">전체 데이터 집합을 다시 계산해야 하는 경우(일괄 처리 계층이 람다에서 수행하는 것과 같음) 스트림을 재생하기만 하면 됩니다. 그러면 병렬화를 통해 시기 적절하게 계산이 완료됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-210">If you need to recompute the entire data set (equivalent to what the batch layer does in lambda), you simply replay the stream, typically using parallelism to complete the computation in a timely fashion.</span></span>

## <a name="internet-of-things-iot"></a><span data-ttu-id="c542b-211">IoT(사물 인터넷)</span><span class="sxs-lookup"><span data-stu-id="c542b-211">Internet of Things (IoT)</span></span>

<span data-ttu-id="c542b-212">실제 관점에서 보면, IoT(사물 인터넷)는 인터넷에 연결된 모든 장치를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-212">From a practical viewpoint, Internet of Things (IoT) represents any device that is connected to the Internet.</span></span> <span data-ttu-id="c542b-213">여기에는 PC, 휴대폰, 스마트 워치, 스마트 자동 온도 조절기, 스마트 냉장고, 연결된 자동차, 심장 모니터링 보형물 및 인터넷에 연결되고 데이터를 주고받는 모든 장치가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-213">This includes your PC, mobile phone, smart watch, smart thermostat, smart refrigerator, connected automobile, heart monitoring implants, and anything else that connects to the Internet and sends or receives data.</span></span> <span data-ttu-id="c542b-214">연결된 장치 수가 매일 증가하고 있으며 이러한 장치에서 수집되는 데이터의 양도 증가하고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-214">The number of connected devices grows every day, as does the amount of data collected from them.</span></span> <span data-ttu-id="c542b-215">종종 이러한 데이터는 매우 제한적이면서, 경우에 따라 대기 시간이 긴 환경에서 수집됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-215">Often this data is being collected in highly constrained, sometimes high-latency environments.</span></span> <span data-ttu-id="c542b-216">경우에 따라 데이터가 수천만 또는 수백만 개의 장치에서 낮은 대기 시간 환경으로 전송되므로, 그에 따라 데이터를 빠르게 수집하고 처리하는 기능도 요구됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-216">In other cases, data is sent from low-latency environments by thousands or millions of devices, requiring the ability to rapidly ingest the data and process accordingly.</span></span> <span data-ttu-id="c542b-217">따라서 이러한 제약 및 고유한 요구 사항을 처리하기 위한 적절한 계획이 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-217">Therefore, proper planning is required to handle these constraints and unique requirements.</span></span>

<span data-ttu-id="c542b-218">이벤트 기반 아키텍처는 IoT 솔루션의 핵심입니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-218">Event-driven architectures are central to IoT solutions.</span></span> <span data-ttu-id="c542b-219">다음 다이어그램은 IoT의 가능한 논리 아키텍처를 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-219">The following diagram shows a possible logical architecture for IoT.</span></span> <span data-ttu-id="c542b-220">이 다이어그램에서는 아키텍처의 이벤트 스트리밍 구성 요소가 강조 표시되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-220">The diagram emphasizes the event-streaming components of the architecture.</span></span>

![IoT 아키텍처](../../guide/architecture-styles/images/iot.png)

<span data-ttu-id="c542b-222">**클라우드 게이트웨이**는 안정적이고 대기 시간이 짧은 메시징 시스템을 사용하여 클라우드 경계에서 장치 이벤트를 수집합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-222">The **cloud gateway** ingests device events at the cloud boundary, using a reliable, low latency messaging system.</span></span>

<span data-ttu-id="c542b-223">장치는 클라우드 게이트웨이에 직접 또는 **필드 게이트웨이**를 통해 이벤트를 보낼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-223">Devices might send events directly to the cloud gateway, or through a **field gateway**.</span></span> <span data-ttu-id="c542b-224">필드 게이트웨이는 이벤트를 수신하여 클라우드 게이트웨이에 전달하는 특수 장치 또는 소프트웨어이며 일반적으로 장치와 함께 배치됩니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-224">A field gateway is a specialized device or software, usually collocated with the devices, that receives events and forwards them to the cloud gateway.</span></span> <span data-ttu-id="c542b-225">필드 게이트웨이에서 필터링, 집계, 프로토콜 변환 등의 기능을 수행하여 원시 장치 이벤트를 전처리할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-225">The field gateway might also preprocess the raw device events, performing functions such as filtering, aggregation, or protocol transformation.</span></span>

<span data-ttu-id="c542b-226">수집된 이벤트는 데이터를 저장소 등으로 라우트하거나 분석 및 기타 처리를 수행할 수 있는 하나 이상의 **스트림 프로세서**를 통과합니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-226">After ingestion, events go through one or more **stream processors** that can route the data (for example, to storage) or perform analytics and other processing.</span></span>

<span data-ttu-id="c542b-227">다음은 몇 가지 일반적인 처리 유형입니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-227">The following are some common types of processing.</span></span> <span data-ttu-id="c542b-228">(전체 목록은 아닙니다.)</span><span class="sxs-lookup"><span data-stu-id="c542b-228">(This list is certainly not exhaustive.)</span></span>

- <span data-ttu-id="c542b-229">보관 또는 배치 분석을 위해 콜드 스토리지에 이벤트 데이터 기록.</span><span class="sxs-lookup"><span data-stu-id="c542b-229">Writing event data to cold storage, for archiving or batch analytics.</span></span>

- <span data-ttu-id="c542b-230">실행 부하 과다 경로 분석, (거의) 실시간으로 이벤트 스트림을 분석하여 이상 검색, 롤링 기간의 패턴 인식 또는 스트림에서 특정 조건이 발생할 때 경고 트리거.</span><span class="sxs-lookup"><span data-stu-id="c542b-230">Hot path analytics, analyzing the event stream in (near) real time, to detect anomalies, recognize patterns over rolling time windows, or trigger alerts when a specific condition occurs in the stream.</span></span> 

- <span data-ttu-id="c542b-231">알림, 경보 등 장치에서 수신된 특수 유형의 비원격 분석 메시지 처리.</span><span class="sxs-lookup"><span data-stu-id="c542b-231">Handling special types of nontelemetry messages from devices, such as notifications and alarms.</span></span> 

- <span data-ttu-id="c542b-232">기계 학습.</span><span class="sxs-lookup"><span data-stu-id="c542b-232">Machine learning.</span></span>

<span data-ttu-id="c542b-233">회색으로 표시된 상자는 이벤트 스트리밍과 직접 관련되지 않은 IoT 시스템의 구성 요소를 표시하지만 전체 표시를 위해 여기에 포함되었습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-233">The boxes that are shaded gray show components of an IoT system that are not directly related to event streaming, but are included here for completeness.</span></span>

- <span data-ttu-id="c542b-234">**장치 레지스트리**는 장치 ID와 일반적으로 장치 메타데이터(예: 위치)를 포함하는 프로비전된 장치의 데이터베이스입니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-234">The **device registry** is a database of the provisioned devices, including the device IDs and usually device metadata, such as location.</span></span>

- <span data-ttu-id="c542b-235">**프로비저닝 API**는 새 장치를 프로비전 및 등록하기 위한 공통 외부 인터페이스입니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-235">The **provisioning API** is a common external interface for provisioning and registering new devices.</span></span>

- <span data-ttu-id="c542b-236">일부 IoT 솔루션에서는 **명령 및 제어 메시지**를 장치에 전송할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c542b-236">Some IoT solutions allow **command and control messages** to be sent to devices.</span></span>

<span data-ttu-id="c542b-237">관련 Azure 서비스:</span><span class="sxs-lookup"><span data-stu-id="c542b-237">Relevant Azure services:</span></span>

- [<span data-ttu-id="c542b-238">Azure IoT Hub</span><span class="sxs-lookup"><span data-stu-id="c542b-238">Azure IoT Hub</span></span>](https://azure.microsoft.com/services/iot-hub/)
- [<span data-ttu-id="c542b-239">Azure Event Hubs</span><span class="sxs-lookup"><span data-stu-id="c542b-239">Azure Event Hubs</span></span>](https://azure.microsoft.com/services/event-hubs/)
- [<span data-ttu-id="c542b-240">Azure Stream Analytics</span><span class="sxs-lookup"><span data-stu-id="c542b-240">Azure Stream Analytics</span></span>](https://azure.microsoft.com/services/stream-analytics/)  

<span data-ttu-id="c542b-241">[Azure IoT 참조 아키텍처](https://azure.microsoft.com/updates/microsoft-azure-iot-reference-architecture-available/)를 읽어 Azure의 IoT에 대해 자세히 알아보세요.</span><span class="sxs-lookup"><span data-stu-id="c542b-241">Learn more about IoT on Azure by reading the [Azure IoT reference architecture](https://azure.microsoft.com/updates/microsoft-azure-iot-reference-architecture-available/).</span></span>


