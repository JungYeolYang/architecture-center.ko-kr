---
title: 일괄 처리
description: ''
author: zoinerTejada
ms.date: 02/12/2018
ms.openlocfilehash: fe07d4d6501d4778025b75807f4d6be5854c3e09
ms.sourcegitcommit: e7e0e0282fa93f0063da3b57128ade395a9c1ef9
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 12/05/2018
ms.locfileid: "52901986"
---
# <a name="batch-processing"></a>일괄 처리

일반적인 빅 데이터 시나리오는 미사용 데이터의 일괄 처리입니다. 이 시나리오에서는 원본 데이터는 원본 애플리케이션 자체에 의해 또는 오케스트레이션 워크플로에 의해 데이터 저장소에 로드됩니다. 그런 다음 데이터는 병렬 작업에 의해 내부에서 처리됩니다(오케스트레이션 워크플로를 통해서도 처리가 시작될 수 있음). 이러한 처리에는 변환된 결과가 분석 및 보고 구성 요소에 의해 쿼리될 수 있는 분석 데이터 저장소로 로드되기 이전의 여러 반복적인 단계가 포함될 수 있습니다.

예를 들어, 웹 서버의 로그가 폴더에 복사된 후 야간에 처리되면서 웹 활동의 일일 보고서가 생성될 수 있습니다.

![](./images/batch-pipeline.png)

## <a name="when-to-use-this-solution"></a>이 솔루션을 사용해야 하는 경우

일괄 처리는 간단한 데이터 변환에서 보다 완전한 ETL(추출-변환-로드) 파이프라인에 이르는 다양한 시나리오에서 사용됩니다. 빅 데이터 컨텍스트에서 일괄 처리는 계산에 상당한 시간이 소요되는 매우 큰 데이터 집합에 작동될 수 있습니다. (예를 들어, [람다 아키텍처](../big-data/index.md#lambda-architecture)를 참조하세요.) 일괄 처리는 일반적으로 추가적인 대화형 탐색으로 이어지며, 기계 학습을 위한 모델링 지원 데이터를 제공하거나 분석 및 시각화에 최적화된 데이터 저장소로 데이터를 씁니다.

일괄 처리의 한 가지 예는 반구조화된 대규모 플랫 CSV 또는 JSON 파일 집합을 추가 쿼리 준비가 완료된 스키마화 및 구조화 형식으로 변환하는 것입니다. 일반적으로 데이터가 수집에 사용되는 원시 형식(예: CSV)에서 쿼리 성능을 높일 수 있는 이진 형식으로 변환됩니다. 이 방법에서는 데이터를 열 형식으로 저장하고, 종종 데이터에 대한 인덱스 및 인라인 통계를 제공하기 때문에 성능이 향상됩니다.

## <a name="challenges"></a>과제

- **데이터 형식 및 인코딩** 가장 까다로운 디버그 문제 일부는 파일이 예기치 않은 형식이나 인코딩을 사용할 때 나타납니다. 예를 들어, 원본 파일은 UTF-16 및 UTF-8 인코딩을 혼합해서 사용하거나 예기치 않은 구분 기호(공백 및 탭)을 포함하거나 예기치 않은 문자를 포함할 수 있습니다. 또 다른 일반적인 예는 구분 기호로 해석되는 탭, 공백 또는 쉼표를 포함하는 텍스트 필드입니다. 데이터 로드 및 구문 분석 논리는 이러한 문제를 감지하여 처리할 만큼 충분히 유연해야 합니다.

- **시간 조각 조정.** 종종 원본 데이터는 연도, 월, 일, 시간 등을 기준으로 구성되는 처리 기간을 반영하는 폴더 계층 구조에 배치됩니다. 경우에 따라 데이터 늦게 도착할 수도 있습니다. 예를 들어, 웹 서버에서 오류가 발생하면 3월 7일에 대한 로그는 3월 9일까지 처리되기 위한 폴더에 저장되지 않습니다. 단지 너무 늦었기 때문에 무시될까요? 다운스트림 처리 논리가 잘못된 순서의 레코드를 처리할 수 있나요?

## <a name="architecture"></a>아키텍처

일괄 처리 아키텍처는 위 다이어그램에 표시되는 다음 논리적 구성 요소를 갖습니다.

- **데이터 저장소.** 일반적으로 다양한 형식의 대용량 파일의 리포지토리로 사용될 수 있는 분산 파일 저장소입니다. 일반적으로 이 종류의 저장소를 데이터 레이크라고도 합니다. 

- **일괄 처리.** 빅 데이터는 일반적으로 대용량이므로 빅 데이터 솔루션은 필터링, 집계 및 그 밖의 분석을 위한 데이터를 준비하기 위해 장기간 실행되는 일괄 처리 작업을 사용하여 데이터 파일을 처리해야 하는 경우가 있습니다. 일반적으로 이러한 작업은 원본 파일 읽기 및 처리와 새 파일에 출력 작성으로 이루어집니다. 

- **분석 데이터 저장소.** 대다수의 빅 데이터 솔루션은 분석할 데이터를 준비한 다음, 분석 도구를 사용하여 쿼리할 수 있는 구조화된 형식으로 처리된 데이터를 제공하도록 디자인되어 있습니다. 

- **분석 및 보고.** 대부분의 빅 데이터 솔루션의 목표는 분석 및 보고를 통해 데이터에 대한 정보를 제공하는 것입니다. 

- **오케스트레이션.** 일괄 처리를 사용할 경우, 일반적으로 데이터를 데이터 저장소, 일괄 처리, 분석 데이터 저장소 및 보고 계층으로 마이그레이션 또는 복사하기 위해 오케스트레이션이 어느 정도 필요합니다.

## <a name="technology-choices"></a>기술 선택

다음과 같은 기술은 Azure의 일괄 처리 솔루션에 권장됩니다.

### <a name="data-storage"></a>데이터 저장소

- **Azure Storage Blob 컨테이너**. 많은 기존 Azure 비즈니스 프로세스가 이미 Azure Blob 저장소를 활용하고 있으므로 빅 데이터 저장소로도 적합합니다.
- **Azure Data Lake Store**. Azure Data Lake Store는 모든 크기의 파일을 위한 거의 제한 없는 저장소와 포괄적인 보안 옵션을 제공하므로, 이기종 형식의 데이터에 대한 중앙 저장소를 요구하는 대규모 빅 데이터 솔루션에 아주 적합합니다.

자세한 내용은 [데이터 저장소](../technology-choices/data-storage.md)를 참조하세요.

### <a name="batch-processing"></a>일괄 처리

- **U-SQL**. U-SQL은 Azure Data Lake Analytics에 사용되는 쿼리 처리 언어입니다. 이 언어는 SQL의 선언적 특성을 C#의 프로시저 확장성과 결합하고, 병렬처 리를 활용하여 방대한 데이터를 효율적으로 처리할 수 있도록 합니다.
- **Hive**. Hive는 HDInsight를 비롯한 대부분의 Hadoop 배포에서 지원되는 SQL 유사 언어입니다. Azure Blob 저장소 및 Azure Data Lake Store를 포함하는 모든 HDFS 호환 저장소에서 데이터를 처리하는 데 사용할 수 있습니다.
- **Pig**. Pig는 HDInsight를 비롯한 많은 Hadoop 배포에서 사용되는 선언적 빅 데이터 처리 언어입니다. 구조화되지 않았거나 반구조화된 데이터를 처리하는 데 특히 유용합니다.
- **Spark**. Spark 엔진은 Java, Scala 및 Python 등의 다양한 언어로 작성된 일괄 처리 프로그램을 지원합니다. Spark는 분산 아키텍처를 사용하여 여러 작업자 노드에서 동시에 데이터를 처리합니다.

자세한 내용은 [일괄 처리](../technology-choices/batch-processing.md)를 참조하세요.

### <a name="analytical-data-store"></a>분석 데이터 저장소

- **SQL Data Warehouse**. Azure SQL Data Warehouse는 SQL Server 데이터베이스 기술을 기준으로 하며, 대규모 데이터 웨어하우징 작업을 지원하도록 최적화된 관리되는 서비스입니다.
- **Spark SQL**. Spark SQL은 SQL 구문을 사용하여 쿼리할 수 있는 데이터프레임 및 테이블을 만들 수 있도록 지원하는 Spark 기반 API입니다.
- **HBase**. HBase는 구조화 및 반구조화 데이터를 쿼리하기 위한 유연한 고성능 옵션을 제공하는 낮은 대기 시간의 NoSQL 저장소입니다.
- **Hive**. 일괄 처리에 유용하다는 것 외에도, Hive는 전형적인 관계형 데이터베이스 관리 시스템과 개념적으로 유사한 데이터베이스 아키텍처를 제공합니다. Tez 엔진 및 Stinger 이니셔티브와 같은 혁신을 통해 Hive 쿼리 성능을 개선했으므로 일부 시나리오에서는 Hive 테이블을 분석 쿼리의 원본으로 효과적으로 사용할 수 있습니다.

자세한 내용은 [분석 데이터 저장소](../technology-choices/analytical-data-stores.md)를 참조하세요.

### <a name="analytics-and-reporting"></a>분석 및 보고

- **Azure Analysis Services**. 많은 빅 데이터 솔루션에서는 보고서, 대시보드 및 대화형 "조각화 및 분석" 방식의 분석의 기준이 될 수 있는 중앙 집중식 OLAP(온라인 분석 처리) 데이터 모델(큐브라고도 함)을 포함하여 기존 엔터프라이즈 비즈니스 인텔리전스 아키텍처를 에뮬레이트합니다. Azure Analysis Services는 이 요구 사항을 충족하도록 테이블 형식 모델 만들기를 지원합니다.
- **Power BI**. Power BI는 데이터 분석가가 OLAP 모델에서 또는 분석 데이터 저장소에서 직접, 데이터 모델을 기준으로 대화형 데이터 시각화를 만들 수 있도록 합니다.
- **Microsoft Excel**. Microsoft Excel은 전 세계적으로 가장 널리 사용되는 소프트웨어 애플리케이션 중 하나로, 다양한 데이터 분석 및 시각화 기능을 제공합니다. 데이터 분석가는 Excel을 사용하여 분석 데이터 저장소에서 문서 데이터 모델을 작성하거나 OLAP 데이터 모델의 데이터를 대화형 피벗 테이블 및 차트로 검색할 수 있습니다.

자세한 내용은 [분석 및 보고](../technology-choices/analysis-visualizations-reporting.md)를 참조하세요.

### <a name="orchestration"></a>오케스트레이션

- **Azure Data Factory**. Azure Data Factory 파이프라인은 반복되는 기간 동안 예약된 작업 시퀀스를 정의하는 데 사용될 수 있습니다. 이러한 작업은 요청 시 HDInsight 클러스터의 Hive, Pig, MapReduce 또는 Spark 작업, Azure Date Lake Analytics의 U-SQL 작업, Azure SQL Data Warehouse 또는 Azure SQL Database의 저장 프로시저 뿐만 아니라 데이터 복사 작업을 시작할 수 있습니다.
- **Oozie** 및 **Sqoop**. Oozie는 Apache Hadoop 에코시스템용 작업 자동화 엔진으로, 데이터를 처리하기 위한 Hive, Pig 및 MapReduce 작업, HDFS 데이터베이스와 SQL 데이터베이스 간에 데이터를 복사하는 Sqoop 작업 뿐만 아니라 데이터 복사 작업을 시작하는 데 사용될 수 있습니다.

자세한 내용은 [파이프라인 오케스트레이션](../technology-choices/pipeline-orchestration-data-movement.md)을 참조하세요.
